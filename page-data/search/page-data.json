{"componentChunkName":"component---node-modules-gatsby-theme-ocular-src-react-templates-search-jsx","path":"/search","result":{"pageContext":{"data":[{"excerpt":"Introduction loaders.gl is a suite of loaders for file formats focused on visualization of big data, including point clouds, 3D geometries…","rawMarkdownBody":"# Introduction\n\nloaders.gl is a suite of loaders for file formats focused on visualization of big data, including point clouds, 3D geometries, images, geospatial formats as well as tabular data.\n\nloaders.gl is part of the [vis.gl](https://vis.gl) ecosystem, and frameworks like [deck.gl](https://deck.gl) and [luma.gl](https://luma.gl) come pre-integrated with loaders.gl. However, all the provided loaders and writers are framework independent, and can be used with any application or framework.\n\n## Loaders\n\nloaders.gl provides a wide selection of loaders organized into categories:\n\n| Category                                                         | Loaders                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| ---------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| [Table Loaders](docs/specifications/category-table)              | Streaming tabular loaders for [CSV](modules/csv/docs/api-reference/csv-loader), [JSON](modules/json/docs/api-reference/json-loader), [Arrow](modules/arrow/docs/api-reference/arrow-loader) etc                                                                                                                                                                                                                                                                                |\n| [Image Loaders](docs/specifications/category-image)              | Loaders for [images](modules/images/docs/api-reference/image-loader), [compressed textures](modules/basis/docs/api-reference/compressed-texture-loader), [supercompressed textures (Basis)](modules/basis/docs/api-reference/basis-loader). Utilities for [mipmapped arrays](modules/images/docs/api-reference/load-image-array), [cubemaps](modules/images/docs/api-reference/load-image-cube), [binary images](modules/images/docs/api-reference/binary-image-api) and more. |\n| [Pointcloud and Mesh Loaders](docs/specifications/mesh-category) | Loaders for point cloud and simple mesh formats such as [Draco](modules/draco/docs/api-reference/draco-loader), [LAS](modules/las/docs/api-reference/las-loader), [PCD](modules/pcd/docs/api-reference/pcd-loader), [PLY](modules/ply/docs/api-reference/ply-loader), [OBJ](modules/obj/docs/api-reference/obj-loader), and [Terrain](modules/terrain/docs/api-reference/terrain-loader).                                                                                      |\n| [Scenegraph Loaders](docs/specifications/category-scenegraph)    | [glTF](modules/gltf/docs/api-reference/gltf-loader) loader                                                                                                                                                                                                                                                                                                                                                                                                                     |\n| [3D Tile Loaders](docs/specifications/category-3d-tiles)         | Loaders for 3D tile formats such as [3D Tiles](modules/3d-tiles/docs/api-reference/tile-3d-loader), I3S and potree                                                                                                                                                                                                                                                                                                                                                             |\n| [Geospatial Loaders](docs/specifications/category-gis)           | Loaders for geospatial formats (beyond GeoJSON) such as [KML](modules/kml/docs/api-reference/kml-loader), [WKT](modules/wkt/docs/api-reference/wkt-loader) etc.                                                                                                                                                                                                                                                                                                                |\n\n## Quick Code Examples\n\nloaders.gl provides a small core API module with common functions to load and save data, and a number of additional modules that provide loaders and writers for specific file formats.\n\nA minimal example using the `load` function and the `CSVLoader` to load a CSV formatted table into a JavaScript array:\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nconst data = await load('data.csv', CSVLoader);\n\nfor (const row of data) {\n  console.log(JSON.stringify(row)); // => '{header1: value1, header2: value2}'\n}\n```\n\nStreaming parsing is available using ES2018 async iterators, allowing \"larger than memory\" files to be processed:\n\n```js\nimport {loadInBatches} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nfor await (const batch of await loadInBatches('data.csv', CSVLoader)) {\n  for (const row of batch) {\n    console.log(JSON.stringify(row)); // => '{header1: value1, header2: value2}'\n  }\n}\n```\n\nTo quickly get up to speed on how the loaders.gl API works, please see [Get Started](docs/developer-guide/get-started).\n\n## Why loaders.gl?\n\nloaders.gl collects a mix of the best existing and a handful of newly written loaders, and package them all in a consistent, portable, framework-independent open source module suite.\n\nThere were already many excellent open source loaders available on e.g github and npm. However, these can be sometimes be hard to use in applications, due to various limitations such as:\n\n- dependencies on a certain framework you are not able to use\n- not packaged for easy (re)use\n- Lack of Node.js support or browser support\n- inability to run in worker threads\n- lack of streaming support\n  etc.\n\n## Supported Platforms\n\nloaders.gl provides consistent support for both browsers and Node.js. The following platforms are supported:\n\n- **Evergreen Browsers** loaders.gl supports recent versions of the major evergreen browsers (e.g. Chrome, Firefox, Safari) on both desktop and mobile.\n- **Edge and IE11** loaders.gl runs on Edge and IE11, assuming that both `@loaders.gl/polyfills` and additional appropriate polyfills (e.g. babel polyfills) are installed. Note that testing on these older platforms is less frequent, so temporary regressions can occur.\n- **Node.js** LTS (Long-Term Support) [releases](https://nodejs.org/en/about/releases/) are also supported through the `@loaders.gl/polyfills` module.\n\n## Main Design Goals\n\n**Framework Agnostic** - Files are parsed into clearly documented data structures (objects + typed arrays) that can be used with any JavaScript framework.\n\n**Worker Support** - Many loaders run in web workers, keeping the main thread free for other tasks while parsing completes.\n\n**Streaming Support** - Several loaders can parse in batches from both node and browser `Stream`s, allowing \"larger than memory\" files to be processed, and initial results to be available while the remainder of a file is still loading.\n\n**Node Support** - All loaders work under Node.js and can be used when writing backend and cloud services, and when running your unit tests under Node.\n\n**Loader Categories** - loaders.gl groups similar data formats into \"categories\". loaders in the same category return parsed data in \"standardized\" form, simplifying applications that want to handle multiple related formats.\n\n**Format Autodection** - Applications can specify multiple loaders when parsing a file, and loaders.gl will automatically pick the right loader for a given file based on file extension, MIME type and file header.\n\n**Bundle Size Optimized** - Each format is published as an independent npm module to allow applications to cherry-pick only the loaders it needs, modules are optimized for tree-shaking, large loader libraries and workers are loaded from CDN and not bundled.\n\n**Modern JavaScript** - loaders.gl is written in standard ES2018 and the API emphasizes modern, portable JavaScript constructs, e.g. async iterators instead of streams, `ArrayBuffer` instead of `Buffer`, etc.\n\n**Binary Data Optimized** - loaders.gl is optimized for use with WebGL frameworks (e.g. by returning typed arrays whenever possible). However, there are no any actual WebGL dependencies and loaders can be used without restrictions in non-WebGL applications.\n\n**Multi-Asset Loading** - Some formats like glTF, or mipmapped cube textures, can required dozens of separate loads to resolve all linked assets (external buffers, images etc). Tracking all the resulting async loads can cause complications for applications. By default, loaders.gl loads all linked assets before resolving a returned `Promise`.\n\n## Licenses, Credits and Attributions\n\nloaders.gl contains code under several permissive open source licenses, currently MIT, BSD and Apache licenses. Additional licenses might be included in the future, however loaders.gl will never include code with non-permissive, commercial or copy-left licenses.\n\nNote that each loader module comes with its own license, so if the distinction matters to you, please check and decide accordingly.\n\nRegading attributions, loaders.gl is partly a repackaging of superb work done by many others in the open source community. We try to be as explicit as we can about the origins and attributions of each loader, both in the documentation page for each loader and in the preservation of comments relating to authorship and contributions inside forked source code.\n\nEven so, we can make mistakes, and we may not have the full history of the code we are reusing. If you think that we have missed something, or that we could do better in regard to attribution, please let us know.\n","slug":"docs","title":"Introduction"},{"excerpt":"Contributing Contributions are welcome, assuming that they align with the general design goals and philosophy of the repo. Unless you just…","rawMarkdownBody":"# Contributing\n\nContributions are welcome, assuming that they align with the general design goals and philosophy of the repo.\n\nUnless you just want to contribute a small bug fix, it is a good idea to start by opening an issue and discuss your idea with the maintainers. This maximizes the chances that your contribution will be accepted once you open a pull request.\n\n## Configuring Your Development Environment\n\nTo contribute, you will likely want to clone the loaders.gl repository and make sure you can install, build and run tests.\n\nOur primary development environment is MacOS, but it is possible to build loaders.gl on Linux and Windows (using a Linux environment).\n\n### Setting up Linux Environment on Windows 10\n\nIt is possible to build under Windows, but not directly in the Windows command prompt. You will need to install a Linux command line environment.\n\nInstall [WSL (Windows Subsystem for Linux)](https://docs.microsoft.com/en-us/windows/wsl/install-win10) on Windows 10.\n\n### Install Node and NPM\n\n```bash\nsudo apt update\nsudo apt install nodejs\n```\n\n### Option: Install NVM\n\n- `https://www.liquidweb.com/kb/how-to-install-nvm-node-version-manager-for-node-js-on-ubuntu-12-04-lts/`\n- `https://github.com/nvm-sh/nvm/releases`\n\n### Install yarn\n\nhttps://www.hostinger.com/tutorials/how-to-install-yarn-on-ubuntu/\n\n```bash\nsudo apt update\nsudo apt install yarn nodejs\nyarn –version\n```\n\n### Install jq\n\n```bash\nsudo apt-get install jq\n```\n\n### Configuring your System\n\nOn Linux Systems Install packages\n\n- mesa-utils\n- xvfb\n- libgl1-mesa-dri\n- libglapi-mesa\n- libosmesa6\n- libxi-dev\n\nTo get the headless tests working: export DISPLAY=:99.0; sh -e /etc/init.d/xvfb start\n\n## Running Tests\n\n- `yarn lint`: Check coding standards and formatting\n- `yarn lint fix`: Fix errors with formatting\n- `yarn test node`: Quick test run under Node.js\n- `yarn test browser`: Test run under browser, good for interactive debugging\n- `yarn test`: Run lint, node test, browser tests (in headless mode)\n","slug":"docs/contributing","title":"Contributing"},{"excerpt":"Roadmap This is the high-level loaders.gl roadmap. For detailed information see RFCs - technical writeups that describe proposed features…","rawMarkdownBody":"# Roadmap\n\nThis is the high-level loaders.gl roadmap. For detailed information see\n\n- **[RFCs](https://github.com/uber-web/loaders.gl/tree/master/dev-docs/RFCs)** - technical writeups that describe proposed features.\n- **[Github Tracker Issues](https://github.com/uber-web/loaders.gl/issues?q=is%3Aissue+is%3Aopen+tracker)** - \"Tracker\" issues contained detailed technical roadmaps for specific features/modules.\n\n## Core Feature Roadmap\n\nMany ideas are in tracker tasks in github, but here are some ideas:\n\n**Worker Improvements**\n\n- Worker Warmup: loaders.gl core should have an option to pre-load workers so that loader thread pool is primed and ready to start off-thread parsing as soon as data arrives on the wire. This can avoid a typical 1-2 second lag to load and parse the worker script on the initial load using that worker.\n- Node.js Workers: Supported since Node 10.6 / 12.3, would increase the appeal of loaders.gl in cloud/backend applications\n\n**Progress Tracking**\n\n- loaders can provide progress callbacks and a `ProgressTracker` class to track the progress of a set of parallel loads.\n\n**Automatic Timing**\n\n- loaders.gl could integrate with probe.gl `Stats`.\n- loaders could export a global stats object.\n- `load` options could accept a `stats` parameter.\n- objects returned from loaders could contain a `stats` object with timing stats.\n- `setDefaultOptions({stats: true})` to enable stats collection, etc.\n\n**MIME types**\n\n- Allow MIME types (e.g. from response headers) to be provided to assist in loader auto-selection.\n\n## Writer Roadmap\n\nNote that Writer support is currently minimal in loaders.gl, so far mainly due to lack of strong internal use cases.\n\n- Worker support for writers\n- Enable Writers to return recommended MIME type(s).\n\n## Loader Roadmap\n\n### Data loaders\n\n- Develop table category helper classes\n- Develop table to Arrow mapping support\n- Develop GeoJSON to Arrow mapping\n\nStreaming tabular loaders\n\n### `CSVLoader`\n\n- Improve perf of CSV Loader to match `d3.dsv`\n\n### Images\n\n- Good example that shows various (compressed) formats loading\n- Decide on ImageWorkerLoader\n- Decide on type: 'data'\n- Basis image decoder, finalize API\n- Compressed image decoder, finalize API\n- Finalize documentation\n\n### Geospatial loaders\n\nFocus on loading of large, complex geospatial data.\n\n- KML\n- Shapefile\n\n### Meshes\n\n- MTL - Implement MTL format support, we should have full OBJ/MTL support.\n- Determine how materials fit into the Mesh category, or if adding MTL returns a Scenegraph category object.\n- OBJ can also support face groups => simple scenegraph?\n\nNote: Given industry convergence on glTF, we do not envision supporting other mesh formats beyond OBJ/MTL.\n\n### Point Clouds\n\nFocus on support formats for large point clouds.\n\n- Better example for point cloud loading\n  - auto discover extents\n  - support streaming loads (display points as they stream in).\n  - better selector for data sets with preview images\n\n**`LASLoader`**\n\n- Implement streaming load\n- load emscripten-lib from unpkg CDN\n- compile C++ to WASM instead of JS?\n- investigate support for LAS 1.4?\n\n### 3D Tiles\n\n- Support for alternative/non-geospatial coordinate systems (potree)\n- Support unlit materials\n- Finalize i3s support\n- Finalize potree support\n- Better example\n  - better selector for data sets with preview images\n\n### Scenegraph Formats\n\nFocus on glTF/GLB - loaders.gl should to have a very solid implementation.\n\n- The glTF loaders should handle (e.g. preprocess) any glTF extensions that can be handled during the load phase (such as Draco, Basis - but many can only be handled during rendering).\n\nWhat loaders.gl will NOT support: Given the emergence of glTF as a major Khronos standard, and availability of good glTF conversion tools and exporters, loaders will most likely not supprt any other large scene/mesh description formats such as COLLADA.\n\n### Other loaders\n\nFinally, some \"unusual\" loaders may be included just for fun, e.g. SVG tesselation.\n","slug":"docs/roadmap","title":"Roadmap"},{"excerpt":"Upgrade Guide Upgrading to v2.1  Some iterator helper functions have been renamed, the old naming is now deprecated. Old Name New Name…","rawMarkdownBody":"# Upgrade Guide\n\n## Upgrading to v2.1\n\n**`@loaders.gl/core`**\n\nSome iterator helper functions have been renamed, the old naming is now deprecated.\n\n| Old Name                   | New Name                 |\n| -------------------------- | ------------------------ |\n| `getStreamIterator`        | `makeStreamIterator`     |\n| `contatenateAsyncIterator` | `concatenateChunksAsync` |\n\n**`@loaders.gl/json`**\n\n- Experimental exports have been removed `JSONParser`, `StreamingJSONParser`, `ClarinetParser`.\n\n**`@loaders.gl/images`**\n\nThe experimental ImageLoaders for individual formats introduced in 2.0 have been removed, use `ImageLoader` for all formats.\n`@loaders.gl/images`\n\n- `getImageData(image)` now returns an object with `{data, width, height}` instead of just the `data` array. This small breaking change ensures that the concept of _image data_ is consistent across the API.\n- `ImageLoader`: `options.image.type`: The `html` and `ndarray` image types are now deprecated and replaced with `image` and `data` respectively.\n\n**`@loaders.gl/3d-tiles`**\n\n`Tileset3DLoader` and `Tile3DLoader` are replaced by `Tiles3DLoader`, which supports loading both a 3D tileset file and a tile. Check `loaders.gl/3d-tiles` for loaded data format.\n\n## Upgrading to v2.0\n\nVersion 2.0 is a major release that consolidates functionality and APIs, and a number of deprecated functions have been removed.\n\nSome general changes:\n\n- All exported loader and writer objects now expose a `mimeType` field. This field is not yet used by `@loaders.gl/core` but is available for applications (e.g. see `selectLoader`).\n- All (non-worker) loaders are now required to expose a `parse` function (in addition to any more specialized `parseSync/parseText/parseInBatches` functions). This simplifies using loaders without `@loaders.gl/core`, which can reduce footprint in small applications.\n\n### `@loaders.gl/core`\n\n| Removal            | Replacement                                                            |\n| ------------------ | ---------------------------------------------------------------------- |\n| `TextEncoder`      | Use global `TextEncoder` instead and `@loaders.gl/polyfills` if needed |\n| `TextDecoder`      | Use global `TextDecoder` instead and `@loaders.gl/polyfills` if needed |\n| `createReadStream` | `fetch().then(resp => resp.body)`                                      |\n| `parseFile`        | `parse`                                                                |\n| `parseFileSync`    | `parseSync`                                                            |\n| `loadFile`         | `load`                                                                 |\n\n### `@loaders.gl/images`\n\n| Removal             | Replacement                                               |\n| ------------------- | --------------------------------------------------------- |\n| `ImageHTMLLoader`   | `ImageLoader` with `options.images.format: 'image'`       |\n| `ImageBitmapLoader` | `ImageLoader` with `options.images.format: 'imagebitmap'` |\n| `decodeImage`       | `parse(arrayBuffer, ImageLoader)`                         |\n| `isImage`           | `isBinaryImage`                                           |\n| `getImageMIMEType`  | `getBinaryImageMIMEType`                                  |\n| `getImageSize`      | `getBinaryImageSize`                                      |\n| `getImageMetadata`  | `getBinaryImageMIMEType` + `getBinaryImageSize`           |\n\n### Loader Objects\n\n- Loaders can no longer have a `loadAndParse` method. Remove it, and just make sure you define `parse` on your loaders instead.\n\n### `@loaders.gl/gltf`\n\nThe `GLTFLoader` now always uses the new v2 parser, and the original `GLTFParser` has been removed.\n\n| Removal            | Replacement  |\n| ------------------ | ------------ |\n| `GLBParser`        | `GLBLoader`  |\n| `GLBBuilder`       | `GLBWriter`  |\n| `GLTFParser`       | `GLTFLoader` |\n| `GLTFBuilder`      | `GLTFWriter` |\n| `packBinaryJson`   | N/A          |\n| `unpackBinaryJson` | N/A          |\n\nNote that automatic packing of binary data (aka \"packed JSON\" support) was only implemented in the v1 `GLTFLoader` and has thus also been removed. Experience showed that packing of binary data for `.glb` files is best handled by applications.\n\n**GLTFLoader option changes**\n\nThe foillowing top-level options are deprecated and will be removed in v2.0\n\n| Removed Option         | Replacement                             | Descriptions                                                              |\n| ---------------------- | --------------------------------------- | ------------------------------------------------------------------------- |\n| `gltf.parserVersion`   | N/A                                     | No longer needs to be specied, only the new gltf parser is available.     |\n| `fetchLinkedResources` | `gltf.fetchBuffers`, `gltf.fetchImages` |                                                                           |\n| `fetchImages`          | `gltf.fetchImages`                      |                                                                           |\n| `createImages`         | N/A                                     | Images are now always created when fetched                                |\n| `decompress`           | `gltf.decompressMeshes`                 | Decompress Draco compressed meshes (if DracoLoader available).            |\n| `DracoLoader`          | N/A                                     | Supply `DracoLoader` to `parse`, or call `registerLoaders(pDracoLoader])` |\n| `postProcess`          | `gltf.postProcess`                      | Perform additional post processing before returning data.                 |\n| `uri`                  | `baseUri`                               | Auto-populated when loading from a url-equipped source                    |\n| `fetch`                | N/A                                     | fetch is automatically available to sub-loaders.                          |\n\n### `@loaders.gl/draco`\n\n| Removal        | Replacement   |\n| -------------- | ------------- |\n| `DracoParser`  | `DracoLoader` |\n| `DracoBuilder` | `DracoWriter` |\n\n### Loader Objects\n\n- Loaders no longer have a `loadAndParse` removed. Just define `parse` on your loaders.\n\n## Upgrading from v1.2 to v1.3\n\n- As with v1.1, `GLTFLoader` will no longer return a `GLTFParser` object in v2.0. A new option `options.gltf.parserVersion: 2` is provided to opt in to the new behavior now.\n\n## Upgrading from v1.0 to v1.1\n\nA couple of functions have been deprecated and will be removed in v2.0. They now emit console warnings. Start replacing your use of these functions now to remove the console warnings and ensure a smooth future upgrade to v2.0.\n\nAlso, Node support now requires installing `@loaders.gl/polyfills` before use.\n\n### @loaders.gl/core\n\n- Removal: Node support for `fetchFile` now requires importing `@loaders.gl/polyfills` before use.\n- Removal: Node support for `TextEncoder`, and `TextDecoder` now requires importing `@loaders.gl/polyfills` before use.\n- Deprecation: `TextEncoder` and `TextDecoder` will not be exported from `loaders.gl/core` in v2.0.\n\n### @loaders.gl/images\n\n- Removal: Node support for images now requires importing `@loaders.gl/polyfills` before use.\n\n### @loaders.gl/gltf\n\n- Deprecation: `GLBParser`/`GLBBuilder` - These will be merged into GLTF classes..\n- Deprecation: `GLTFParser`/`GLTFBuilder` - The new `GLTF` class can hold GLTF data and lets application access/modify it.\n- Deprecation: `GLTFLoader` will no longer return a `GLTFParser` object in v2.0. Instead it will return a pure javascript object containing the parse json and any binary chunks. This object can be accessed through the `GLTF` class. Set `options.GLTFParser` to `false` to opt in to the new behavior now.\n\n## v1.0\n\nFirst official release of loaders.gl.\n","slug":"docs/upgrade-guide","title":"Upgrade Guide"},{"excerpt":"What's New v2.1 (In Development) Target Release Date: mid-Feb, 2019.  releases will be made available. @loaders.gl/core The  and  functions…","rawMarkdownBody":"# What's New\n\n## v2.1 (In Development)\n\nTarget Release Date: mid-Feb, 2019. `alpha` releases will be made available.\n\n**@loaders.gl/core**\n\n- The `load` and `parse` functions can now read data directly from `Stream` objects both in node and browser.\n\n**@loaders.gl/arrow**\n\n- The ArrowJS dependency has been upgraded to v0.16.\n- The ArrowJS API documentation in the loaders.gl website has been improved.\n\n**@loaders.gl/images**\n\n- Images can now be loaded as data: Using the `ImageLoader` with `options.image.type: 'data'` parameter will return an _image data object_ with width, height and a typed array containing the image data (instead of an opaque `Image` or `ImageBitmap` instance).\n- `ImageBitmap` loading now works reliably, use `ImageLoader` with `options.image.type: 'imagebitmap'`.\n\n**@loaders.gl/json**\n\n- The streaming JSON loader now has an experimental option `_rootObjectBatches` that returns the top-level JSON object containing the JSON array being streamed, as additional first (partial) and last (complete) batches.\n\n**@loaders.gl/i3s** (new loader module)\n\n- New loader module for loading [I3S](https://github.com/Esri/i3s-spec) tiles.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td style=\"text-align: center;\">\n        <img style=\"max-height:200px\" src=\"https://raw.github.com/uber-web/loaders.gl/master/website/static/images/example-i3s.jpg\" />\n        <p><strong>Tiles3DLoader</strong></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n**@loaders.gl/mvt** (new loader module)\n\n- New loader module for loading [Mapbox Vector Tiles](https://github.com/mapbox/vector-tile-spec) tiles.\n\n**@loaders.gl/terrain** (new loader module)\n\n- New loader module for reconstructing mesh surfaces from height map images.\n\n**@loaders.gl/wkt** (new loader module)\n\n- New loader module for the Well-Known Text geometry format.\n\n## v2.0\n\nRelease Date: Dec 20, 2019\n\nThe 2.0 release brings potentially dramatic bundle size savings through dynamic loading of loaders and workers, significant overhauls to several loaders including , image loading improvements and the glTF loader, and a powerful loader composition system.\n\n- **Loader-Specific Options** Each loader now defines its own sub object in the options object. This makes it possible to cleanly specify options for multiple loaders at the same time. This is helpful when loaders.gl auto-selects a pre-registered loader or when passing options to a sub-loader when using a composite loader.\n\n- **Smaller Loaders** Big loaders such as `DracoLoader` and `BasisLoader` that use large libraries (e.g. WASM/WebAssembly or emscripten/C++ transpiled to JavaScript) now load those libraries dynamically from `unpkg.com` CDN resulting in dramatic bundle size savings. E.g the bundle size impact of the `DracoLoader` was reduced from > 1MB to just over 10KB.\n\n- **Worker Loaders**\n\n  - Ease-of-use: Worker loading is provided by the main loader objects. It is not necessary to import the `...WorkerLoader` objects to enable worker loading (but see below about bundle size)\n  - Performance: Loading on worker threads is now the default: All worker enabled loaders now run on worker threads by default (set `options.worker: false` to disable worker-thread loading and run the loader on the main thread).\n  - Debugging: Development builds of workers are now available on `unpkg.com` CDN, eabling debugging of worker loaders.\n  - Bundle size: Workers are no longer bundled, but loaded from from the `unpkg.com` CDN.\n  - Bundle size: Note that the old `...WorkerLoader` classes are still available. Using these can save even more bundle space since during tree-shaking since they do not depend on the non-worker parser.\n\n- **Composite Loaders**\n  - The new _composite loader_ architecture enables complex loaders like `Tiles3DLoader` and `GLTFLoader` to be composed from more primitive loaders without losing the ability to run some parts on worker, pass arguments to sub-loaders etc.\n\n### New Loader Modules\n\n- **@loaders.gl/basis** (Experimental) A new module for the basis format that enables. This module also provides a `CompressedImageLoader` for more traditional compressed images.\n- **@loaders.gl/json** (Experimental) A new streaming `JSONLoader` that supports batched (i.e. streaming) parsing from standard JSON files, e.g. geojson. No need to reformat your files as line delimited JSON.\n\n### Update Loader Modules\n\n- `@loaders.gl/gltf` the `GLTFLoader` is now a \"composite loader\". The perhaps most important change is that `load(url, GLTFLoader)` also loads all sub-assets, including images, Draco compressed meshes, etc making the loaded data easier for applications to use.\n- `@loaders.gl/images` see below for a list of changes\n\n### @loaders.gl/images Updates\n\n- **New ImageLoader options** `options: {image: {}}` contain common options that apply across the category\n  - `options.image.type`, Ability to control loaded image type enabling faster `ImageBitmap` instances to be loaded via `type: 'imagebitmap`. Default `auto` setting returns traditional HTML image objects.\n- Image Decoding. `options.image.decodeHTML: true` - `ImageLoader` now ensures HTML images are completely decoded and ready to be used when the image is returned (by calling `Image.decode()`).\n\n- **Parsed Image API** Since the type of images returned by the `ImageLoader` depends on the `{image: {type: ...}}` option, a set of functions are provided to work portably with loaded images: `isImage()`, `getImageType()`, `getImageData()`, ...\n- **Binary Image API** Separate API to work with unparsed images in binary data form: `isBinaryImage()`, `getBinaryImageType()`, `getBinaryImageSize()`, ...\n- **\"Texture\" Loading API** New methods `loadImages` and `loadImageCube` can signficantly simplify loading of arrays of arrays of (mipmapped) images that are often used in 3D applications. These methods allow an entire complex of images (e.g. 6 cube faces with 10 mip images each) to be loaded using a single async call.\n- **Improved Node.js support** More image test cases are now run in both browser and Node.js and a couple of important Node.js issues were uncovered and fixed.\n\n## v1.3\n\nRelease Date: Sep 13, 2019\n\nThe 1.3 release is focused on production quality 3D tiles support, maturing the v2 glTF parser, and provides some improvements to the core API.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td style=\"text-align: center;\">\n        <img style=\"max-height:200px\" src=\"https://raw.github.com/uber-web/loaders.gl/master/website/static/images/example-3d-tiles.png\" />\n        <p><strong>Tiles3DLoader</strong></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### @loaders.gl/3d-tiles\n\n- **Tile3DLayer moved to deck.gl**\n\n  - The `Tile3DLayer` can now be imported from `@deck.gl/geo-layers`, and no longer needs to be copied from the loaders.gl `3d-tiles` example\n\n- **Batched 3D Model Tile Support**\n\n  - `b3dm` tiles can now be loaded and displayed by the `Tile3DLayer` (in addition to `pnts` tiles).\n\n- **Performance Tracking**\n\n  - `Tileset3D` now contain a `stats` object which tracks the loading process to help profile big tilesets.\n  - Easily displayed in your UI via the `@probe.gl/stats-widget` module (see 3d-tiles example).\n\n- **Request Scheduling**\n  - The `Tileset3D` class now cancels loads for not-yet loaded tiles that are no longer in view).\n  - Scheduling dramatically improves loading performance when panning/zooming through large tilesets.\n\n### @loaders.gl/gltf\n\n- **Version 2 Improvements**\n  - Select the new glTF parser by passing `options.gltf.parserVersion: 2` to the `GLTFLoader`.\n  - Many improvements to the v2 glTF parser.\n\n### @loaders.gl/core\n\n- **Loader Selection Improvements**\n\n  - The loader selection mechanism is now exposed to apps through the new `selectLoader` API.\n  - Loaders can now examine the first bytes of a file\n  - This complements the existing URL extension based auto detection mechanisms.\n\n- **Worker Thread Pool**\n  - Now reuses worker threads. Performance gains by avoiding worker startup overhead.\n  - Worker threads are named, easy to track in debugger\n  - Worker based loaders can now call `parse` recursively to delegate parsing of embedded data (e.g. glTF, Draco) to other loaders\n\n## v1.2\n\nThe 1.2 release is a smaller release that resolves various issues encountered while using 1.1.\n\nRelease Date: Aug 8, 2019\n\n- `@loaders.gl/core`: File Type Auto Detection now supports binary files\n- `@loaders.gl/polyfills`: Fixed `TextEncoder` warnings\n- `@loaders.gl/arrow`: Improved Node 8 support\n- `@loaders.gl/images`: Image file extensions now added to loader object\n- `@loaders.gl/gltf`: Generate default sampler parameters if none provided in gltf file\n\n### @loaders.gl/3d-tiles (EXPERIMENTAL)\n\n- Support for dynamic traversal of 3D tilesets (automatically loads and unloads tiles based on viewer position and view frustum).\n- Support for loading tilesets from Cesium ION servers.\n- Asynchronous tileset loading\n- Auto centering of view based on tileset bounding volumes\n- deck.gl `Tile3DLayer` class provided in examples.\n\n## v1.1\n\nThe 1.1 release addresses a number of gaps in original loaders.gl release, introduces the `GLTFLoader`, and initiates work on 3DTiles support.\n\nRelease Date: May 30, 2019\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td style=\"text-align: center;\">\n        <img style=\"max-height:200px\" src=\"https://raw.github.com/uber-web/loaders.gl/master/website/static/images/example-gltf.jpg\" />\n        <p><strong>GLTFLoader</strong></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### @loaders.gl/core\n\n- `fetchFile` function - Can now read browser `File` objects (from drag and drop or file selection dialogs).\n- `isImage(arrayBuffer [, mimeType])` function - can now accept a MIME type as second argument.\n\n### @loaders.gl/images\n\n- `getImageMIMEType(arrayBuffer)` function ( EW) - returns the MIME type of the image in the supplied `ArrayBuffer`.\n- `isImage(arrayBuffer [, mimeType])` function - can now accept a MIME type as second argument.\n\n### @loaders.gl/gltf\n\n- The glTF module has been refactored with the aim of simplifying the loaded data and orthogonalizing the API.\n- \"Embedded' GLB data (GLBs inside other binary formats) can now be parsed (e.g. the glTF parser can now extract embedded glTF inside 3D tile files).\n\n- New classes/functions:\n  - [`GLTFScenegraph`](/docs/api-reference/gltf/gltf-scenegraph) class (NEW) - A helper class that provides methods for structured access to and modification/creation of glTF data.\n  - [`postProcessGLTF`](/docs/api-reference/gltf/post-process-gltf) function ( EW) - Function that performs a set of transformations on loaded glTF data that simplify application processing.\n  - [`GLBLoader`](/docs/api-reference/gltf/glb-loader)/[`GLBWriter`](NEW) - loader/writer pair that enables loading/saving custom (non-glTF) data in the binary GLB format.\n  - [`GLTFLoader`](/docs/api-reference/gltf/gltf-loader), letting application separately handle post-processing.\n\n### @loaders.gl/3d-tiles (NEW MODULE)\n\n- Support for the 3D tiles format is being developed in the new `@loaders.gl/3d-tiles` module.\n- Loading of individual point cloud tiles, including support for Draco compression and compact color formats such as RGB565 is supported.\n\n### @loaders.gl/polyfills (NEW MODULE)\n\nNode support now requires importing `@loaders.gl/polyfills` before use. This reduces the number of dependencies, bundle size and potential build complications when using other loaders.gl modules when not using Node.js support.\n\n### @loaders.gl/loader-utils (NEW MODULE)\n\nHelper functions for loaders have been broken out from `@loaders.gl/core`. Individual loaders no longer depend on`@loaders.gl/core` but only on `@loaders.gl/loader-utils`.\n\n## v1.0\n\nRelease Date: April 2019\n\nFirst Official Release\n","slug":"docs/whats-new","title":"What's New"},{"excerpt":"3D Tiles Loaders The 3D tiles category is experimental. The 3D Tiles category defines a generalized representation of hierarchical…","rawMarkdownBody":"# 3D Tiles Loaders\n\n> The 3D tiles category is experimental.\n\nThe 3D Tiles category defines a generalized representation of hierarchical geospatial data structures.\n\n## 3D Tiles Category Loaders\n\n| Loader                                                                     | Notes |\n| -------------------------------------------------------------------------- | ----- |\n| [`Tiles3DLoader`](modules/3d-tiles/docs/api-reference/tiles-3d-loader)     |       |\n| [`CesiumIonLoader`](modules/3d-tiles/docs/api-reference/cesium-ion-loader) |       |\n| [`I3SLoader`](modules/i3s/docs/api-reference/i3s-loader)                   |       |\n| [`PotreeLoader`](modules/potree/docs/api-reference/potree-loader)          |       |\n\n## Overview\n\nThe 3D Tiles category is can represent the\n\n- [OGC 3D Tiles](https://www.opengeospatial.org/standards/3DTiles) standard\n- [OGC i3s](https://www.opengeospatial.org/standards/i3s) standard\n- `potree` format as well.\n\n## Concepts\n\n- **Tile Header Hierarchy** - An initial, \"minimal\" set of data listing the _hierarchy of available tiles_, with minimal information to allow an application to determine which tiles need to be loaded based on a certain viewing position in 3d space.\n- **Tile Header** - A minimal header describing a tiles bounding volume and a screen space error tolerance (allowing the tile to be culled if it is distant), as well as the URL to load the tile's actual content from.\n- **Tile Cache** - Since the number of tiles in big tilesets often exceed what can be loaded into available memory, it is important to have a system that releases no-longer visible tiles from memory.\n- **Tileset Traversal** - Dynamically loading and rendering 3D tiles based on current viewing position, possibly triggering loads of new tiles and unloading of older, no-longer visible tiles.\n\n## Data Format\n\nCheck [`Tiles3DLoader`](modules/3d-tiles/docs/api-reference/tiles-3d-loader), [`CesiumIonLoader`](modules/3d-tiles/docs/api-reference/cesium-ion-loader) |       |\n and [`I3SLoader`](modules/i3s/docs/api-reference/i3s-loader).\n\n## Helper Classes\n\nTileset Traversal Support\n\nTo start loading tiles once a top-level tileset file is loaded, the application can instantiate the `Tileset3D` class and start calling `tileset3D.update(viewport)`.\n\nSince 3D tiled data sets tend to be very big, the key idea is to only load the tiles actually needed to show a view from the current camera position.\n\nThe `Tileset3D` allows callbacks (`onTileLoad`, `onTileUnload`) to be registered that notify the app when the set of tiles available for rendering has changed. This is important because tile loads complete asynchronously, after the `tileset3D.update(...)` call has returned.\n\n## Additional Information\n\n### Coordinate Systems\n\nTo help applications process the `position` data in the tiles, 3D Tiles category loaders are expected to provide matrices are provided to enable tiles to be used in both fixed frame or cartographic (long/lat-relative, east-north-up / ENU) coordinate systems:\n\n- _cartesian_ WGS84 fixed frame coordinates\n- _cartographic_ tile geometry positions to ENU meter offsets from `cartographicOrigin`.\n\nPosition units in both cases are in meters.\n\nFor cartographic coordinates, tiles come with a prechosen cartographic origin and precalculated model matrix. This cartographic origin is \"arbitrary\" (chosen based on the tiles bounding volume center). A different origin can be chosen and a transform can be calculated, e.g. using the math.gl `Ellipsoid` class.\n","slug":"docs/specifications/category-3d-tiles","title":"3D Tiles Loaders"},{"excerpt":"Geospatial Loaders The Geospatial category is experimental Several geospatial formats return data in the form of lists of lng/lat encoded…","rawMarkdownBody":"# Geospatial Loaders\n\n> The Geospatial category is experimental\n\nSeveral geospatial formats return data in the form of lists of lng/lat encoded geometric objects.\n\n## Geospatial Category Loaders\n\n| Loader                                                   | Notes |\n| -------------------------------------------------------- | ----- |\n| [`KMLLoader`](modules/kml/docs/api-reference/kml-loader) |       |\n| [`WKTLoader`](modules/wkt/docs/api-reference/wkt-loader) |       |\n| [`MVTLoader`](modules/mvt/docs/api-reference/mvt-loader) |       |\n\n## Data Format\n\n## Data Structure\n\nA JavaScript object with a number of top-level array-valued fields:\n\n| Field           | Description                                          |\n| --------------- | ---------------------------------------------------- |\n| `points`        | A [GeoJson](https://geojson.org/) FeatureCollection. |\n| `lines`         | A [GeoJson](https://geojson.org/) FeatureCollection. |\n| `polygons`      | A [GeoJson](https://geojson.org/) FeatureCollection. |\n| `imageoverlays` | Urls and bounds of bitmap overlays                   |\n| `documents`     |                                                      |\n| `folders`       |                                                      |\n| `links`         |                                                      |\n\n### GeoJSON Conversion\n\nGeospatial category data can be converted to GeoJSON (sometimes with a loss of information). Most geospatial applications can consume geojson.\n","slug":"docs/specifications/category-gis","title":"Geospatial Loaders"},{"excerpt":"Image Loaders The image loader category documents a common data format, options, conventions and utilities for loader and writers for images…","rawMarkdownBody":"# Image Loaders\n\nThe image loader category documents a common data format, options, conventions and utilities for loader and writers for images that follow loaders.gl conventions.\n\n## Image Category Loaders\n\n| Loader                                                                                  | Notes                                                 |\n| --------------------------------------------------------------------------------------- | ----------------------------------------------------- |\n| [`ImageLoader`](modules/images/docs/api-reference/image-loader)                         | Loads compressed images (PNG, JPG, etc)               |\n| [`CompressedTextureLoader`](modules/basis/docs/api-reference/compressed-texture-loader) | Parses compressed textures to image data mipmap array |\n| [`BasisLoader`](modules/basis/docs/api-reference/basis-loader)                          | Transpiles into supported compressed texture format   |\n\nCore image category support is provided by the `@loaders.gl/images` module:\n\n## Usage\n\nIndividual loaders for specific image formats can be imported for `@loaders.gl/images`:\n\n```js\nimport '@loaders.gl/polyfills'; // Only required if loading images under Node.js\nimport {ImageLoader} from '@loaders.gl/images';\nimport {registerLoaders, load} from '@loaders.gl/core';\nregisterLoaders(ImageLoader);\nconst image = await load('image.jpeg');\n```\n\nHowever since each image loader is quite small (in terms of code size and bundle size impact), most applications will just install all image loaders in one go:\n\n```js\nimport '@loaders.gl/polyfills'; // Only required if loading images under Node.js\nimport {ImageLoaders} from '@loaders.gl/images';\nimport {registerLoader, load} from '@loaders.gl/core';\nregisterLoaders(ImageLoader);\nconst image = await load('image.jpeg');\n```\n\n## Image Types\n\nImages can be loaded as image data or as opaque image objects (`Image` or `ImageBitmap`), and the image _type_ option can be used to control the type of image object produced by the `ImageLoader`.\n\nA loaded image can always be returned as an _image data_ object (an object containing a `Uint8Array` with the pixel data, and metadata like `width` and `height`, and in Node.js images are always loaded as image data objects).\n\nIn the browser, the `ImageLoader` uses the browser's native image loading functionality, and if direct access to the image data is not required, it is more efficient to load data into an opaque image object. The `ImageLoader` prefers `ImageBitmap` when supported, falling back to `Image` (aka `HTMLImageElement`) on older browsers.\n\nNote that _type_ is independent of the _format_ of the image (see below).\n\n| Image Type    | Class                                                                | Availability         | Workers                | Description                                                                                                           |\n| ------------- | -------------------------------------------------------------------- | -------------------- | ---------------------- | --------------------------------------------------------------------------------------------------------------------- |\n| `data`        | Object with `{width: Number, height: Number, data: Uint8Array, ...}` | Node.js and browsers | No                     | Compatible with headless gl.                                                                                          |\n| `imagebitmap` | `ImageBitmap`                                                        | Chrome/Firefox       | Yes: **transferrable** | A newer JavaScript class designed for efficient loading of images, optimized for use in worker threads and with WebGL |\n| `image`       | `Image` (aka `HTMLImageElement`)                                     | All browsers         | No                     | The traditional HTML/JavaScript class used for image loading into DOM trees. WebGL compatible.                        |\n\n## Image Data\n\nImage data objects are images loaded as data, represented by an object that contains a typed array with the pixel data, size, and possibly additional metadata `{width: Number, height: Number, data: Uint8Array, ...}`\n\nTo get an image data object from a loaded `Image` or `ImageBitmap`, call `getImageData(image)`. To load an image data object directly, set the `image.type: 'data'` option when loading the image.\n\n### Image Formats\n\nThe _format_ of the image describes how the memory is laid out. It is mainly important when working with `data` _type_ images. The default format / memory layout for image data is `RGBA` and `UNSIGNED_BYTE` i.e. four components per pixel, each a byte.\n\nSome loaders may add additional fields to the image data structure to describe the data format. Currently the image category does not provide any documentation for how to describe alternate formats/memory layouts, however a preliminary recommendation is to follow OpenGL/WebGL conventions.\n\n## Compressed Images\n\nCompressed images are always returned as image data objects. They will have an additional field, `compressed: true`, indicating that the typed array in the `data` field contains compressed pixels and is not directly indexable.\n\nApplications that use e.g. the `CompressedTextureLoader` and/or the `BasisLoader` together with the `ImageLoader` can check this flag before attempting to access the image data.\n\n## Options\n\nThe image category support some generic options (specified using `options.image.<option-name>`), that are applicable to all (or most) image loaders.\n\n| Option                 | Default  | Type    | Availability   | Description                                   |\n| ---------------------- | -------- | ------- | -------------- | --------------------------------------------- |\n| `options.image.type`   | `'auto'` | string  | See table      | One of `auto`, `data`, `imagebitmap`, `image` |\n| `options.image.decode` | `true`   | boolean | No: Edge, IE11 | Wait for HTMLImages to be fully decoded.      |\n\n## Notes\n\n### About worker loading\n\nWorker loading is only supported for the `data` and `imagebitmap` formats. Since image worker loading is only available on some browsers (Chrome and Firefox), the `ImageLoader` dynamically determines if worker loading is available. Use `options.worker: false` to disable worker loading of images.\n\n## Image API\n\nThe image category also provides a few utilities:\n\n- Detecting (\"sniffing\") mime type and size of image files before parsing them\n- Getting image data (arrays of pixels) from an image without knowing which type was loaded (TBA)\n\n## Remarks\n\n### ImageData\n\nImage data objects return by image category loaders have the same fields (`width`, `height`, `data`) as the browser's built-in `ImageData` class, but are not actual instances of `ImageData`. However, should you need it, it is easy to create an `ImageData` instance from an image data object:\n\n```js\nconst data = load(url, ImageLoader, {image: {type: 'data'}});\nconst imageData = new ImageData(data.data, data.width, data.height);\n```\n","slug":"docs/specifications/category-image","title":"Image Loaders"},{"excerpt":"Mesh and PointCloud Loaders The mesh and pointcloud loader category is intended for simpler mesh and point clouds formats that describe a…","rawMarkdownBody":"# Mesh and PointCloud Loaders\n\nThe _mesh and pointcloud_ loader category is intended for simpler mesh and point clouds formats that describe a \"single geometry primitive\" (as opposed to e.g. a scenegraph consisting of a hierarchy of multiple geometries).\n\n## Mesh/PointCloud Category Loaders\n\n| Loader                                                               | Notes |\n| -------------------------------------------------------------------- | ----- |\n| [`DracoLoader`](modules/draco/docs/api-reference/draco-loader)       |       |\n| [`LASLoader`](modules/las/docs/api-reference/las-loader)             |       |\n| [`OBJLoader`](modules/obj/docs/api-reference/obj-loader)             |       |\n| [`PCDLoader`](modules/pcd/docs/api-reference/pcd-loader)             |       |\n| [`PLYLoader`](modules/ply/docs/api-reference/ply-loader)             |       |\n| [`TerrainLoader`](modules/terrain/docs/api-reference/terrain-loader) |       |\n\n## Data Format\n\nA single mesh is typically defined by a set of attributes, such as `positions`, `colors`, `normals` etc, as well as a draw mode.\n\nThe Pointcloud/Mesh loaders output mesh data in a common form that is optimized for use in WebGL frameworks:\n\n- All attributes (and indices if present) are stored as typed arrays of the proper type.\n- All attributes (and indices if present) are wrapped into glTF-style \"accessor objects\", e.g. `{size: 1-4, value: typedArray}`.\n- Attribute names are mapped to glTF attribute names (on a best-effort basis).\n- An `indices` field is added (only if present in the loaded geometry).\n- A primitive drawing `mode` value is added (the numeric value matches WebGL constants, e.g `GL.TRIANGLES`).\n\n| Field        | Type                | Contents                                                                                                    |\n| ------------ | ------------------- | ----------------------------------------------------------------------------------------------------------- |\n| `loaderData` | `Object` (Optional) | Loader and format specific data                                                                             |\n| `header`     | `Object`            | See [Header](#header)                                                                                       |\n| `mode`       | `Number`            | See [Mode](#mode)                                                                                           |\n| `attributes` | `Object`            | Keys are [glTF attribute names](#gltf-attribute-name-mapping) and values are [accessor](#accessor) objects. |\n| `indices`    | `Object` (Optional) | If present, describes the indices (elements) of the geometry as an [accessor](#accessor) object.            |\n\n### Header\n\nThe `header` fields are only recommended at this point, applications can not assume they will be present:\n\n| `header` Field | Type     | Contents |\n| -------------- | -------- | -------- |\n| `vertexCount`  | `Number` |          |\n\n### Mode\n\nPrimitive modes are aligned with [OpenGL/glTF primitive types](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#primitive)\n\n| Value | Primitive Mode   | Comment                                                                                              |\n| ----- | ---------------- | ---------------------------------------------------------------------------------------------------- |\n| `0`   | `POINTS`         | Used for point cloud category data                                                                   |\n| `1`   | `LINES`          | Lines are rarely used due to limitations in GPU-based rendering                                      |\n| `2`   | `LINE_LOOP`      | -                                                                                                    |\n| `3`   | `LINE_STRIP`     | -                                                                                                    |\n| `4`   | `TRIANGLES`      | Used for most meshes. Indices attributes are often used to reuse vertex data in remaining attributes |\n| `5`   | `TRIANGLE_STRIP` | -                                                                                                    |\n| `6`   | `TRIANGLE_FAN`   | -                                                                                                    |\n\n### Accessor\n\n`attributes` and `indices` are represented by glTF \"accessor objects\" with the binary data for that attribute resolved into a typed array of the proper type.\n\n| Accessors Fields | glTF? | Type                | Contents                                                                                                                                           |\n| ---------------- | ----- | ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `value`          | No    | `TypedArray`        | Contains the typed array (corresponds to `bufferView`). The type of the array will match the GL constant in `componentType`.                       |\n| `size`           | No    | `Number`            | Number of components, `1`-`4`.                                                                                                                     |\n| `byteOffset`     | Yes   | `Number`            | Starting offset into the bufferView.                                                                                                               |\n| `count`          | Yes   | `Number`            | The number of elements/vertices in the attribute data.                                                                                             |\n| `originalName`   | No    | `String` (Optional) | If this was a named attribute in the original file, the original name (before substitution with glTF attribute names) will be made available here. |\n\n### glTF Attribute Name Mapping\n\nTo help applications manage attribute name differences between various formats, mesh loaders map known attribute names to [glTF 2.0 standard attribute names](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#geometry) a best-effort basis.\n\nWhen a loader can map an attribute name, it will replace ir with the glTF equivalent. This allows applications to use common code to handle meshes and point clouds from different formats.\n\n| Name         | Accessor Type(s)   | Component Type(s)                                                                     | Description                                                                                                        |\n| ------------ | ------------------ | ------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n| `POSITION`   | `\"VEC3\"`           | `5126` (FLOAT)                                                                        | XYZ vertex positions                                                                                               |\n| `NORMAL`     | `\"VEC3\"`           | `5126` (FLOAT)                                                                        | Normalized XYZ vertex normals                                                                                      |\n| `TANGENT`    | `\"VEC4\"`           | `5126` (FLOAT)                                                                        | XYZW vertex tangents where the _w_ component is a sign value (-1 or +1) indicating handedness of the tangent basis |\n| `TEXCOORD_0` | `\"VEC2\"`           | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized | UV texture coordinates for the first set                                                                           |\n| `TEXCOORD_1` | `\"VEC2\"`           | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized | UV texture coordinates for the second set                                                                          |\n| `COLOR_0`    | `\"VEC3\"`, `\"VEC4\"` | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized | RGB or RGBA vertex color                                                                                           |\n| `JOINTS_0`   | `\"VEC4\"`           | `5121` (UNSIGNED_BYTE), `5123` (UNSIGNED_SHORT)                                       |                                                                                                                    |\n| `WEIGHTS_0`  | `\"VEC4\"`           | `5126` (FLOAT), `5121` (UNSIGNED_BYTE) normalized, `5123` (UNSIGNED_SHORT) normalized |                                                                                                                    |\n\n> Note that for efficiency reasons, mesh loaders are not required to convert the format of an attribute's binary data to match the glTF specifications (i.e. if normals were encoded using BYTES then that is what will be returned even though glTF calls out for FLOAT32). Any such alignment needs to be done by the application as a second step.\n\n## Limitations\n\n### Scenegraph support\n\nFor more complex, scenegraph-type formats (i.e. formats that contain multiple geometric primitives), loaders.gl provides glTF 2.0 support via the `GLTFLoader`.\n\n### Material support\n\nMaterial support is provided by some mesh formats (e.g. OBJ/MTL) and is currently not implemented by loaders.gl, however the glTF loader has full support for PBR (Physically-Based Rendering) materials.\n","slug":"docs/specifications/category-mesh","title":"Mesh and PointCloud Loaders"},{"excerpt":"Scenegraph Loaders The Scenegraph category is intended to represent glTF scenegraphs. Loaders Loader Notes     Data Format The data format…","rawMarkdownBody":"# Scenegraph Loaders\n\nThe Scenegraph category is intended to represent glTF scenegraphs.\n\n## Loaders\n\n| Loader                                                      | Notes |\n| ----------------------------------------------------------- | ----- |\n| [`GLTFLoader`](modules/gltf/docs/api-reference/gltf-loader) |       |\n| [`GLBLoader`](modules/gltf/docs/api-reference/glb-loader)   |       |\n\n## Data Format\n\nThe data format is fairly raw, close to the unpacked glTF/GLB data structure, it is described by:\n\n- a parsed JSON object (with top level arrays for `scenes`, `nodes` etc)\n- a list of `ArrayBuffer`s representing binary blocks (into which `bufferViews` and `images` in the JSON point).\n\n## Data Structure\n\nA JSON object with the following top-level fields:\n\n| Field     | Type            | Default | Description                                              |\n| --------- | --------------- | ------- | -------------------------------------------------------- |\n| `magic`   | `Number`        | glTF    | The first four bytes of the file                         |\n| `version` | `Number`        | `2`     | The version number                                       |\n| `json`    | `Object`        | `{}`    | The JSON chunk                                           |\n| `buffers` | `ArrayBuffer[]` | `[]`    | (glTF) The BIN chunk plus any base64 or BIN file buffers |\n\nBuffers can be objects in the shape of `{buffer, byteOffset, byteLength}`.\n\n## Helper Classes\n\nTo simplify higher-level processing of the loaded, raw glTF data, several helper classes are provided in the `@loaders.gl/gltf` module, these can:\n\n- unpack and remove certain glTF extensions\n- extract typed array views from the JSON objects into the binary buffers\n- create HTML images from image buffers\n- etc\n\n## Non-glTF Scenegraphs\n\nThe scenegraph \"category\" was created specifically for the `glTF` format, and there are no plans to support other scenegraph formats in loaders.gl (as such formats tend to have large and complex specifications with many edge cases).\n\nTherefore, the current recommendation is to first convert scenegraph files in other formats to glTF with external tools before loading them using loaders.gl.\n\nThat said, hypothetical new loaders for other scenegraph formats (e.g. a COLLADA loader) could potentially choose to belong to the Scenegraph category by \"converting\" loaded data to the format described on this page. It would thus enable interoperability with applications that are already designed to use the `GLTFLoader`).\n","slug":"docs/specifications/category-scenegraph","title":"Scenegraph Loaders"},{"excerpt":"Table Loaders The table category loaders supports loading tables in row-based, columnar or batched columnar formats. Table Category Loaders…","rawMarkdownBody":"# Table Loaders\n\nThe _table_ category loaders supports loading tables in _row-based_, _columnar_ or _batched columnar_ formats.\n\n## Table Category Loaders\n\n| Loader                                                         | Notes                              |\n| -------------------------------------------------------------- | ---------------------------------- |\n| [`ArrowLoader`](modules/arrow/docs/api-reference/arrow-loader) |                                    |\n| [`CSVLoader`](modules/csv/docs/api-reference/csv-loader)       |                                    |\n| [`JSONLoader`](modules/json/docs/api-reference/json-loader)    | Set `options.json.table` to `true` |\n\n## Data Structure\n\n| Field    | Type                | Contents                                                     |\n| -------- | ------------------- | ------------------------------------------------------------ |\n| `schema` | `Object`            | Metadata of the table, maps name of each column to its type. |\n| `data`   | `Object` or `Array` | Data of the table, see [table types](#table-types)           |\n| `length` | `Number`            | Number of rows                                               |\n\n## Table Types\n\nloaders.gl deals with (and offers utilities to convert between) three different types of tables:\n\n### Classic Tables (Row-Major)\n\nThis is the classic JavaScript table. `data` consists of an `Array` of `Object` instances, each representing a row.\n\n### Columnar Tables (Column-Major)\n\nColumnar tables are stored as one array per column. Columns that are numeric can be loaded as typed arrays which are stored in contigous memory. `data` is an `Object` that maps column names to an array or typed array.\n\nContiguous memory has tremendous benefits:\n\n- Values are adjacent in memory, the resulting cache locality can result in big performance gains\n- Typed arrays can of course be efficiently transferred from worker threads to main thread\n- Can be directly uploaded to the GPU for further processing.\n\n### Chunked Columnar Tables (DataFrames)\n\nA problem with columnar tables is that column arrays they can get very long, causing issues with streaming, memory allication etc. A powerful solution is to worked with chunked columnar tables, where columns is are broken into matching sequences of typed arrays.\n\nThe down-side is that complexity can increase quickly. Data Frames are optimized to minimize the amount of copying/moving/reallocation of data during common operations such e.g. loading and transformations, and support zero-cost filtering through smart iterators etc.\n\nUsing the Arrow API it is possible to work extremely efficiently with very large (multi-gigabyte) datasets.\n","slug":"docs/specifications/category-table","title":"Table Loaders"},{"excerpt":"Loader Object To be compatible with the parsing/loading functions in  such as  and , a parser needs to be described by a \"loader object…","rawMarkdownBody":"# Loader Object\n\nTo be compatible with the parsing/loading functions in `@loaders.gl/core` such as `parse` and `load`, a parser needs to be described by a \"loader object\" conforming to the following specification.\n\n## Loader Object Format v1.0\n\n### Common Fields\n\n| Field               | Type       | Default  | Description                                                     |\n| ------------------- | ---------- | -------- | --------------------------------------------------------------- |\n| `name`              | `String`   | Required | Short name of the loader ('OBJ', 'PLY' etc)                     |\n| `extension`         | `String`   | Required | Three letter (typically) extension used by files of this format |\n| `extensions`        | `String[]` | Required | Array of file extension strings supported by this loader        |\n| `category`          | `String`   | Optional | Indicates the type/shape of data                                |\n| `parse` \\| `worker` | `Function` | `null`   | Every non-worker loader should expose a `parse` function.       |\n\nNote: Only one of `extension` or `extensions` is required. If both are supplied, `extensions` will be used.\n\n### Test Function\n\n| Field      | Type       | Default  | Description                                                                                   |\n| ---------- | ---------- | -------- | --------------------------------------------------------------------------------------------- |\n| `test`     | `Function` | `String` | `String[]`                                                                                    | `null` | Guesses if a binary format file is of this format by examining the first bytes in the file. If the test is specified as a string or array of strings, the initial bytes are expected to be \"magic bytes\" matching one of the provided strings. |\n| `testText` | `Function` | `null`   | Guesses if a text format file is of this format by examining the first characters in the file |\n\n### Parser Functions\n\nEach (non-worker) loader should define a `parse` function. Additional parsing functions can be exposed depending on the loaders capabilities, to optimize for text parsing, synchronous parsing, streaming parsing, etc:\n\n| Parser function field               | Type       | Default | Description                                                                            |\n| ----------------------------------- | ---------- | ------- | -------------------------------------------------------------------------------------- |\n| `parse`                             | `Function` | `null`  | Asynchronously parses binary data (e.g. file contents) asynchronously (`ArrayBuffer`). |\n| `parseInBatches` (Experimental)     | `Function` | `null`  | Parses binary data chunks (`ArrayBuffer`) to output data \"batches\"                     |\n| `parseInBatchesSync` (Experimental) | `Function` | `null`  | Synchronously parses binary data chunks (`ArrayBuffer`) to output data \"batches\"       |\n| `parseSync`                         | `Function` | `null`  | Atomically and synchronously parses binary data (e.g. file contents) (`ArrayBuffer`)   |\n| `parseTextSync`                     | `Function` | `null`  | Atomically and synchronously parses a text file (`String`)                             |\n\nSynchronous parsers are more flexible as they can support synchronous parsing which can simplify application logic and debugging, and iterator-based parsers are more flexible as they can support batched loading of large data sets in addition to atomic loading.\n\nYou are encouraged to provide the most capable parser function you can (e.g. `parseSync` or `parseToIterator` if possible). Unless you are writing a completely new loader from scratch, the appropriate choice often depends on the capabilities of an existing external \"loader\" that you are working with.\n\n### Parser Function Signatures\n\n- `async parse(data : ArrayBuffer, options : Object, context : Object) : Object`\n- `parseSync(data : ArrayBuffer, options : Object, context : Object) : Object`\n- `parseInBatches(data : AsyncIterator, options : Object, context : Object) : AsyncIterator`\n\nThe `context` parameter will contain the foolowing fields\n\n- `parse` or `parseSync`\n- `url` if available\n","slug":"docs/specifications/loader-object-format","title":"Loader Object"},{"excerpt":"Writer Object To be compatible with  functions such as , writer objects need to conform to the following specification: Common Fields Field…","rawMarkdownBody":"# Writer Object\n\nTo be compatible with `@loaders.gl/core` functions such as `encode`, writer objects need to conform to the following specification:\n\n### Common Fields\n\n| Field       | Type     | Default  | Description                                                     |\n| ----------- | -------- | -------- | --------------------------------------------------------------- |\n| `name`      | `String` | Required | Short name of the loader ('OBJ', 'PLY' etc)                     |\n| `extension` | `String` | Required | Three letter (typically) extension used by files of this format |\n| `category`  | `String` | Optional | Indicates the type/shape of data                                |\n\n### Encoder Function\n\n| Field                            | Type       | Default | Description                                            |\n| -------------------------------- | ---------- | ------- | ------------------------------------------------------ |\n| `encodeSync`                     | `Function` | `null`  | Encodes synchronously                                  |\n| `encode`                         | `Function` | `null`  | Encodes asynchronously                                 |\n| `encodeInBatches` (Experimental) | `Function` | `null`  | Encodes and releases batches through an async iterator |\n\nNote: The format of the input data to the encoders depends on the loader. Several loader categories are defined to provided standardized data formats for similar loaders.\n","slug":"docs/specifications/writer-object-format","title":"Writer Object"},{"excerpt":"Creating New Loaders and Writers See the a detailed specification of the loader object format API reference. Overview Applications can also…","rawMarkdownBody":"# Creating New Loaders and Writers\n\n> See the a detailed specification of the [loader object format API reference](docs/specifications/loader-object-format).\n\n## Overview\n\nApplications can also create new loader objects. E.g. if you have existing JavaScript parsing functionality that you would like to use with the loaders.gl core utility functions.\n\n## Creating a Loader Object\n\nYou would give a name to the loader object, define what file extension(s) it uses, and define a parser function.\n\n```js\nexport default {\n  name: 'JSON',\n  extensions: ['json'],\n  testText: null,\n  parse: async (arrayBuffer) => await JSON.parse(new TextDecoder().decode(arrayBuffer),\n  parseTextSync: JSON.parse\n};\n```\n\n| Field       | Type       | Default  | Description                                                                       |\n| ----------- | ---------- | -------- | --------------------------------------------------------------------------------- |\n| `name`      | `String`   | Required | Short name of the loader ('OBJ', 'PLY' etc)                                       |\n| `extension` | `String`   | Required | Three letter (typically) extension used by files of this format                   |\n| `testText`  | `Function` | `null`   | Guesses if a file is of this format by examining the first characters in the file |\n\nA loader must define a parser function for the format, a function that takes the loaded data and converts it into a parsed object.\n\nDepending on how the underlying loader works (whether it is synchronous or asynchronous and whether it expects text or binary data), the loader object can expose the parser in a couple of different ways, specified by provided one of the parser function fields.\n\n## Dependency Management\n\nIn general, it is recommended that loaders are \"standalone\" and avoid importing `@loaders.gl/core`. `@loaders.gl/loader-utils` provides a small set of shared loader utilities.\n\n## Creating Composite Loaders\n\nloaders.gl enables loaders to call other loaders (referred to as \"sub-loaders\" in this section). This enables loaders for \"composite formats\" to be \"composed\" out of loaders for the primitive parts.\n\nGood examples of sub-loaders are the `GLTFLoader` which can delegate Draco mesh decoding to the `DracoLoader` and image decoding to the various `ImageLoaders` and the `BasisLoader`.\n\nNaturally, Composite loaders can call other composite loaders, which is for instance used by the `Tiles3DLoader` which uses the `GLTFLoader` to parse embedded glTF data in certain tiles.\n\n## Calling loaders inside loaders\n\nTo call another loader, a loader should use the appropriate `parse` function provided in the `context` parameter.\n\nA conceptual example of a 3D Tiles loader calling the `GLTFLoader` with some additional options.\n\n```js\nexport async function parse3DTile(arrayBuffer, options, context) {\n  const tile = {};\n  // Extract embedded GLB (if present) into `tile.gltfArrayBuffer`\n  ...\n  if (tile.gltfArrayBuffer) {\n    const {parse} = context;\n    tile.gltf = await parse(tile.gltfArrayBuffer, GLTFLoader, {\n      gltf: {...}\n    });\n  }\n}\n```\n\nRemarks:\n\n- While a loader could potentially import `parse` from `@loaders.gl/core` to invoke a sub-loader, it is discouraged, not only from a dependency management reasons, but it prevents loaders.gl from properly handling parameters and allow worker-loaders to call other loaders.\n","slug":"docs/developer-guide/creating-loaders-and-writers","title":"Creating New Loaders and Writers"},{"excerpt":"Managing Dependencies This section is work in progress, not all options are implemented/finalized Parsers and encoders for some formats are…","rawMarkdownBody":"# Managing Dependencies\n\n> This section is work in progress, not all options are implemented/finalized\n\nParsers and encoders for some formats are quite complex and can be quite big in terms of code size.\n\n### Loading Dependencies from Alternate CDN\n\nBy default, loaders.gl loads pre-built workers and a number of bigger external libraries from the [https://unpkg.com/](https://unpkg.com/) CDN.\n\nIt is possible to specify other CDNs using `options.cdn`.\n\nKeep in mind that it is typically not sufficient to point to a server that just serves the data of the files in question. Browsers do a number of security checks on cross-origin content and requires certain response headers to be properly set, and unfortunately, error messages are not always helpful.\n\nTo determine your candidate CDN service is doing what is needed, check with `curl -u <url>` and look for headers like:\n\n```\ncontent-type: application/javascript; charset=utf-8\naccess-control-allow-origin: *\n```\n\n### Loading Dependencies from Your Own Server\n\nBy setting `options.cdn: false` and doing some extra setup, you can load dependencies from your own server. This removes the impact of a potentially flaky CDN.\n\nOptions:\n\n- Load from `node_modules/@loaders.gl/<module>/dist/libs/...`\n- Load from a modules directory `libs/...`\n- Load from unique locations - `options.modules[<dependency name>]` can be set to url strings.\n\n### Bundling Dependencies\n\nIt is also possible to include dependencies in your application bundle\n\n- PRO: Doesn't require copying/configuring/serving supporting modules.\n- CON: Increases the size of your application bundle\n\n`options.modules` will let your application `import` or `require` dependencies (thus bundling them) and supply them to loaders.gl.\n\nSee each loader module for information on its dependencies.\n\nExample: bundling the entire `draco3d` library:\n\n```js\nimport draco from 'draco3d';\nimport {setLoaderOptions} from '@loaders.gl/core';\nsetLoaderOptions({\n  modules: {\n    draco3d\n  }\n});\n```\n","slug":"docs/developer-guide/dependencies","title":"Managing Dependencies"},{"excerpt":"Error Handling Applications typically want to provide solid error handling when loading and saving data. Ideally the applications wants to…","rawMarkdownBody":"# Error Handling\n\nApplications typically want to provide solid error handling when loading and saving data. Ideally the applications wants to use a simple clean API for the loading, and yet have the confidence that errors are caught and meaningful messages are presented to the user.\n\n## Types of Errors\n\nThere are tree main types of errors that arise when attempting to load a data resource:\n\n1. There is some kind of network/resource access error, preventing the request for data from being issued\n2. A request is sent to a server, but the server is unable to service the request due to some error condition (often illegal access tokens or request parameters) and sends an error response.\n3. The server returns data, but the parser is unable to parse it (perhaps due to the data being malformatted, or formatted according to an unsupported version of that format).\n\nloaders.gl can detect all of these error conditions and report the resulting errors in a unified way (the errors will be available as exceptions or rejected promises depending on your async programming style, see below).\n\n### Error Messages\n\nloaders.gl aims to prodice concise, easy-to-understand error messages that can be presented directly to the end user.\n\nWhen the fetch call fails, the genereted exception is passed to the user, and the same is true when a loader fails. For server error responses, some basic information about the error is compiled into an error message (using e.g. `response.status`, `response.url` and occasionally `response.text`).\n\nNote that while servers often send some information about errors in `response.text()` when setting HTTP error codes, there are no universally adhered-to conventions for how servers format those error messages. The data is often a set of key-value pairs that are JSON or XML encoded, but even then the exact key names are usually server-specific.\n\nAt the moment loaders.gl does not provide any error formatting plugins, so if you know how your specific service formats errors and want to extract these in a way that you can present to the user, you may want to take control of the fetch `Response` status checking, see below.\n\n## parse Error Handling\n\n`parse` accepts fetch `Response` objects, and `parse` will check the status of the `Response` before attempting to parse, and generate an exception if appropriate.\n\n## Handling Errors from Async Functions\n\nNote that `parse` is an async function, and in JavaScript, errors generated by async functions will be reported either as an exception or as a rejected promise, depending on how the async funtion was called (using promises or the `await` keyword):\n\nWhen using `await`, errors are reported as exceptions\n\n```js\ntry {\n  const response = await fetch(url);\n  const data = await parse(response);\n} catch (error) {\n  console.log(error);\n}\n```\n\nA rejected promise is generated when using `Promise.then`.\n\n```js\nfetch(url)\n  .then(response => parse(response))\n  .catch(error => console.log(error));\n```\n\nAlso note that the Javascript runtime seamlessly converts errors between exceptions and promises in mixed code.\n\n## fetch Error Handling\n\nloaders.gl is designed around the use of the modern JavaScript `fetch` API, so for additional context, it may help to review of how the JavaSctipt `fetch` function handles errors.\n\n`fetch` separates between \"network errors\" that can be detected directly (these cause the `fetch` to throw an exception) and server side errors that are reported asynchronously with HTTP status codes (in this case the `Response` object offers accessors that must be called to check if the operation was successful before accessing data).\n\nExample: \"manually\" checking separately for fetch network errors and server errors:\n\n```js\n// Check for network error\nlet response;\ntry {\n  response = await fetch(url);\n} catch (error) {\n  console.log('Network error');\n}\n\n// Check for server error\nif (!response.ok) {\n  console.log(`fetch failed with status ${response.status}`);\n}\n```\n\nNote that servers often sends a message providing some detail about what went wrong, and that message can be accessed using the standard (asynchronous) `response.text()` or `response.json()` methods.\n\n```js\nif (!response.ok) {\n  const errorMessage = await response.text();\n  // Custom parsing can be done here, if you know how your particular service formats errors\n  console.log(`fetch failed with status ${errorMessage}`);\n}\n```\n","slug":"docs/developer-guide/error-handling","title":"Error Handling"},{"excerpt":"Get Started Installing Install loaders.gl core and loader for any modules you would like to use. Each format is published as a separate npm…","rawMarkdownBody":"# Get Started\n\n## Installing\n\nInstall loaders.gl core and loader for any modules you would like to use.\n\nEach format is published as a separate npm module.\n\n```bash\nyarn add @loaders.gl/core\nyarn add @loaders.gl/gltf\n...\n```\n\n## Usage\n\nYou can import a loader and use it directly with `parse`. Note that `parse` can accept a `fetch` response object as the source of data to be parsed:\n\n```js\nimport {parse} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\nconst data = await parse(fetch('data.csv'), CSVLoader);\n```\n\nYou can register loaders after importing them\n\n```js\nimport {registerLoaders} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\nregisterLoaders(CSVLoader);\n```\n\nThen, in the same file (or some other file in the same app) that needs to load CSV, you no longer need to supply the loader to `parse`. It will autodetect the pre-registered loader:\n\n```js\nimport {parse} from '@loaders.gl/core';\n\n// The pre-registered CSVLoader gets auto selected based on file extension...\nconst data = await parse(fetch('data.csv'));\n```\n\n## Building\n\nYou can use your bundler of choice such as webpack or rollup. See the [`get-started-...`](https://github.com/uber-web/loaders.gl/tree/master/examples) examples for minimal working examples of how to bundle loaders.gl.\n\n## Supporting Older Browsers\n\nloaders.gl is designed to leverage modern JavaScript (ES2018) and to optimize functionality and performance on evergreen browsers.\n\nHowever, the default distribution is completely transpiled to ES5 so using loaders.gl with older or \"slower moving\" browsers such as IE11 and Edge is possible, assuming that the appropriate polyfills are installed.\n\nTo build on Edge and IE11, `TextEncoder` and `TextDecoder` must be polyfilled. There are several polyfills available on `npm`, but you can also use the polyfills provided by loaders.gl:\n\n```bash\nyarn install @loaders.gl/polyfills\n```\n\n```js\nimport '@loaders.gl/polyfills';\n```\n\n## Supporting Node.js\n\nA number of polyfills for `fetch`, `TextEncoder` etc are available to make loaders.gl work under Node.js, just install the `@loaders.gl/polyfills module` as described above.\n","slug":"docs/developer-guide/get-started","title":"Get Started"},{"excerpt":"Loader Categories To simplify working with multiple similar formats, loaders and writers in loaders.gl are grouped into categories. The idea…","rawMarkdownBody":"# Loader Categories\n\nTo simplify working with multiple similar formats, loaders and writers in loaders.gl are grouped into _categories_.\n\nThe idea is that many loaders return very similar data (e.g. point clouds loaders), which makes it possible to represent the loaded data in the same data structure, letting applications handle the output from multiple loaders without\n\nWhen a loader is documented as belonging to a specifc category, it converts the parsed data into the common format for that category. This allows an application to support multiple formats with a single code path, since all the loaders will return similar data structures.\n\n## Categories and Loader Registration\n\nThe fact that loaders belong to categories enable applications to flexibly register new loaders in the same category.\n\nFor instance, once an application has added support for one loader in a category, other loaders in the same category can be registered during application startup.\n\nOriginal code\n\n```js\nimport {parse, registerLoaders} from '@loaders.gl/core';\nimport {PCDLoader} from `@loaders.gl/pcd';\nregisterLoaders([PCDLoader]);\nasync function loadPointCloud(url) {\n  const pointCloud = await parse(fetch(url));\n  // Use some WebGL framework to render the parsed cloud\n}\n```\n\nNow support for additional point cloud formats can be added to the application without touching the original code:\n\n```js\nimport {LASLoader} from `@loaders.gl/las';\nimport {DracoLoader} from `@loaders.gl/draco';\nregisterLoaders([LASLoader, DracoLoader]);\n```\n\n## Data Format\n\nEach category documents the returned data format. loaders and writers reference the category documentation.\n\n## Writers and Categories\n\nWriters for a format that belongs to a category accept data objects with fields described by the documentation for that category.\n\n## Accessing Format-Specific Data\n\nSometimes, not all the properties provided by a certain file format can be mapped to common properties defined by the corresponding loader category.\n\nTo access format-specific properties, use the `loaderData` field in data object returned by the loader.\n\n## Available Categories\n\nCategories are described in the specifications section. Some currently defined categories are:\n\n- [Table](/docs/specifications/category-table)\n- [PointCloud/Mesh](/docs/specifications/category-mesh)\n- [Scenegraph](/docs/specifications/category-scenegraph)\n- [GIS](/docs/specifications/category-gis)\n","slug":"docs/developer-guide/loader-categories","title":"Loader Categories"},{"excerpt":"Polyfills Older browsers (mainly Edge and IE11) as well as Node.js do not provide certain APIs (,  etc) that loaders.gl depends on. The good…","rawMarkdownBody":"# Polyfills\n\nOlder browsers (mainly Edge and IE11) as well as Node.js do not provide certain APIs (`TextEncoder`, `fetch` etc) that loaders.gl depends on.\n\nThe good news is that these APIs can be provided by the application using the [polyfill](<https://en.wikipedia.org/wiki/Polyfill_(programming)>) technique.\n\nWhile there are many good polyfill modules for these classes available on `npm`, to make the search for a version that is guaranteed to work with loaders.gl a little easier, the `@loaders.gl/polyfills` module is provided.\n\nTo install these polyfills, just `import` the polyfills module before start using loaders.gl.\n\n```js\nimport '@loaders.gl/polyfills';\nimport {parse} from '@loaders.gl/core';\n```\n\n## Combining with other Polyfills\n\nloaders.gl only installs polyfills if the corresponding global symbol is `undefined`. This means that if another polyfill is already installed when `@loaders.gl/polyfills` is imported, the other polyfill will remain in effect. Since most polyfill libraries work this way, applications can mix and match polyfills by ordering the polyfill import statements appropriately (but see the remarks below for a possible caveat).\n\n## Provided Polyfills\n\nSee [API Reference](/docs/api-reference/polyfills).\n\n## Remarks\n\nApplications should typically only install this module if they need to run under older environments. While the polyfills are only installed at runtime if the platform does not already support them, they will still be included in your application bundle, i.e. importing the polyfill module will increase your application's bundle size.\n\nWhen importing polyfills for the same symbol from different libraries, the import can depend on how the other polyfill is written. to control the order of installation, you may want to use `require` rather than `import` when importing `@loaders.gl/polyfills`. As a general rule, `import` statements execute before `require` statments.\n","slug":"docs/developer-guide/polyfills","title":"Polyfills"},{"excerpt":"Using Loaders loaders.gl has parser functions that use so called \"loaders\" to convert the raw data loaded from files into parsed objects…","rawMarkdownBody":"# Using Loaders\n\nloaders.gl has parser functions that use so called \"loaders\" to convert the raw data loaded from files into parsed objects. Each loader encapsulates a parsing function for one file format (or a group of related file formats) together with some metadata (like the loader name, common file extensions for the format etc).\n\n## Installing loaders\n\nloaders.gl provides a suite of pre-built loader objects packaged as scoped npm modules. The intention is that applications will install and import loaders only for the formats they need.\n\n## Using Loaders\n\nLoaders are passed into utility functions in the loaders.gl core API to enable parsing of the chosen format.\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\ndata = await load(url, CSVLoader);\n// Application code here\n...\n```\n\n## Specifying and Registering Loaders\n\nAs seen above can be specified directly in a call to `load` or any of the `parse` functions:\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {PCDLoader} from '@loaders.gl/pcd';\nimport {LASLoader} from '@loaders.gl/las';\n\nconst pointCloud = await load(url, [PCDLoader, LASLoader]);\n\n// Application code here\n...\n```\n\nLoaders can also be registered globally. To register a loader, use `registerLoaders`:\n\n```js\nimport {registerLoaders, load} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nregisterLoaders([CSVLoader]);\n\ndata = await load('url.csv'); // => CSVLoader selected from pre-registered loaders\n```\n\n## Selecting Loadera\n\nThe loader selection algorithm is exposed to applications via `selectLoader`:\n\n```js\nimport {selectLoader} from '@loaders.gl/core';\nimport {ArrowLoader} from '@loaders.gl/arrow';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nselectLoader([ArrowLoader, CSVLoader], 'filename.csv'); // => CSVLoader\n```\n\nNote: Selection works on urls and/or data\n\n## Loader Options\n\n`load`, `parse` and other core functions accept loader options in the form of an options object.\n\n```js\nparse(data, Loader, {...options});\n```\n\nSuch loader options objects are organized into nested sub objects, with one sub-object per loader or loader category. This provides a structured way to pass options to multiple loaders.\n\n```js\nload(url, {\n  json: {...},\n  csv: {...},\n  '3d-tiles': {...},\n  gltf: {...}\n});\n```\n\nAn advantage of this design is that since the core functions can select a loader from a list of multiple candidate loaders, or invoke sub-loaders, the nested options system allows separate specification of options to each loader in a single options object.\n\nLoader options are merged with default options using a deep, two-level merge. Any object-valued key on the top level will be merged with the corresponding key value in the default options object.\n\n## Using Composite Loaders\n\nloaders.gl enables the creation of _composite loaders_ that call other loaders (referred to as \"sub-loaders\" in this section). This enables loaders for \"composite formats\" to be quickly composed out of loaders for the primitive parts.\n\nComposite Loader usage is designed to be conceptually simple for applications (loaders.gl handles a number of subtleties under the hood).\n\nA composite loader is called just like any other loader, however there are some additional\n\n### Parameter Passing between Loaders\n\nLoaders and parameters are passed through to sub loaders and are merged so that applications can override them:\n\n```js\n  parse(data, [Tiles3DLoader, GLTFLoader, DracoLoader], {\n    '3d-tiles': {\n      ...\n    },\n    gltf: {\n      ...\n    }\n  });\n```\n\nIn this example:\n\n- the passed in loaders would override any loaders specified inside the sub-loaders as well as any globally registered loaders.\n- The options will be passed through to the sub-loaders, so that the `GLTFLoader` will receive the `gltf` options, merged with any `gltf` options set by the `Tiles3DLoader`.\n\nThis override system makes it easy for applications to test alternate sub-loaders or parameter options without having to modify any existing loader code.\n","slug":"docs/developer-guide/using-loaders","title":"Using Loaders"},{"excerpt":"Using Worker Loaders By default, many loaders.gl loader modules do their parsing on JavaScript worker threads. This means that the main…","rawMarkdownBody":"## Using Worker Loaders\n\nBy default, many loaders.gl loader modules do their parsing on JavaScript worker threads. This means that the main thread will not block during parsing. Worker threads can also run in parallel, increasing your application's performance.\n\nFor more details on the advantages and complications with worker thread based loading the [Worker Threads](./using-worker-loaders.md) article in the concepts secion.\n\n## Loading Files in Parallel using Worker Loaders\n\nThe `DracoLoader` is worker enabled and uses worker threads by default. To load two Draco encoded meshes _in parallel_ on worker threads, just use the `DracoLoader` as follows:\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {DracoLoader} from '@loaders.gl/draco';\n\nasync function loadInParallel(url1, url2) {\n  const [data1, data2] = await Promise.all([load(url1, DracoLoader), load(url2, DracoLoader)]);\n}\n```\n\n## Disabling Worker Loaders\n\nApplications can use the `worker: false` option to disable worker loaders, for instance to simplify debugging of parsing issues:\n\n```js\nasync function loadwWithoutWorker(url1) {\n  const data = await load(url1, DracoLoader, {worker: false});\n}\n```\n\n## Concurrency Level\n\nConcurrency - The `options.maxConcurrency` parameter can be adjusted to define how many workers should be created for each format. Note that setting this higher than roughly the number CPU cores on your current machine will not provide much benefit and may create extra overhead.\n\n## ArrayBuffer Neutering\n\nBe aware that when calling worker loaders, binary data is transferred from the calling thread to the worker thread. This means that if you are using `parse`, any `ArrayBuffer` parameter you pass in to the will be \"neutered\" and no longer be accessible in the calling thread.\n\nMost applications will not need to do further processing on the raw binary data after it has been parsed so this is rarely an issue, but if you do, you may need to copy the data before parsing, or disable worker loading (see above).\n\n## Specifying Worker Script URLs (Advanced)\n\nIn JavaScript, worker threads are loaded from separate scripts files and are typically not part of the main application bundle. For ease-of-use, loaders.gl provides a default set of pre-built worker threads which are published on loaders.gl npm distribution from `unpck.com` CDN (Content Delivery Network).\n\nAs an advanced option, it is possible to for application to specify alternate URLs for loading a pre-built worker loader instance.\n\nThis can be useful e.g. when building applications that cannot access CDNs or when creating highly customized application builds, or doing in-depth debugging.\n\n## Composite Loaders and Workers (Advanced)\n\nloaders.gl supports sub-loader invocation from worker loaders. This is somewhat experimental\n\nA worker loader starts a seperate thread with a javascript bundle that only contains the code for that loader, so a worker loader needs to call the main thread (and indirectly, potentially another worker thread with another worrker loader) to parse using a sub-loader, properly transferring data into and back from the other thread.\n\n## Debugging Worker Loaders (Advanced)\n\nDebugging worker loaders is tricky. While it is always possible to specify `options.worker: false` which helps in many situations, there are cases where the worker loader itself must be debugged.\n\nTBA - There is an ambition to provide better support for debugging worker loaders:\n\n- Pre-build non-minified versions of workers, and provide option to easily select those.\n- Let loaders.gl developers easily switch between CDN and locally built workers.\n- ...\n","slug":"docs/developer-guide/using-worker-loaders","title":" Using Worker Loaders"},{"excerpt":"AsyncIterators Streaming functionality in loaders.gl is built on the ES2018  concept. This page gives some background on AsyncIterator since…","rawMarkdownBody":"# AsyncIterators\n\nStreaming functionality in loaders.gl is built on the ES2018 `AsyncIterator` concept. This page gives some background on AsyncIterator since it is a recently introduced concept (at least as part of the JavaScript standard).\n\n## Availability\n\n`AsyncIterator` is a standard JavaScript ES2018 feature and is well supported by recent evergreen browsers and Node.js versions.\n\nThe `for await of` iteration syntax is supported as well as the babel transpiler.\n\n## Batched Parsing and Endcoding using AsyncIterators\n\nThe input and output from streaming loaders and writers can both be expressed in terms of async iterators.\n\n## Using AsyncIterator\n\nRemember tyhat an async iterator can be consumed (iterated over) via the for-await construct:\n\n```js\nfor await (const x of asyncIterable) {}\n```\n\n## Using Streams as AsyncIterators\n\nWith a little effort, streams in JavaScript can be treated as AsyncIterators. As the section about [Javascript Streams](docs/developer-guide/streams.md) explains, instead of registering callbacks on the stream, you can now work with streams in this way:\n\n```js\nfor await (const buf of fs.createReadStream('foo.txt')) {\n  // do something\n}\n```\n\n## Creating AsyncIterators\n\nRemember that any object in JavaScript that implements the `[Symbol.asyncIterator]()` method is an `AsyncIterable`. And the async generator syntax can be used to generate new async iterators\n\n```js\nasync function* asyncIterator() {\n  yield new Promise(...)\n}\n\nfor await (const x of asyncIterator()) {} // Notice parens after 'asyncIterator'\n```\n","slug":"docs/developer-guide/concepts/async-iterators","title":"AsyncIterators"},{"excerpt":"Using Writers Writers and the  functions are available for use, however they are considere experimental. They rae still in development, and…","rawMarkdownBody":"# Using Writers\n\n> Writers and the `encode` functions are available for use, however they are considere experimental. They rae still in development, and may still have issues.\n\nWriters allow applications to generate properly formatted data for a number of the formats supported by loaders.gl.\n\n> Not all formats have writers.\n\nFor a detailed specification of the writer object format see the [API reference](docs/specifications/writer-object-format.md).\n\n## Usage\n\nAs an example, to Draco-compress a mesh using the `DracoWriter`:\n\n```js\nimport {DracoWriter} from '@loaders.gl/draco';\nimport {encode} from '@loaders.gl/core';\n\nconst mesh = {\n  attributes: {\n    POSITION: {...}\n  }\n};\n\nconst data = await encode(mesh, DracoWriter, options);\n```\n\n## Input Data\n\n_Writers_ accept the same format of data that is produced by the corresponding loaders. This format is documented either in each loader or usually as part of the documentation for that loader category.\n\nIf applications have data in a different format, they will need to first transform the data to the format expected by the _writer_.\n","slug":"docs/developer-guide/using-writers","title":"Using Writers"},{"excerpt":"Streaming Streaming support in loaders.gl is a work-in-progress. The ambition is that many loaders would support streaming from both Node…","rawMarkdownBody":"# Streaming\n\n> Streaming support in loaders.gl is a work-in-progress. The ambition is that many loaders would support streaming from both Node and DOM streams, through a consistent API and set of conventions (for both applications and loader/writer objects).\n\n## Streaming Loads\n\n### Incremental Parsing\n\nSome loaders offer incremental parsing (chunks of incomplete data can be parsed, and updates will be sent after a certain batch size has been exceeded). In many cases, parsing is fast compared to loading of data, so incremental parsing on its own may not provide a lot of value for applications.\n\n### Incremental Loading\n\nIncremental parsing becomes more interesting when it can be powered by incremental loading, whether through request updates or streams (see below).\n\n### Streamed Loading\n\nStreamed loading means that the entire data does not need to be loaded.\n\nThis is particularly advantageous when:\n\n- loading files with sizes that exceed browser limits (e.g. 1GB in Chrome)\n- doing local processing to files (tranforming one row at a time), this allows pipe constructions that can process files that far exceed internal memory.\n\n## Batched Updates\n\nFor incemental loading and parsing to be really effective, the application needs to be able to deal efficiently with partial batches as they arrive. Each loader category (or loader) may define a batch update conventions that are appropriate for the format being loaded.\n\n## Streaming Writes\n\nTBA\n\n## Node Streams vs DOM Streams\n\nStream support is finally arriving in browsers, however DOM Streams have a slightly different API than Node streams and the support across browsers is still spotty.\n\n## Polyfills\n\nStream support across browsers can be somewhat improved with polyfills. TBA\n\n## Stream Utilities\n\n- Stream to memory, ...\n- Automatically create stream if loader/writer only supports streaming\n- ...\n","slug":"docs/developer-guide/concepts/streaming","title":"Streaming"},{"excerpt":"Worker Threads On modern browsers, many loaders.gl loaders are set up to run on JavaScript worker threads. (Refer the documentation of each…","rawMarkdownBody":"# Worker Threads\n\nOn modern browsers, many loaders.gl loaders are set up to run on JavaScript worker threads. (Refer the documentation of each loader to see if it supports worker thread loading).\n\nLoading and parsing of data on worker threads can bring significant advantages\n\n- **Avoid blocking the browser main thread** - when parsing longer files, the main thread can become blocked, effectively \"freezing\" the application's user interface until parsing completes.\n- **Parallel parsing on multi-core CPUs** - when parsing multiple files on machines that have multiple cores (essentially all machines, even modern mobile phones tend to have at least two cores), worker threads enables multiple files to be parsed in parallel which can dramatically reduce the total load times.\n\nHoever, there are a number of considerations when loading and parsing data on JavaScript worker threads:\n\n- **Serialization/deserializion overhead** when transferring resuls back to main thread can more than defeat gains from loading on a separate thread.\n- **Choice of Data Types** - Due to data transfer issues there are constraints on what data types are appropriate\n- **Build configuration** - Workers can require complex build system setup/configuration.\n- **Message Passing** - Parsing on workers requires message passing between threads. While simple it can add clutter to application code.\n- **Debugging** - Worker based code tends to be harder to debug. Being able to easily switch back to main thread parsing (or an alternate worker build) can be very helpful.\n- **Startup Times** - Worker startup times can defeat speed gains from parsing on workers.\n\n## Data Transfer\n\nThreads cannot share non-binary data structures and these have to be serialized/deserialized. This is a big issue for worker thread based loading as the purpose of loaders is typically to load and parse big datastructures, and main thread deserialization times are often comparable to or even exceed the time required to parse the data in the first place, defeating the value of moving parsing to a worker thread.\n\nThe solution is usually to use data types that support ownership transfer (see next section) as much as possible and minimize the amount of non-binary data returned from the parser.\n\n## Data Types\n\nJavaScript ArrayBuffers and Typed Arrays can be passed with minimal overhead (ownership transfer) and the value of worker based parsing usually depends on whether the loaded data can (mostly) be stored in these types.\n\n## Message Passing\n\nloaders.gl will handle message passing behind the scenes. Loading on a worker thread returns a promise that completes when the worker is done and the data has been transferred back to the main thread.\n\n## Build Configuration\n\nAll worker enabled loaders come with a pre-built, minimal worker \"executable\" to enable zero-configuration use in applications.\n\n## Bundle size concerns\n\nAll worker enabled loaders provide separate loader objects to ensure that tree-shaking bundlers will be able to remove the code for the unused case.\n\n## Debugging and Benchmarking\n\nLoaders.gl offers loader objects for main thread and worker threads. A simple switch lets you move your loading back to the main thread for easier debugging and benchmarking (comparing speeds to ensure you are gaining the benefits you expect from worker thread based loading).\n","slug":"docs/developer-guide/concepts/worker-threads","title":"Worker Threads"},{"excerpt":"Binary Data The loaders.gl API consistently uses s to represent and transport binary data. Why ArrayBuffers? One of the design goals of…","rawMarkdownBody":"# Binary Data\n\nThe loaders.gl API consistently uses `ArrayBuffer`s to represent and transport binary data.\n\n## Why ArrayBuffers?\n\nOne of the design goals of loaders.gl is to provide applications with a single, consistent API that works across (reasonably modern) browsers, worker threads and Node.js. One of the characteristics of this API is how binary data is represented.\n\nloaders.gl \"standardizes\" on ArrayBuffers for a number of reasons:\n\n- ArrayBuffers are the \"canonical\" input format for the WebGL API, allowing efficient uploads of large binary data sets to the GPU.\n- ArrayBuffers allow ownership to be transferred between threads (Browser Main Thread and WebWorkers), massively improving performance when sending data back from loaders running on web worker to the application/main thread.\n- ArrayBuffers are used to transport raw data in most newer JavaScript APIs, including WebSockets, Web Intents, XMLHttpRequest version 2 etc.\n- ArrayBuffers are well supported by recent Node.js versions, in fact the traditional Node.js `Buffer` class is now backed by an `ArrayBuffer`.\n\n## ArrayBuffers and Typed Arrays\n\nRecall that typed arrays (e.g. `Float32Array`) are just views into array buffers. Every typed array has a `buffer` reference.\n\nMany loaders.gl functions directly accept typed arrays, which essentially means they accept the associated ArrayBuffer. However, be aware that typed arrays can represent partial views (i.e. they can have offsets) that sometimes need special handling in the application.\n\n## Converting between ArrayBuffers and Strings\n\nWe use the `TextEncoder` and `TextDecoder` classes in the JavaScript [string encoding/decoding library](https://github.com/inexorabletash/text-encoding).\n\nSince these classes are central to using ArrayBuffers correctly, loaders.gl provides polyfills for them under Node.js.\n\n## Binary Types in JavaScript\n\nBinary data types in JS:\n\n- `ArrayBuffer`\n- `Uint8Array` and other typed arrays, plus\n- `DataView`\n- `Blob`\n- `Buffer` nodejs\n\nExamples of \"semi-binary\" data types in JS:\n\n- `Array`: Array of bytes (elements are numbers between 0 and 255).\n- `String` (binary): string in “binary” form, 1 byte per char (2 bytes).\n- `String` (base64): string containing the binary data encoded in a base64 form.\n\n## Converting between ArrayBuffers and other Binary Formats.\n\nStandardizing on ArrayBuffers helps streamline the loaders.gl API. But occasionally applications need to interface with APIs that accept other binary data types/formats. To support this case, loaders.gl provides a small set of utilities (non-exhaustive) for converting from and to other binary JavaScript types/formats, e.g. `toArrayBuffer`:\n","slug":"docs/developer-guide/concepts/binary-data","title":"Binary Data"},{"excerpt":"@loaders.gl/wkt This module contains a geometry loader for the WKT (Well-Known Text) format. loaders.gl is a collection of framework…","rawMarkdownBody":"# @loaders.gl/wkt\n\nThis module contains a geometry loader for the WKT (Well-Known Text) format.\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent visualization-focused loaders (parsers).\n","slug":"modules/wkt","title":"@loaders.gl/wkt"},{"excerpt":"Overview The  module handles compressing and decompressing of the ZIP format. Installation Attributions ZipLoader is a wrapper around the…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/zip` module handles compressing and decompressing of the [ZIP](<https://en.wikipedia.org/wiki/Zip_(file_format)>) format.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/zip\n```\n\n## Attributions\n\nZipLoader is a wrapper around the [JSZip module](https://stuk.github.io/jszip/). JSZip has extensive documentation on options (and more functionality than this loader object can expose).\n","slug":"modules/zip/docs","title":"Overview"},{"excerpt":"@loaders.gl/zip loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loaders and…","rawMarkdownBody":"# @loaders.gl/zip\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loaders and writers for the Zip Archive format.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/zip","title":"@loaders.gl/zip"},{"excerpt":"@loaders.gl/tiles (Experimental) This module contains the common components for tiles loaders, i.e. 3D tiles. loaders.gl is a collection of…","rawMarkdownBody":"# @loaders.gl/tiles (Experimental)\n\nThis module contains the common components for tiles loaders, i.e. [3D tiles](https://github.com/AnalyticalGraphicsInc/3d-tiles).\n\n[loaders.gl](https://loaders.gl/docs) is a collection of loaders for big data visualizations.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/tiles","title":"@loaders.gl/tiles (Experimental)"},{"excerpt":"@loaders.gl/terrain loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module reconstructs…","rawMarkdownBody":"# @loaders.gl/terrain\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module reconstructs mesh surfaces from height map images, e.g. [Mapzen Terrain Tiles](https://github.com/tilezen/joerd/blob/master/docs/formats.md), which encodes elevation into R,G,B values.\n\nFor documentation please visit the [website](https://loaders.gl).\n\n`@loaders.gl/terrain` uses [MARTINI](https://github.com/mapbox/martini) for mesh reconstruction.\n\nISC License\n\nCopyright (c) 2019, Mapbox\n\nPermission to use, copy, modify, and/or distribute this software for any purpose\nwith or without fee is hereby granted, provided that the above copyright notice\nand this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS\nOF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER\nTORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF\nTHIS SOFTWARE.\n","slug":"modules/terrain","title":"@loaders.gl/terrain"},{"excerpt":"@loaders.gl/wkt The  module handles the the Well Known Text, an ASCII format that defines geospatial geometries. Installation Loaders and…","rawMarkdownBody":"# @loaders.gl/wkt\n\nThe `@loaders.gl/wkt` module handles the the [Well Known Text](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry), an ASCII format that defines geospatial geometries.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/wkt\nnpm install @loaders.gl/core\n```\n\n## Loaders and Writers\n\n| Loader                                                   |\n| -------------------------------------------------------- |\n| [`WKTLoader`](modules/wkt/docs/api-reference/wkt-loader) |\n| [`WKTWriter`](modules/wkt/docs/api-reference/wkt-writer) |\n\n## Attribution\n\nThe `WKTLoader` is based on a fork of the Mapbox [`wellknown`](https://github.com/mapbox/wellknown) module under the ISC license (MIT/BSD 2-clause equivalent).\n","slug":"modules/wkt/docs","title":"@loaders.gl/wkt"},{"excerpt":"@loaders.gl/tables This module contains: Classes and APIs for manipulating tabular data output from loaders.gl table category loaders (CSV…","rawMarkdownBody":"# @loaders.gl/tables\n\nThis module contains:\n\n- Classes and APIs for manipulating tabular data output from loaders.gl table category loaders (CSV, JSON, ...).\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nPlease visit the [website](https://loaders.gl).\n","slug":"modules/tables","title":"@loaders.gl/tables"},{"excerpt":"ZipWriter Encodes a filemap into a Zip Archive. Returns an  that is a valid Zip Archive and can be written to file. Loader Characteristic…","rawMarkdownBody":"# ZipWriter\n\nEncodes a filemap into a Zip Archive. Returns an `ArrayBuffer` that is a valid Zip Archive and can be written to file.\n\n| Loader         | Characteristic                                                   |\n| -------------- | ---------------------------------------------------------------- |\n| File Extension | `.zip`                                                           |\n| File Type      | Binary                                                           |\n| Data Format    | \"File Map\"                                                       |\n| File Format    | [ZIP Archive](<https://en.wikipedia.org/wiki/Zip_(file_format)>) |\n| Encoder Type   | Asynchronous                                                     |\n| Worker Thread  | No                                                               |\n| Streaming      | No                                                               |\n\n## Usage\n\n```js\nimport {encode, writeFile} from '@loaders.gl/core';\nimport {ZipWriter} from '@loaders.gl/zip';\n\nconst FILEMAP = {\n  filename1: arrayBuffer1,\n  'directory/filename2': ...\n};\n\nconst arrayBuffer = await encode(FILE_MAP, ZipWriter)\nwriteFile(zipFileName, arrayBuffer);\n```\n\n## File Format\n\nThe file map is an object with keys representing file names or relative paths in the zip file, and values being the contents of each sub file (either `ArrayBuffer` or `String`).\n\n## Options\n\nOptions are forwarded to [JSZip.generateAsync](https://stuk.github.io/jszip/documentation/api_jszip/generate_async.html), however type is always set to `arraybuffer` to ensure compatibility with writer driver functions in `@loaders.gl/core`.\n","slug":"modules/zip/docs/api-reference/zip-writer","title":"ZipWriter"},{"excerpt":"ZipLoader Decodes a Zip Archive into a file map. Loader Characteristic File Extension  File Type Binary File Format ZIP Archive Data Format…","rawMarkdownBody":"# ZipLoader\n\nDecodes a Zip Archive into a file map.\n\n| Loader         | Characteristic                                                   |\n| -------------- | ---------------------------------------------------------------- |\n| File Extension | `.zip`                                                           |\n| File Type      | Binary                                                           |\n| File Format    | [ZIP Archive](<https://en.wikipedia.org/wiki/Zip_(file_format)>) |\n| Data Format    | \"File Map\"                                                       |\n| Decoder Type   | Asynchronous                                                     |\n| Worker Thread  | No                                                               |\n| Streaming      | No                                                               |\n\n## Usage\n\n```js\nimport {parse} from '@loaders.gl/core';\nimport {ZipLoader} from '@loaders.gl/zip';\n\nconst fileMap = await parse(arrayBuffer, ZipLoader);\nfor (const fileName in FILE_MAP) {\n  const fileData = fileMap[key];\n  // Do something with the subfile\n}\n```\n\n## Data Format\n\nThe file map is an object with keys representing file names or relative paths in the zip file, and values being the contents of each sub file (either `ArrayBuffer` or `String`).\n\n## Options\n\nOptions are forwarded to [JSZip.loadAsync](https://stuk.github.io/jszip/documentation/api_jszip/load_async.html).\n","slug":"modules/zip/docs/api-reference/zip-loader","title":"ZipLoader"},{"excerpt":"@loaders.gl/potree (Experimental) This module contains loaders for the potree format. loaders.gl is a collection of framework independent 3D…","rawMarkdownBody":"# @loaders.gl/potree (Experimental)\n\nThis module contains loaders for the [potree](https://github.com/potree/potree) format.\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial loaders (parsers).\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/potree","title":"@loaders.gl/potree (Experimental)"},{"excerpt":"Overview  exposes handy classes  and  which can understand the loaded data from tile loaders (, , etc.), and provide useful functions for…","rawMarkdownBody":"# Overview\n\n`@loaders/tiles` exposes handy classes `Tileset3D` and `Tile3D` which can understand the loaded data from tile loaders (`@loaders.gl/3d-tiles`, `@loaders.gl/i3s`, etc.), and provide useful functions for dynamically selecting tiles for rendering under a viewport.\n\n## Concepts\n\n- [OGC 3D Tiles](https://www.opengeospatial.org/standards/3DTiles) standard\n- [OGC i3s](https://www.opengeospatial.org/standards/i3s) standard\n- **Tile Header Hierarchy** - An initial, \"minimal\" set of data listing the _hierarchy of available tiles_, with minimal information to allow an application to determine which tiles need to be loaded based on a certain viewing position in 3d space.\n- **Tile Header** - A minimal header describing a tiles bounding volume and a screen space error tolerance (allowing the tile to be culled if it is distant), as well as the URL to load the tile's actual content from.\n- **Tile Content** - The actual payload of the tile.\n- **Tile Cache** - Since the number of tiles in big tilesets often exceed what can be loaded into available memory, it is important to have a system that releases no-longer visible tiles from memory.\n- **Tileset Traversal** - Dynamically loading and rendering 3D tiles based on current viewing position, possibly triggering loads of new tiles and unloading of older, no-longer visible tiles.\n\n### Tileset3D Class\n\n#### Properties\n\n- `boundingVolume` (`BoundingVolume`): The root tile's bounding volume, which is also the bouding volume of the entire tileset. Check `Tile3DHeader#boundingVolume`\n- `cartesianCenter` (`Number[3]`): Center of tileset in fixed frame coordinates.\n- `cartographicCenter` (`Number[3]`): Center of tileset in cartographic coordinates `[long, lat, elevation]`\n- `ellipsoid` ([`Ellipsoid`](https://math.gl/modules/geospatial/docs/api-reference/ellipsoid)): Gets an ellipsoid describing the shape of the globe.\n- `maximumMemoryUsage` (`Number`): If tiles sized more than `maximumMemoryUsage` are needed to for the current view, when these tiles go out of view, they will be unloaded.`maximumMemoryUsage` must be greater than or equal to zero.\n- `modelMatrix` (`Matrix4: A [Matrix4](https://math.gl/modules/core/docs/api-reference/matrix4) instance (4x4 transformation matrix) that transforms the entire tileset.\n- `root` (`Tile3DHeader`): The root tile header.\n- tiles: Array<Tile3DHeader>: All the tiles that have been traversed.\n- `stats` ([`Stats`](https://uber-web.github.io/probe.gl/docs/api-reference/log/stats))): An instance of a probe.gl `Stats` object that contains information on how many tiles have been loaded etc. Easy to display using a probe.gl `StatsWidget`.\n- `tileset` (`Object`): The original tileset data this object instanced from.\n- `tilesLoaded` (`Boolean`): When `true`, all tiles that meet the screen space error this frame are loaded. The tileset is completely loaded for this view.\n- `gpuMemoryUsageInBytes` (`Number`): The total amount of GPU memory in bytes used by the tileset. This value is estimated from geometry, texture, and batch table textures of loaded tiles. For point clouds, this value also includes per-point metadata.\n- `url` (`String`): The url to a tileset JSON file.\n- `zoom` (`Number[3]`): A web mercator zoom level that displays the entire tile set bounding volume\n\n#### Methods\n\n- `constructor(tileset : Object, url : String [, options : Object])`\n  - `tileset`: The loaded tileset (parsed JSON). See [Tileset Object Format](#tileset-object).\n  - `options`: Options object, but not limited to\n    Parameters:\n    - `modelMatrix`=`Matrix4.IDENTITY` (`Matrix4`) - A 4x4 transformation matrix that transforms the tileset's root tile.\n    - `maximumMemoryUsage`=`512`] (`Number`) - The maximum amount of memory in MB that can be used by the tileset.\n    - `ellipsoid`=`Ellipsoid.WGS84` ([`Ellipsoid`](https://math.gl/modules/geospatial/docs/api-reference/ellipsoid)) - The ellipsoid determining the size and shape of the globe.\n      Callbacks:\n    - `onTileLoad` (`(tileHeader : Tile3DHeader) : void`) - callback when a tile node is fully loaded during the tileset traversal.\n    - `onTileUnload` (`(tileHeader : Tile3DHeader) : void`) - callback when a tile node is unloaded during the tileset traversal.\n    - `onTileError` (`(tileHeader : Tile3DHeader, message : String) : void`) - callback when a tile faile to load during the tileset traversal.\n- `update(viewport: WebMercatorViewport) : Number`: Execute traversal under current viewport and fetch tiles needed for current viewport and update `selectedTiles`. Return `frameNumber` of this update frame.\n- `destroy() : void`: Destroys the WebGL resources held by this object, and destroy all the tiles' resources by recursively traversing the tileset tree.\n\n### Tile3D Class\n\n#### Properties\n\n- `boundingVolume` (`BoundingVolume`): A bounding volume that encloses a tile or its content. Exactly one box, region, or sphere property is required. ([`Reference`](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#bounding-volume))\n- `id` (`Number`|`String`): A unique number for the tile in the tileset. Default to the url of the tile.\n- `contentState` (`String`): Indicate of the tile content state. Available options\n  - `UNLOADED`: Has never been requested or has been destroyed.\n  - `LOADING`: Is waiting on a pending request.\n  - `PROCESSING`: Contents are being processed for rendering. Depending on the content, it might make its own requests for external data.\n  - `READY`: All the resources are loaded and decoded.\n  - `FAILED`: Request failed.\n- `contentType` (`String`): One of\n  - `empty`: does not have any content to render\n  - `render`: has content to render\n  - `tileset`: tileset tile\n- `depth` (`Number`): The depth of the tile in the tileset tree.\n- `content` (`Object`): The tile's content.This represents the actual tile's payload.\n- `type` (`String`): One of `scenegraph`, `pointcloud`, `mesh`\n- `parent` (`Tile3DHeader`): Parent of this tile.\n- `refine` (`String`): Specifies the type of refine that is used when traversing this tile for rendering. [`Reference`](https://github.com/AnalyticalGraphicsInc/3d-tiles/blob/master/specification/README.md#refinement)\n  - `ADD`: high-resolution children tiles should be rendered in addition to lower-resolution parent tiles when level of details of parent tiles are not sufficient for current view.\n  - `REPLACEMENT`: high-resolution children tiles should replace parent tiles when lower-resolution parent tiles are not sufficient for current view.\n- `selected` (`Boolean`): Whether this tile is selected for rendering in current update frame and viewport. A selected tile should has its content loaded and satifies current viewport.\n- `tileset` (`Tileset3D`): The `Tileset3D` instance containing this tile.\n- `header` (`Object`): The unprocessed tile header object passed in.\n\n#### Methods\n\n- `constructor(tileset : Object, header : Object, parentHeader : Object)`\n  - `tileset`: The loaded tileset (parsed JSON)\n  - `header`: The loaded tile header file. See [Tile Object Format](#tile-object).\n  - `parentHeader`: The loaded parent file.\n- `destroy()`: Destroy the tile node, including destroy all the metadata and unload content.\n- `loadContent()`: Load a content of the tile.\n- `unloadContent()`: Unload a content of the tile.\n\n## Data Format\n\nThis section specifies the unified data formats from tileset loader and tile loader.\n\n### Tileset Object\n\nThe following fields are guaranteed. But different tileset loaders may have different extra fields.\n\n| Field  | Type     | Contents                                                                      |\n| ------ | -------- | ----------------------------------------------------------------------------- |\n| `root` | `Object` | The root tile header object                                                   |\n| `url`  | `Object` | The root tile header object                                                   |\n| `type` | `String` | Indicate the type of tileset specification, `3d-tiles`, `i3s`, `potree`, etc. |\n\n### Tile Object\n\nThe following fields are guaranteed. But different tile loaders may have different extra fields.\n\n| Field             | Type         | Contents                                                                                                                                                                                                                                                                                                                            |\n| ----------------- | ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `boundingVolume`  | `Object`     | A bounding volume that encloses a tile or its content. Exactly one box, region, or sphere property is required. ([`Reference`](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#bounding-volume))                                                                                                        |\n| `children`        | `Array`      | An array of objects that define child tiles. Each child tile content is fully enclosed by its parent tile's bounding volume and, generally, has more details than parent. for leaf tiles, the length of this array is zero, and children may not be defined.                                                                        |\n| `content`         | `String`     | The actual payload of the tile or the url point to the actual payload.                                                                                                                                                                                                                                                              |\n| `id`              | `String`     | Identifier of the tile, unique in a tileset                                                                                                                                                                                                                                                                                         |\n| `lodSelection`    | `Object`     | Used for deciding if this tile is sufficient given current viewport. Cesium tile use [`geometricError`](https://github.com/AnalyticalGraphicsInc/3d-tiles/blob/master/specification/README.md#geometric-error), `i3s` uses [`metricType` and `maxError`](https://github.com/Esri/i3s-spec/blob/master/docs/1.7/lodSelection.cmn.md) |\n| `refine`          | `String`     | Refinement type of the tile, `ADD` or `REPLACE`                                                                                                                                                                                                                                                                                     |\n| `type`            | `String`     | Type of the tile, one of `pointcloud`, `scenegraph`, `mesh`                                                                                                                                                                                                                                                                         |\n| `transformMatrix` | `Number[16]` | A matrix that transforms from the tile's local coordinate system to the parent tile's coordinate system—or the tileset's coordinate system in the case of the root tile                                                                                                                                                             |  |\n\n### Tile Content\n\nAfter content is loaded, the following fields are guaranteed. But different tiles may have different extra content fields.\n\n| Field                | Type         | Contents                                                                                                                               |\n| -------------------- | ------------ | -------------------------------------------------------------------------------------------------------------------------------------- |\n| `cartesianOrigin`    | `Number[3]`  | \"Center\" of tile geometry in WGS84 fixed frame coordinates                                                                             |\n| `cartographicOrigin` | `Number[3]`  | \"Origin\" in lng/lat (center of tile's bounding volume)                                                                                 |\n| `modelMatrix`        | `Number[16]` | Transforms tile geometry positions to fixed frame coordinates                                                                          |\n| `attributes`         | `Object`     | Each attribute follows luma.gl [accessor](https://github.com/uber/luma.gl/blob/master/docs/api-reference/webgl/accessor.md) properties |\n\n`attributes` contains following fields\n\n| Field                  | Type     | Contents                          |\n| ---------------------- | -------- | --------------------------------- |\n| `attributes.positions` | `Object` | `{value, type, size, normalized}` |\n| `attributes.normals`   | `Object` | `{value, type, size, normalized}` |\n| `attributes.colors`    | `Object` | `{value, type, size, normalized}` |\n\nPointCloud Fields\n\n| Field        | Type                       | Contents                                                 |\n| ------------ | -------------------------- | -------------------------------------------------------- |\n| `pointCount` | `Number`                   | Number of points                                         |\n| `color`      | `Number[3]` or `Number[4]` | Color of the tile when there are not `attributes.colors` |\n\nScenegraph Fields\n\n| Field  | Type     | Contents                                                                                             |\n| ------ | -------- | ---------------------------------------------------------------------------------------------------- |\n| `gltf` | `Object` | check [GLTFLoader](https://loaders.gl/modules/gltf/docs/api-reference/gltf-loader) for detailed spec |\n\nSimpleMesh Fields\n\n| Field     | Type | Contents              |\n| --------- | ---- | --------------------- |\n| `texture` | URL  | url of tile's texture |\n\n## Additional Information\n\n### Coordinate Systems\n\nTo help applications process the `position` data in the tiles, 3D Tiles category loaders are expected to provide matrices are provided to enable tiles to be used in both fixed frame or cartographic (long/lat-relative, east-north-up / ENU) coordinate systems:\n\n- _cartesian_ WGS84 fixed frame coordinates\n- _cartographic_ tile geometry positions to ENU meter offsets from `cartographicOrigin`.\n\nPosition units in both cases are in meters.\n\nFor cartographic coordinates, tiles come with a prechosen cartographic origin and precalculated model matrix. This cartographic origin is \"arbitrary\" (chosen based on the tiles bounding volume center). A different origin can be chosen and a transform can be calculated, e.g. using the math.gl `Ellipsoid` class.\n","slug":"modules/tiles/docs","title":"Overview"},{"excerpt":"WKTLoader Loader and writer for the Well-known text format for representation of geometry. Loader Characteristic File Extension , File Type…","rawMarkdownBody":"# WKTLoader\n\nLoader and writer for the [Well-known text] format for representation of geometry.\n\n| Loader         | Characteristic                                                                              |\n| -------------- | ------------------------------------------------------------------------------------------- |\n| File Extension | `.wkt`,                                                                                     |\n| File Type      | Text                                                                                        |\n| File Format    | [Well Known Text](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) |\n| Data Format    | [Geometry](/docs/specifications/category-gis)                                               |\n| Supported APIs | `load`, `parse`, `parseSync`                                                                |\n\n## Usage\n\n```js\nimport {WKTLoader} from '@loaders.gl/wkt';\nimport {parseSync} from '@loaders.gl/core';\n\nconst data = parseSync('LINESTRING (30 10, 10 30, 40 40)', WKTLoader);\n// => {type: 'LineString', coordinates: [[30, 10], [10, 30], [40, 40]]}\n```\n\n```js\nimport {WKTLoader} from '@loaders.gl/wkt';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, WKTLoader);\n```\n\n## Options\n\nN/A\n\n## Attribution\n\nThe `WKTLoader` is based on a fork of the Mapbox [`wellknown`](https://github.com/mapbox/wellknown) module under the ISC license (MIT/BSD 2-clause equivalent).\n","slug":"modules/wkt/docs/api-reference/wkt-loader","title":"WKTLoader"},{"excerpt":"WKTWriter Writer for the Well-known text format for representation of geometry. Loader Characteristic File Extension , File Type Text File…","rawMarkdownBody":"# WKTWriter\n\nWriter for the [Well-known text] format for representation of geometry.\n\n| Loader         | Characteristic                                                                              |\n| -------------- | ------------------------------------------------------------------------------------------- |\n| File Extension | `.wkt`,                                                                                     |\n| File Type      | Text                                                                                        |\n| File Format    | [Well Known Text](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) |\n| Data Format    | [Geometry](/docs/specifications/category-gis)                                               |\n| Supported APIs | `encode`, `encodeSync`                                                                      |\n\n## Usage\n\n```js\nimport {WKTWriter} from '@loaders.gl/wkt';\n```\n\n## Options\n\nN/A\n\n## Attribution\n\nThe `WKTWriter` is based on a fork of the Mapbox [`wellknown`](https://github.com/mapbox/wellknown) module under the ISC license (MIT/BSD 2-clause equivalent).\n","slug":"modules/wkt/docs/api-reference/wkt-writer","title":"WKTWriter"},{"excerpt":"@loaders.gl/polyfills loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains…","rawMarkdownBody":"# @loaders.gl/polyfills\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains polyfills for running on older browsers (mainly Edge and IE11) as well as Node.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/polyfills","title":"@loaders.gl/polyfills"},{"excerpt":"Overview The  module reconstructs mesh surfaces from height map images, e.g. Mapzen Terrain Tiles, which encodes elevation into R,G,B values…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/terrain` module reconstructs mesh surfaces from height map images, e.g. [Mapzen Terrain Tiles](https://github.com/tilezen/joerd/blob/master/docs/formats.md), which encodes elevation into R,G,B values.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/terrain\nnpm install @loaders.gl/core\n```\n\n## Attribution\n\n`@loaders.gl/terrain` uses [MARTINI](https://github.com/mapbox/martini) for mesh reconstruction.\n\nISC License\n\nCopyright (c) 2019, Mapbox\n\nPermission to use, copy, modify, and/or distribute this software for any purpose\nwith or without fee is hereby granted, provided that the above copyright notice\nand this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS\nOF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER\nTORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF\nTHIS SOFTWARE.\n","slug":"modules/terrain/docs","title":"Overview"},{"excerpt":"@loaders.gl/ply loaders.gl is a collection of loaders for big data visualizations. This module contains loaders for the PLY format. For…","rawMarkdownBody":"# @loaders.gl/ply\n\n[loaders.gl](https://loaders.gl/docs) is a collection of loaders for big data visualizations.\n\nThis module contains loaders for the PLY format.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/ply","title":"@loaders.gl/ply"},{"excerpt":"@loaders.gl/pcd loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loaders for…","rawMarkdownBody":"# @loaders.gl/pcd\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loaders for the PCD format.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/pcd","title":"@loaders.gl/pcd"},{"excerpt":"@loaders.gl/obj loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loader for…","rawMarkdownBody":"# @loaders.gl/obj\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loader for the OBJ format.\n\nFor documentation please visit the [website](https://loaders.gl).\n\nNote: The OBJ parser in this module is a port of [three.js](https://github.com/mrdoob/three.js)'s OBJLoader.\n\nThe MIT License\n\nCopyright © 2010-2019 three.js authors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n","slug":"modules/obj","title":"@loaders.gl/obj"},{"excerpt":"Working with Tables The loaders.gl table category provides support for working interchangably with row-oriented and columnar tables.","rawMarkdownBody":"# Working with Tables\n\nThe loaders.gl table category provides support for working interchangably with row-oriented and columnar tables.\n","slug":"modules/tables/docs/table-guide","title":"Working with Tables"},{"excerpt":"@loaders.gl/tables Table Table APIs The table API is modelled after a subset of the Apache Arrow API: Class Arrow Counterpart Description…","rawMarkdownBody":"# @loaders.gl/tables\n\n> Table\n\n## Table APIs\n\nThe table API is modelled after a subset of the Apache Arrow API:\n\n| Class                                                              | Arrow Counterpart | Description  |\n| ------------------------------------------------------------------ | ----------------- | ------------ |\n| [`Table`](modules/tables/docs/api-reference/table.md)              | Table             | Table        |\n| [`TableSchema`](modules/tables/docs/api-reference/table-schema.md) | `Schema`          | Table schema |\n| [`TableBatch`](modules/tables/docs/api-reference/table-batch.md)   | `RecordBatch`     | Table batch  |\n\n## Micro-Loaders\n\nLoaders with limited functionality but with minimal bundle size impact:\n\n| Loader       | Description                                                                           |\n| ------------ | ------------------------------------------------------------------------------------- |\n| `JSONLoader` | A minimal non-streaming JSON loader that uses the built-in `JSON.parse` function      |\n| `XMLLoader`  | A non-streaming, browser-only XML loader that uses the browser's built-in DOM parser. |\n","slug":"modules/tables/docs","title":"@loaders.gl/tables"},{"excerpt":"@loaders.gl/mvt This module contains a geometry loader for Mapbox Vector Tiles (MVT). loaders.gl is a collection of framework independent…","rawMarkdownBody":"# @loaders.gl/mvt\n\nThis module contains a geometry loader for Mapbox Vector Tiles (MVT).\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent visualization-focused loaders (parsers).\n","slug":"modules/mvt","title":"@loaders.gl/mvt"},{"excerpt":"Tile3D The  class is used internally by   class to manage loading/unloading tiles. Constructor Paremeters:  (Tileset3D) -  instance which…","rawMarkdownBody":"# Tile3D\n\n> The `Tile3D` class is used internally by `loaders.gl/tiles` `Tileset3D` class to manage loading/unloading tiles.\n\n## Constructor\n\n```js\nnew Tile3D(tileset, header, parentHeader);\n```\n\nParemeters:\n\n- `tileset` (Tileset3D) - `Tileset3D` instance which contains this tile\n- `header` (Tile3D) - `Tile3D` instance\n- `parentHeader` (Tile3D) - `Tile3D` instance of parent tile\n\n#### Properties\n\n###### `boundingVolume` (BoundingVolume)\n\nA bounding volume that encloses a tile or its content. Exactly one box, region, or sphere property is required. ([`Reference`](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#bounding-volume))\n\n###### `id` (Number`|`String)\n\nA unique number for the tile in the tileset. Default to the url of the tile.\n\n###### `contentState` (String)\n\nIndicate of the tile content state. Available options\n\n- `UNLOADED`: Has never been requested or has been destroyed.\n- `LOADING`: Is waiting on a pending request.\n- `PROCESSING`: Contents are being processed for rendering. Depending on the content, it might make its own requests for external data.\n- `READY`: All the resources are loaded and decoded.\n- `FAILED`: Request failed.\n\n###### `contentType` (String)\n\nOne of\n\n- `empty`: does not have any content to render\n- `render`: has content to render\n- `tileset`: tileset tile\n\n###### `depth` (Number)\n\nThe depth of the tile in the tileset tree.\n\n###### `content` (Object)\n\nThe tile's content.This represents the actual tile's payload.\n\n###### `type` (String)\n\nOne of `scenegraph`, `pointcloud`, `mesh`\n\n###### `parent` (Tile3DHeader)\n\nParent of this tile.\n\n###### `refine` (String)\n\nSpecifies the type of refine that is used when traversing this tile for rendering. [`Reference`](https://github.com/AnalyticalGraphicsInc/3d-tiles/blob/master/specification/README.md#refinement)\n\n- `ADD`: high-resolution children tiles should be rendered in addition to lower-resolution parent tiles when level of details of parent tiles are not sufficient for current view.\n- `REPLACEMENT`: high-resolution children tiles should replace parent tiles when lower-resolution parent tiles are not sufficient for current view.\n\n###### `selected` (Boolean)\n\nWhether this tile is selected for rendering in current update frame and viewport. A selected tile should has its content loaded and satifies current viewport.\n\n###### `tileset` (Tileset3D)\n\nThe `Tileset3D` instance containing this tile.\n\n###### `header` (Object)\n\nThe unprocessed tile header object passed in.\n\n#### Methods\n\n##### `destroy()`\n\nDestroy the tile node, including destroy all the metadata and unload content.\n\n##### `loadContent()`\n\nLoad a content of the tile.\n\n##### `unloadContent()`\n\nUnload a content of the tile.\n","slug":"modules/tiles/docs/api-reference/tile-3d","title":"Tile3D"},{"excerpt":"Tileset3D The  class is being generalized to handle more use cases. Since this may require modifying some APIs, this class should be…","rawMarkdownBody":"# Tileset3D\n\n> The `Tileset3D` class is being generalized to handle more use cases. Since this may require modifying some APIs, this class should be considered experiemental.\n\nThe `Tileset3D` class can be instantiated with tileset data formatted according to the [3D Tiles Category](docs/specifications/3d-tiles), which is supported by the [Tiles3DLoader](docs/api-reference/3d-tiles/tileset-3d-loader).\n\nReferences\n\n- [3D Tiles](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification).\n- [I3S Tiles](https://github.com/Esri/i3s-spec).\n\n## Usage\n\nLoading a tileset and instantiating a `Tileset3D` instance.\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {Tileset3D} from '@loaders.gl/tiles';\nimport {Tiles3DLoader} from '@loaders.gl/3d-tiles';\n\nconst tilesetUrl = 'https://assets.cesium.com/43978/tileset.json';\nconst tilesetJson = await load(tilesetUrl, Tiles3DLoader);\nconst tileset3d = new Tileset3D(tilesetJson, {\n  onTileLoad: tile => console.log(tile)\n});\n```\n\nLoading a tileset and dynamically load/unload with viewport.\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {Tileset3D} from '@loaders.gl/tiles';\nimport {I3SLoader} from '@loaders.gl/i3s';\nimport WebMercatorViewport from '@math.gl/web-mercator';\n\nconst tileseturl =\n  'https://tiles.arcgis.com/tiles/z2tnIkrLQ2BRzr6P/arcgis/rest/services/SanFrancisco_Bldgs/SceneServer/layers/0';\nconst tilesetJson = await load(tilesetUrl, I3SLoader);\nconst tileset3d = new Tileset3D(tilesetJson, {\n  onTileLoad: tile => console.log(tile)\n});\n\nconst viewport = new WebMercatorViewport({latitude, longitude, zoom});\ntileset3d.update(viewport);\n```\n\nSince `Tileset3D's update` is a synchronized call, which selects the tiles qualified for rendering based on current viewport and available tiles, user can trigger another `update` when new tiles are loaded.\n\n```js\nimport {Tileset3D} from '@loaders.gl/tiles';\n\nconst viewport = new WebMercatorViewport({latitude, longitude, zoom});\n\nconst tileset3d = new Tileset3D(tilesetJson, {\n  onTileLoad: tile => tileset3d.update(viewport)\n});\n```\n\n## Constructor\n\n```js\nnew Tileset3D(tilesetJson, {\n  onTileLoad: tile => console.log(tile)\n});\n```\n\nParameters:\n\n- `json`: loaded tileset json object, should follow the format [tiles format](https://loaders.gl/docs/specifications/category-3d-tiles)\n- `options`:\n  - `options.ellipsoid`=`Ellipsoid.WGS84` (`Ellipsoid`) - The ellipsoid determining the size and shape of the globe.\n  - `options.throttleRequests`=`true` (`Boolean`) - Determines whether or not to throttle tile fetching requests.\n  - `options.modelMatrix`=`Matrix4.IDENTITY` (`Matrix4`) - A 4x4 transformation matrix this transforms the entire tileset.\n  - `options.maximumMemoryUsage`=`512`] (`Number`) - The maximum amount of memory in MB that can be used by the tileset.\n  - `options.fetchOptions` - fetchOptions, i.e. headers, used to load tiles from tiling server\n\nCallbacks:\n\n- `onTileLoad` (`(tileHeader : Tile3DHeader) : void`) - callback when a tile node is fully loaded during the tileset traversal.\n- `onTileUnload` (`(tileHeader : Tile3DHeader) : void`) - callback when a tile node is unloaded during the tileset traversal.\n- `onTileError` (`(tileHeader : Tile3DHeader, message : String) : void`) - callback when a tile faile to load during the tileset traversal.\n\nThe `Tileset3D` allows callbacks (`onTileLoad`, `onTileUnload`) to be registered that notify the app when the set of tiles available for rendering has changed. This is important because tile loads complete asynchronously, after the `tileset3D.update(...)` call has returned.\n\nCesium 3D tiles specific options:\n\n- `options.maximumScreenSpaceError`=`16`] (`Number`) - The maximum screen space error used to drive level of detail refinement.\n\n## Properties\n\n###### `boundingVolume` (BoundingVolume)\n\nThe root tile's bounding volume, which is also the bouding volume of the entire tileset. Check `Tile3DHeader#boundingVolume`\n\n###### `cartesianCenter` (Number[3])\n\nCenter of tileset in fixed frame coordinates.\n\n###### `cartographicCenter` (Number[3])\n\nCenter of tileset in cartographic coordinates `[long, lat, elevation]`\n\n###### `ellipsoid` ([`Ellipsoid`](https://math.gl/modules/geospatial/docs/api-reference/ellipsoid))\n\nGets an ellipsoid describing the shape of the globe.\n\n##### `modelMatrix` (Matrix4)\n\nA [Matrix4](https://math.gl/modules/core/docs/api-reference/matrix4) instance (4x4 transformation matrix) that transforms the entire tileset.\n\n###### `root` (Tile3DHeader)\n\nThe root tile header.\n\n###### `tiles` (Tile3DHeader[])\n\nAll the tiles that have been traversed.\n\n###### `stats` ([`Stats`](https://uber-web.github.io/probe.gl/docs/api-reference/log/stats))\n\nAn instance of a probe.gl `Stats` object that contains information on how many tiles have been loaded etc. Easy to display using a probe.gl `StatsWidget`.\n\n###### `tileset` (Object)\n\nThe original tileset data this object instanced from.\n\n###### `tilesLoaded` (Boolean)\n\nWhen `true`, all tiles that meet the screen space error this frame are loaded. The tileset is completely loaded for this view.\n\n###### `gpuMemoryUsageInBytes` (Number)\n\nThe total amount of GPU memory in bytes used by the tileset. This value is estimated from geometry, texture, and batch table textures of loaded tiles. For point clouds, this value also includes per-point metadata.\n\n###### `url` (String)\n\nThe url to a tileset JSON file.\n\n###### `zoom` (Number[3])\n\nA web mercator zoom level that displays the entire tile set bounding volume\n\n##### `tilesLoaded` : boolean\n\nWhen `true`, all tiles that meet the screen space error this frame are loaded. The tileset is\ncompletely loaded for this view.\n\nSee Tileset3D#allTilesLoaded\n\n### Cesium 3D Tiles properties\n\n### asset : Object\n\nGets the tileset's asset object property, which contains metadata about the tileset.\n\nSee the [asset schema reference](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#reference-asset) in the 3D Tiles spec for the full set of properties.\n\n### properties : Object\n\nGets the tileset's properties dictionary object, which contains metadata about per-feature properties.\n\nSee the [properties schema reference](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#reference-properties) in the 3D Tiles spec for the full set of properties.\n\n### maximumScreenSpaceError : Number\n\nThe maximum screen space error used to drive level of detail refinement. This value helps determine when a tile refines to its descendants, and therefore plays a major role in balancing performance with visual quality.\n\nA tile's screen space error is roughly equivalent to the number of pixels wide that would be drawn if a sphere with a\nradius equal to the tile's <b>geometric error</b> were rendered at the tile's position. If this value exceeds\n`maximumScreenSpaceError` the tile refines to its descendants.\n\nDepending on the tileset, `maximumScreenSpaceError` may need to be tweaked to achieve the right balance. Higher values provide better performance but lower visual quality. \\*\n\n### maximumMemoryUsage : Number\n\n^default 16 \\*\n^exception `maximumScreenSpaceError` must be greater than or equal to zero.\n\nThe maximum amount of GPU memory (in MB) that may be used to cache tiles. This value is estimated from\ngeometry, textures, and batch table textures of loaded tiles. For point clouds, this value also\nincludes per-point metadata.\n\nTiles not in view are unloaded to enforce this.\n\nIf decreasing this value results in unloading tiles, the tiles are unloaded the next frame.\n\nIf tiles sized more than `maximumMemoryUsage` are needed\nto meet the desired screen space error, determined by `Tileset3D.maximumScreenSpaceError`,\nfor the current view, then the memory usage of the tiles loaded will exceed\n`maximumMemoryUsage`. For example, if the maximum is 256 MB, but\n300 MB of tiles are needed to meet the screen space error, then 300 MB of tiles may be loaded. When\nthese tiles go out of view, they will be unloaded.\n\n^default 512 \\*\n^exception `maximumMemoryUsage` must be greater than or equal to zero.\n^see Tileset3D#gpuMemoryUsageInBytes\n\n### root : Tile3DHeader\n\nThe root tile header.\n\n### boundingSphere : BoundingSphere\n\nThe tileset's bounding sphere.\n\n```js\nvar tileset = viewer.scene.primitives.add(\n  new Tileset3D({\n    url: 'http://localhost:8002/tilesets/Seattle/tileset.json'\n  })\n);\n\ntileset.readyPromise.then(function(tileset) {\n  // Set the camera to view the newly added tileset\n  viewer.camera.viewBoundingSphere(tileset.boundingSphere, new HeadingPitchRange(0, -0.5, 0));\n});\n```\n\n### modelMatrix : Matrix4\n\nA 4x4 transformation matrix that transforms the entire tileset.\n\n### maximumMemoryUsage : Number\n\n### gpuMemoryUsageInBytes : Number\n\nThe total amount of GPU memory in bytes used by the tileset. This value is estimated from\ngeometry, texture, and batch table textures of loaded tiles. For point clouds, this value also\nincludes per-point metadata.\n\n### stats : Stats\n\nAn instance of a probe.gl `Stats` object that contains information on how many tiles have been loaded etc. Easy to display using a probe.gl `StatsWidget`.\n\n### ellipsoid : Ellipsoid\n\nGets an ellipsoid describing the shape of the globe.\n\nReturns the `extras` property at the top-level of the tileset JSON, which contains application specific metadata.\nReturns `undefined` if `extras` does not exist.\n\nException The tileset is not loaded. Use Tileset3D.readyPromise or wait for Tileset3D.ready to be true.\n\nSee [Extras](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#specifying-extensions-and-application-specific-extras) in the 3D Tiles specification.}\n\n### unloadTileset\n\nUnloads all tiles that weren't selected the previous frame. This can be used to\nexplicitly manage the tile cache and reduce the total number of tiles loaded below\n`Tileset3D.maximumMemoryUsage`.\n\nTile unloads occur at the next frame to keep all the WebGL delete calls\nwithin the render loop.\n\n### isDestroyed() : Boolean\n\nReturns true if this object was destroyed; otherwise, false.\n\nIf this object was destroyed, it should not be used; calling any function other than\n`isDestroyed` will result in an exception.\n\n^returns `Boolean`: `true` if this object was destroyed; otherwise, `false`.\n\n### destroy()\n\nDestroys the WebGL resources held by this object. Destroying an object allows for deterministic\nrelease of WebGL resources, instead of relying on the garbage collector to destroy this object.\n\nOnce an object is destroyed, it should not be used; calling any function other than `isDestroyed` will result in an exception. Therefore, assign the return value `undefined` to the object as done in the example.\n\nWxception This object was destroyed, i.e., destroy() was called.\n\n## Methods\n\n##### `update`\n\n`update(viewport: WebMercatorViewport) : Number`:\n\nParameters:\n\n- `viewport`: a `WebMercatorViewport`\n\nExecute traversal under current viewport and fetch tiles needed for current viewport and update `selectedTiles`. Return `frameNumber` of this update frame.\n","slug":"modules/tiles/docs/api-reference/tileset-3d","title":"Tileset3D"},{"excerpt":"@loaders.gl/math (Experimental, Temporary) loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This…","rawMarkdownBody":"# @loaders.gl/math (Experimental, Temporary)\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains math utilities for the `@loaders.gl3d-tiles` module. As they mature, these will likely be moved to a math framework (e.g. math.gl).\n\nThis code is a fork of a subset of the Cesium math library whcih is Apache 2 licensed.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/math","title":"@loaders.gl/math (Experimental, Temporary)"},{"excerpt":"@loaders.gl/potree The potree loaders are still under development and are not yet considered ready for use. Support for loading and…","rawMarkdownBody":"# @loaders.gl/potree\n\n> The potree loaders are still under development and are not yet considered ready for use.\n\nSupport for loading and traversing [potree](http://potree.org/) format point clouds.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/potree\nnpm install @loaders.gl/core\n```\n\n## Usage\n\n> Intended usage only, not yet working!\n\n```\nimport {load} from `@loaders.gl/core`;\nimport {PotreeLoader} from `@loaders.gl/potree`;\nimport {Tileset3D} from `@loaders.gl/category-3d-tiles`;\n\nconst potree = await load(POTREE_URL);\nconst tileset = new Tileset3D(potree);\nconst tilesToRender = tileset.traverse(frameData);\n```\n\n## API\n\nThis modules provides the following exports:\n\n- `PotreeHierarchyChunkLoader` for the hierarchy indices\n\n## Roadmap\n\nThe plan is to provide the following loaders/writers:\n\n- `PotreeLoader` for individual tiles\n\n`PotreeLoader` is intended to work with the 3d tileset classes in the `@loaders.gl/3d-tiles` module.\n\n- `Tileset3D` class will be generalized to accept loaded potree tilesets.\n\n## Attribution\n\nThe `PotreeLoader` is a fork of Markus Schuetz' potree code (https://github.com/potree/potree) under BSD-2 clause license.\n","slug":"modules/potree/docs","title":"@loaders.gl/potree"},{"excerpt":"@loaders.gl/core This module contains shared utilities for loaders.gl, a collection of framework independent 3D and geospatial loaders…","rawMarkdownBody":"# @loaders.gl/core\n\nThis module contains shared utilities for loaders.gl, a collection of framework independent 3D and geospatial loaders (parsers).\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/loader-utils","title":"@loaders.gl/core"},{"excerpt":"@loaders.gl/las loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loaders and…","rawMarkdownBody":"# @loaders.gl/las\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loaders and writers for the LAS and LAZ formats.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/las","title":"@loaders.gl/las"},{"excerpt":"@loaders.gl/kml loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loaders for…","rawMarkdownBody":"# @loaders.gl/kml\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loaders for the KML format.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/kml","title":"@loaders.gl/kml"},{"excerpt":"@loaders.gl/json This module contains a table loader for the JSON and line delimited JSON formats. loaders.gl is a collection of framework…","rawMarkdownBody":"# @loaders.gl/json\n\nThis module contains a table loader for the JSON and line delimited JSON formats.\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent visualization-focused loaders (parsers).\n","slug":"modules/json","title":"@loaders.gl/json"},{"excerpt":"TerrainLoader The  reconstructs mesh surfaces from height map images, e.g. Mapzen Terrain Tiles, which encodes elevation into R,G,B values…","rawMarkdownBody":"# TerrainLoader\n\nThe `TerrainLoader` reconstructs mesh surfaces from height map images, e.g. [Mapzen Terrain Tiles](https://github.com/tilezen/joerd/blob/master/docs/formats.md), which encodes elevation into R,G,B values.\n\n| Loader                | Characteristic                                |\n| --------------------- | --------------------------------------------- |\n| File Extension        | `.png`, `.pngraw`                             |\n| File Type             | Binary                                        |\n| File Format           | Encoded height map                            |\n| Data Format           | [Mesh](/docs/specifications/category-mesh.md) |\n| Decoder Type          | Asynchronous                                  |\n| Worker Thread Support | Yes                                           |\n| Streaming Support     | No                                            |\n\n## Usage\n\n```js\nimport {ImageLoader} from '@loaders.gl/images';\nimport {TerrainLoader} from '@loaders.gl/terrain';\nimport {load, registerLoaders} from '@loaders.gl/core';\n\nregisterLoaders(ImageLoader);\n\nconst data = await load(url, TerrainLoader, options);\n```\n\n## Options\n\n| Option                     | Type          | Default   | Description                                                                                                                                   |\n| -------------------------- | ------------- | --------- | --------------------------------------------------------------------------------------------------------------------------------------------- |\n| `terrain.meshMaxError`     | number        | `10`      | Mesh error in meters. The output mesh is in higher resolution (more vertices) if the error is smaller.                                        |\n| `terrain.bounds`           | array<number> | `null`    | Bounds of the image to fit x,y coordinates into. In `[minX, minY, maxX, maxY]`. If not supplied, x and y are in pixels relative to the image. |\n| `terrain.elevationDecoder` | object        | See below | See below                                                                                                                                     |\n\n### elevationDecoder\n\nParameters used to convert a pixel to elevation in meters.\nAn object containing the following fields:\n\n- `rScale`: Multiplier of the red channel.\n- `gScale`: Multiplier of the green channel.\n- `bScale`: Multiplier of the blue channel.\n- `offset`: Translation of the sum.\n\nEach color channel (r, g, and b) is a number between `[0, 255]`.\n\nFor example, the Mapbox terrain service's elevation is [encoded as follows](https://docs.mapbox.com/help/troubleshooting/access-elevation-data/#decode-data):\n\n```\nheight = -10000 + ((R * 256 * 256 + G * 256 + B) * 0.1)\n```\n\nThe corresponding `elevationDecoder` is:\n\n```\n{\n  \"rScale\": 6553.6,\n  \"gScale\": 25.6,\n  \"bScale\": 0.1,\n  \"offset\": -10000\n}\n```\n\nThe default value of `elevationDecoder` decodes a grayscale image:\n\n```\n{\n  \"rScale\": 1,\n  \"gScale\": 0,\n  \"gScale\": 0,\n  \"offset\": 0\n}\n```\n","slug":"modules/terrain/docs/api-reference/terrain-loader","title":"TerrainLoader"},{"excerpt":"@loaders.gl/images loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loader…","rawMarkdownBody":"# @loaders.gl/images\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loader and writers for images that follow loaders.gl conventions and work under both node and browser.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/images","title":"@loaders.gl/images"},{"excerpt":"@loaders.gl/i3s (Experimental) This module contains a loader for i3s (Indexed SceneLayers). loaders.gl is a collection of loaders for big…","rawMarkdownBody":"# @loaders.gl/i3s (Experimental)\n\nThis module contains a loader for [i3s](https://github.com/Esri/i3s-spec) (Indexed SceneLayers).\n\n[loaders.gl](https://loaders.gl/docs) is a collection of loaders for big data visualizations.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/i3s","title":"@loaders.gl/i3s (Experimental)"},{"excerpt":"Overview The  module handles the the Polygon file format, or the Stanford Trangle Format, a file format for 3D graphical objects described…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/ply` module handles the the [Polygon file format](http://paulbourke.net/dataformats/ply/), or the Stanford Trangle Format, a file format for 3D graphical objects described as a collection of polygons.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/ply\n```\n\n## Attribution\n\nPLYLoader is a fork of the THREE.js PLYLoader under MIT License. The THREE.js source files contained the following attributions:\n\n@author Wei Meng / http://about.me/menway\n","slug":"modules/ply/docs","title":"Overview"},{"excerpt":"Overview The  module handles the the Point Cloud Data format, which encodes point cloud data for use inside Point Cloud Library (PCL…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/pcd` module handles the the [Point Cloud Data format](http://pointclouds.org/documentation/tutorials/pcd_file_format.php), which encodes point cloud data for use inside Point Cloud Library (PCL).\n\n## Installation\n\n```bash\nnpm install @loaders.gl/pcd\nnpm install @loaders.gl/core\n```\n\n## Attribution\n\nPCDLoader is a fork of the THREE.js PCDLoader under MIT License. The THREE.js source files contained the following attributions:\n\n- @author Filipe Caixeta / http://filipecaixeta.com.br\n- @author Mugen87 / https://github.com/Mugen87\n","slug":"modules/pcd/docs","title":"Overview"},{"excerpt":"@loaders.gl/gltf loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loader and…","rawMarkdownBody":"# @loaders.gl/gltf\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loader and writers for the glTF format.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/gltf","title":"@loaders.gl/gltf"},{"excerpt":"Overview The  module handles the the Wavefront OBJ format, a simple ASCII format that defines 3D geometries as vertices, normals and faces…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/obj` module handles the the [Wavefront OBJ format](https://en.wikipedia.org/wiki/Wavefront_.obj_file), a simple ASCII format that defines 3D geometries as vertices, normals and faces.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/obj\nnpm install @loaders.gl/core\n```\n\n## Attribution\n\nOBJLoader is a port of [three.js](https://github.com/mrdoob/three.js)'s OBJLoader under MIT License.\n","slug":"modules/obj/docs","title":"Overview"},{"excerpt":"@loaders.gl/draco loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loader…","rawMarkdownBody":"# @loaders.gl/draco\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loader and writer for Draco compressed meshes and point clouds.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/draco","title":"@loaders.gl/draco"},{"excerpt":"TableBatch RowTableBatch ColumnarTableBatch ArrowTableBatch","rawMarkdownBody":"# TableBatch\n\n- RowTableBatch\n- ColumnarTableBatch\n- ArrowTableBatch\n","slug":"modules/tables/docs/api-reference/table-batch","title":"TableBatch"},{"excerpt":"TableSchema","rawMarkdownBody":"# TableSchema\n","slug":"modules/tables/docs/api-reference/table-schema","title":"TableSchema"},{"excerpt":"Table","rawMarkdownBody":"# Table\n","slug":"modules/tables/docs/api-reference/table","title":"Table"},{"excerpt":"@loaders.gl/csv This module contains a table loader for the CSV and DSV formats. loaders.gl is a collection of framework independent…","rawMarkdownBody":"# @loaders.gl/csv\n\nThis module contains a table loader for the CSV and DSV formats.\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent visualization-focused loaders (parsers).\n","slug":"modules/csv","title":"@loaders.gl/csv"},{"excerpt":"Overview The  module handles the Mapbox Vector Tile format, a protobuf encoded format that defines geospatial geometries. Installation…","rawMarkdownBody":"# Overview \n\nThe `@loaders.gl/mvt` module handles the [Mapbox Vector Tile](https://github.com/mapbox/vector-tile-spec) format, a protobuf encoded format that defines geospatial geometries.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/mvt\nnpm install @loaders.gl/core\n```\n\n## Loaders and Writers\n\n| Loader                                                    |\n| --------------------------------------------------------- |\n| [`MVTLoader`](modules/mvts/docs/api-reference/mvt-loader) |\n\n## Attribution\n\nThe `MVTLoader` uses [`@mapbox/vector-tile`](https://github.com/mapbox/vector-tile-js) module under the BSD-3-Clause.\n","slug":"modules/mvt/docs","title":"Overview "},{"excerpt":"@loaders.gl/core This module contains shared utilities for loaders.gl, a collection of framework independent 3D and geospatial loaders…","rawMarkdownBody":"# @loaders.gl/core\n\nThis module contains shared utilities for loaders.gl, a collection of framework independent 3D and geospatial loaders (parsers).\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/core","title":"@loaders.gl/core"},{"excerpt":"@loaders.gl/basis loaders.gl is a collection of framework independent 3D and geospatial parsers and encoders. This module contains loader…","rawMarkdownBody":"# @loaders.gl/basis\n\n[loaders.gl](https://loaders.gl/docs) is a collection of framework independent 3D and geospatial parsers and encoders.\n\nThis module contains loader for [basis universal textures](https://github.com/BinomialLLC/basis_universal).\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/basis","title":"@loaders.gl/basis"},{"excerpt":"@loaders.gl/arrow This module contains a table loader for the Apache Arrow format. loaders.gl is a collection of loaders for big data…","rawMarkdownBody":"# @loaders.gl/arrow\n\nThis module contains a table loader for the Apache Arrow format.\n\n[loaders.gl](https://loaders.gl/docs) is a collection of loaders for big data visualizations.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/arrow","title":"@loaders.gl/arrow"},{"excerpt":"Overview The  library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes. Classes and…","rawMarkdownBody":"# Overview\n\n> The `@loaders.gl/math` library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes.\n\nClasses and utilities to help working with geometries (arrays of vertices) stored in typed arrays according to WebGL/OpenGL layout rules.\n\n## Usage Examples\n\n## Framework Independence\n\nLike all non-core math.gl modules, this library can be used without the math.gl core classes.\n\n- Any input vectors can be supplied as length 3 JavaScript `Array` instances.\n- Any result vectors can be treated as length 3 JavaScript `Array` instances (they may be math.gl `Vector3`).\n- The core math.gl classes inherit from JavaScript `Array` and can be used directly as input.\n","slug":"modules/math/docs","title":"Overview"},{"excerpt":"Overview The  module handles the LASER file format (LAS) or its compressed version (LAZ), a public format for the interchange of…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/las` module handles the [LASER file format](https://www.asprs.org/divisions-committees/lidar-division/laser-las-file-format-exchange-activities) (LAS) or its compressed version (LAZ), a public format for the interchange of 3-dimensional point cloud data data, developed for LIDAR mapping purposes.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/las\n```\n\n## Attribution\n\nLASLoader is a fork of Uday Verma and Howard Butler's [plasio](https://github.com/verma/plasio/) under MIT License.\n","slug":"modules/las/docs","title":"Overview"},{"excerpt":"@loaders.gl/3d-tiles (Experimental) This module contains a loader for 3D tiles. loaders.gl is a collection of loaders for big data…","rawMarkdownBody":"# @loaders.gl/3d-tiles (Experimental)\n\nThis module contains a loader for [3D tiles](https://github.com/AnalyticalGraphicsInc/3d-tiles).\n\n[loaders.gl](https://loaders.gl/docs) is a collection of loaders for big data visualizations.\n\nFor documentation please visit the [website](https://loaders.gl).\n","slug":"modules/3d-tiles","title":"@loaders.gl/3d-tiles (Experimental)"},{"excerpt":"Overview The  module supports the KML format. KML (Keyhole Markup Language) is an XML-based file format used to display geographic data in…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/kml` module supports the KML format.\n\nKML (Keyhole Markup Language) is an XML-based file format used to display geographic data in an Earth browser such as Google Earth (originally named \"Keyhole Earth Viewer\"). It can be used with any 2D or 3D maps.\n\nReferences:\n\n- [Keyhole Markup Language - Wikipedia](https://en.wikipedia.org/wiki/Keyhole_Markup_Language)\n- [KML Tutorial - Google](https://developers.google.com/kml/documentation/kml_tut)\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/kml\n```\n\n## Attribution\n\n`XMLLoader` is an adaptation of Nick Blackwell's [`js-simplekml`](https://github.com/nickolanack/js-simplekml) module under MIT license.\n","slug":"modules/kml/docs","title":"Overview"},{"excerpt":"Overview The  provides optional support for Node.js and older browsers. Older browsers (mainly Edge and IE11) as well as versions of Node.js…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/polyfills` provides optional support for Node.js and older browsers.\n\nOlder browsers (mainly Edge and IE11) as well as versions of Node.js prior to v11 do not provide certain classes that loaders.gl depends on.\n\nWhile there are many good polyfill modules available on `npm`, to make the search for a version that works perfectly with loaders.gl a little easier, a polyfill module is included.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/polyfills\n```\n\n## Usage\n\nJust import `@loaders.gl/polyfills` before you start using other loaders.gl modules.\n\n```js\nimport '@loaders.gl/polyfills';\nimport '@loaders.gl/core';\n```\n\n## Included Polyfills\n\n| Polyfill                    | Node         | Browser              | Comments                                                                                                                                                                                    |\n| --------------------------- | ------------ | -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `TextEncoder`/`TextDecoder` | Node.js < 11 | Yes (Older browsers) | Only UTF8 is guaranteed to be supported                                                                                                                                                     |\n| `atob`/`btoa`               | All versions | No                   | Note: these functions are [not unicode safe](https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/Base64_encoding_and_decoding#The_Unicode_Problem), but OK to use for test cases. |\n| `fetch`                     | All versions | No                   | A subset of the fetch API is supported, see below.                                                                                                                                          |\n\n## fetch Polyfill\n\nThe Node.js `fetch` polyfill supports a subset of the browser fetch API, including:\n\n- `Response.text()`, `Response.arrayBuffer()`.\n- `Response.body` stream\n- limited support for `headers`\n- data uri / base64 decoding\n\n# TextEncoder and TextDecoder Polyfills\n\n`TextEncoder` and `TextDecoder` polyfills are provided to ensure these APIs are always available. In modern browsers these will evaluate to the built-in objects of the same name, however under Node.js polyfills are transparently installed.\n\nNote: The provided polyfills only guarantee UTF8 support.\n\n## Remarks\n\n- Applications should only install this module if they need to run under older environments. While the polyfills are only installed at runtime if the platform does not already support them, importing this module will increase the application's bundle size.\n- Refer to browser documentation for the usage of these classes, e.g. MDN.\n- In the browser, overhead of using these imports is very low, as most polyfills are only bundled under Node.js.\n- If working under older browsers, e.g. IE11, you may need to install your own TextEncoder/TextDecoder polyfills before loading this library\n\n## Attribution\n\nThe `Header` polyfill (for Node.js `fetch`) is a fork of the implementation in https://github.com/github/fetch (MIT license).\n","slug":"modules/polyfills/docs/api-reference","title":"Overview"},{"excerpt":"@loaders.gl/json The  module handles tabular data stored in the JSON file format. Installation Loaders and Writers Loader  Additional APIs…","rawMarkdownBody":"# @loaders.gl/json\n\nThe `@loaders.gl/json` module handles tabular data stored in the [JSON file format](https://www.json.org/json-en.html).\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/json\n```\n\n## Loaders and Writers\n\n| Loader                                                      |\n| ----------------------------------------------------------- |\n| [`JSONLoader`](modules/json/docs/api-reference/json-loader) |\n\n## Additional APIs\n\nSee table category.\n\n## Module Roadmap\n\n### General Improvements\n\nError messages: `JSON.parse` tends to have unhelpful error messages\n\n### Support Streaming JSON Formats\n\n- Overview of [JSON Streaming Formats](https://en.wikipedia.org/wiki/JSON_streaming) (Wikipedia).\n\n- [Line-delimited JSON](http://jsonlines.org/) (LDJSON) (aka JSON lines) (JSONL).\n- [NewLine delimited JSON](https://github.com/ndjson/ndjson-spec)\n\n### Autodetection of streaming JSON\n\nA number of hints can be used to determine if the data is formatted using a streaming JSON format\n\n- if the filename extension is `.jsonl`\n- if the MIMETYPE is `application/json-seq`\n- if the first value in the file is a number, assume the file is length prefixed.\n\nFor data in non-streaming JSON format, the presence of a top-level array will start streaming of objects.\n\nFor embedded arrays, a path specifier may need to be supplied (or could look for first array).\n\n### MIME Types and File Extensions\n\n| Format                          | Extension | MIME Media Type [RFC4288](https://www.ietf.org/rfc/rfc4288.txt) |\n| ------------------------------- | --------- | --------------------------------------------------------------- |\n| Standard JSON                   | `.json`   | `application/json`                                              |\n| Line-delimited JSON             | `.jsonl`  | -                                                               |\n| NewLine delimited JSON          | `.ndjson` | `application/x-ndjson`                                          |\n| Record separator-delimited JSON | -         | `application/json-seq`                                          |\n","slug":"modules/json/docs","title":"@loaders.gl/json"},{"excerpt":"Overview The  module contains loader and writers for images that follow loaders.gl conventions and work under both node and browser…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/images` module contains loader and writers for images that follow loaders.gl conventions and work under both node and browser.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/images\nnpm install @loaders.gl/core\n```\n\n## API\n\n| Loader                                                          | Description |\n| --------------------------------------------------------------- | ----------- |\n| [`ImageLoader`](modules/images/docs/api-reference/image-loader) |             |\n| [`ImageWriter`](modules/images/docs/api-reference/image-writer) |             |\n\n### Binary Image API\n\nA set of functions that can extract information from \"unparsed\" binary memory representation of certain image formats. These functions are intended to be called on raw `ArrayBuffer` data, before the `ImageLoader` parses it and converts it to a parsed image type.\n\nThese functions are used internally to autodetect if image loader can be used to parse a certain `ArrayBuffer`, but are also available to applications.\n\n| Function                                                                     | Description |\n| ---------------------------------------------------------------------------- | ----------- |\n| `isBinaryImage(imageData : ArrayBuffer [, mimeType : String]) : Boolean`     |             |\n| `getBinaryImageMIMEType(imageData : ArrayBuffer) : String | null`            |             |\n| `getBinaryImageSize(imageData : ArrayBuffer [, mimeType : String]) : Object` |             |\n\n### Parsed Image API\n\nA set of functions to work with parsed images returned by the `ImageLoader`.\n\n| Function                                        | Description                                                                                               |\n| ----------------------------------------------- | --------------------------------------------------------------------------------------------------------- |\n| `isImageTypeSupported(type : string) : boolean` | Check if type is supported by current run-time environment                                                |\n| `getDefaultImageType() : string`                | Returns the image type selected by default ( `options.image.type: 'auto'` in current run-time environment |\n| `isImage(image : any) : boolean`                | Checks any JavaScript value to see if it is an image of a type that loaders.gl can work with              |\n| `getImageType(image : any) : string`            | Returns the type name for this image.                                                                     |\n| `getImageData(image : any) : object`            | Returns an image data object with a `data` array representing the pixels of an image                      |\n\n### Image Loading API for WebGL Textures\n\nThe images API also offers functions to load \"composite\" images for WebGL textures, cube textures and image mip levels.\n\nThese functions take a `getUrl` parameter that enables the app to supply the url for each \"sub-image\", and return a single promise enabling applications to for instance load all the faces of a cube texture, with one image for each mip level for each face in a single async operation.\n\n| Function                                                              | Description                                                                                                           |\n| --------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |\n| [`loadImage`](modules/images/docs/api-reference/load-image)           | Load a single image                                                                                                   |\n| [`loadImageArray`](modules/images/docs/api-reference/load-images)     | Load an array of images, e.g. for a `Texture2DArray` or `Texture3D`                                                   |\n| [`loadImageCube`](modules/images/docs/api-reference/load-cube-images) | Load a map of 6 images for the faces of a cube map, or a map of 6 arrays of images for the mip levels of the 6 faces. |\n\nAs with all loaders.gl functions, while these functions are intended for use in WebGL applications, they do not call any WebGL functions, and do not actually create any WebGL textures..\n\n## Image Types\n\nTo support image loading on older browsers and Node.js, the `ImageLoader` can return different types, i.e. different representations of the parsed image.\n\n- `ImageBitmap` - An `ImageBitmap` object represents a bitmap image that can be painted to a canvas without undue latency. This is the preferred parsed image representation in the browser. It can also be transferred efficiently between threads. Not available in some older browsers.\n- `Image` (aka `HTMLImageElement`) - The traditional HTML image class. Available in all browsers.\n- `data` - a memory layout for parsed pixels in node.js. Texture creation functions in headless gl accept `data` images.\n\nSee [`ImageLoader`](modules/images/docs/api-reference/image-loader) for more details on options etc.\n","slug":"modules/images/docs","title":"Overview"},{"excerpt":"PLYLoader The  parses simple meshes in the Polygon File Format or the Stanford Triangle Format. Loader Characteristic File Extension  File…","rawMarkdownBody":"# PLYLoader\n\nThe `PLYLoader` parses simple meshes in the Polygon File Format or the Stanford Triangle Format.\n\n| Loader                | Characteristic                                |\n| --------------------- | --------------------------------------------- |\n| File Extension        | `.ply`                                        |\n| File Type             | Binary/Text                                   |\n| File Format           | [PLY](http://paulbourke.net/dataformats/ply/) |\n| Data Format           | [Mesh](docs/specifications/category-mesh.md)  |\n| Decoder Type          | Synchronous                                   |\n| Worker Thread Support | Yes                                           |\n| Streaming Support     | No                                            |\n\n## Usage\n\n```js\nimport {PLYLoader} from '@loaders.gl/ply';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, PLYLoader, options);\n```\n\n## Options\n\n| Option | Type | Default | Description |\n| ------ | ---- | ------- | ----------- |\n\n","slug":"modules/ply/docs/api-reference/ply-loader","title":"PLYLoader"},{"excerpt":"Overview The  module supports loading and traversing Indexed 3d Scene Layer (I3S). References I3S Tiles Specification - The living…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/i3s` module supports loading and traversing Indexed 3d Scene Layer (I3S).\n\nReferences\n\n- [I3S Tiles Specification](https://github.com/Esri/i3s-spec) - The living specification.\n- [I3S Tiles Standard](http://www.ogc.org/standards/i3s) - The official standard from [OGC](http://www.ogc.org/standards/i3s), the Open Geospatial Consortium.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/i3s\nnpm install @loaders.gl/core\n```\n\n## API\n\nA standard complement of loader is provided to load the individual 3d Tile file formats:\n\n- [`I3SLoader`](modules/3d-tiles/docs/api-reference/i3s-loader), a loader for loading a top-down or nested tileset and its tiles.\n\nTo handle the complex dynamic tile selection and loading required to performantly render larger-than-browser-memory tilesets, additional helper classes are provided in `@loaders.gl/tiles` module:\n\n- [`Tileset3D`](modules/3d-tiles/docs/api-reference/tileset-3d) to work with the loaded tileset.\n- [`Tile3D`](modules/3d-tiles/docs/api-reference/tile-3d) to access data for a specific tile.\n\n## Usage\n\nBasic API usage is illustrated in the following snippet. Create a `Tileset3D` instance, point it a valid tileset URL, set up callbacks, and keep feeding in new camera positions:\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {I3SLoader} from '@loaders.gl/i3s';\nimport {Tileset3D} from '@loaders.gl/tiles';\n\nconst tilesetUrl = ''; // add the url to your tileset.json file here\n\nconst tilesetJson = await load(tilesetUrl, I3SLoader);\n\nconst tileset3d = new Tileset3D(tilesetJson, {\n  onTileLoad: tile => console.log(tile)\n});\n\n// initial viewport\ntileset3d.update(viewport);\n\n// Viewport changes (pan zoom etc)\ntileset3d.update(viewport);\n\n// Visible tiles\nconst visibleTiles = tileset3d.tiles.filter(tile => tile.selected);\n\n// Note that visibleTiles will likely not immediately include all tiles\n// tiles will keep loading and file `onTileLoad` callbacks\n```\n\n## Remarks \n\n`@loaders.gl/3s` is still under experimental, and mainly support decoding `MeshPyramids` (3D Object and Integrated Mesh) profiles.\n\n## Attribution\n\n","slug":"modules/i3s/docs","title":"Overview"},{"excerpt":"PCDLoader The  loads point cloud in the Point Cloud Data (PCD) format. Loader Characteristic File Extension  File Type Text/Binary File…","rawMarkdownBody":"# PCDLoader\n\nThe `PCDLoader` loads point cloud in the Point Cloud Data (PCD) format.\n\n| Loader                | Characteristic                                                                         |\n| --------------------- | -------------------------------------------------------------------------------------- |\n| File Extension        | `.pcd`                                                                                 |\n| File Type             | Text/Binary                                                                            |\n| File Format           | [Point Cloud Data](http://pointclouds.org/documentation/tutorials/pcd_file_format.php) |\n| Data Format           | [PointCloud](docs/specifications/category-mesh.md)                                     |\n| Decoder Type          | Synchronous                                                                            |\n| Worker Thread Support | Yes                                                                                    |\n| Streaming Support     | No                                                                                     |\n\nNote: Currently only `ascii` and `binary` subformats are supported. Compressed binary files are currently not supported.\n\n## Usage\n\n```js\nimport {PCDLoader} from '@loaders.gl/pcd';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, PCSLoader, options);\n```\n\n## Options\n\n| Option | Type | Default | Description |\n| ------ | ---- | ------- | ----------- |\n\n","slug":"modules/pcd/docs/api-reference/pcd-loader","title":"PCDLoader"},{"excerpt":"Overview  The  module provides loaders and writers of the GLB/glTF formats. Installation Optionally, to support Draco encoded gltf files…","rawMarkdownBody":"# Overview\n\n![logo](./images/gltf-small.png)\n\nThe `@loaders.gl/gltf` module provides loaders and writers of the GLB/glTF formats.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/gltf\nnpm install @loaders.gl/core\n```\n\nOptionally, to support Draco encoded gltf files\n\n```bash\nnpm install @loaders.gl/draco\n```\n\n## GLTFScenegraph API\n\nTo simplify traversing and building glTF data objects, the [`GLTFScenegraph`](docs/api-reference/gltf/gltf-scenegraph) class can be used.\n\nA glTF data object can also be built programmatically using the GLTFScenegraph's \"fluent API\":\n\n```js\nimport {encode} from '@loaders.gl/gltf';\nimport {GLTFScenegraph, GLTFWriter} from '@loaders.gl/gltf';\nconst gltfScenegraph = new GLTFScenegraph()\n  .addApplicationData(...)\n  .addExtras(...)\n  .addExtension(...)\n  .addRequiredExtension(...);\n\nconst arrayBuffer = encode(gltfScenegraph, GLTFWriter);\n```\n\n## GLTF Post Processing\n\nThe [`postProcessGLTF`](docs/api-reference/gltf/post-process-gltf) function implements a number of transformations on the loaded glTF data that would typically need to be performed by the application after loading the data, and is provided as an optional function that applications can call after loading glTF data. Refer to the reference page for details on what transformations are performed.\n\nContext: the glTF data object returned by the GLTF loader contains the \"raw\" glTF JSON structure (to ensure generality and \"data fidelity\" reasons). However, most applications that are going to use the glTF data to visualize it in (typically in WebGL) will need to do some processing of the loaded data before using it.\n\n## Using GLB as a \"Binary Container\" for Arbitrary Data\n\nThe GLB binary container format used by glTF addresses a general need to store a mix of JSON and binary data, and can potentially be used as a foundation for building custom loaders and writers.\n\nTo allow for this (and also to generally improve the glTF code structure), the `GLTFLoader` and `GLTFBuilder` classes are built on top of GLB focused classes (`GLBLoader` and `GLBBuilder`) that can be used independently of the bigger glTF classes.\n\n## glTF Extension Support\n\nCertain glTF extensions are fully or partially supported by the glTF classes. For details on which extensions are supported, see [glTF Extensions](docs/api-reference/gltf-loaders/gltf-extensions).\n\n## Draco Mesh and Point Cloud Compression\n\nDraco encoding and decoding is supported by the `GLTFBuilder` and `GLTFParser` classes but requires the DracoWriter and DracoLoader dependencies to be \"injected\" by the application.\n\n```js\nimport {GLTFBuilder} from '@loaders.gl/gltf';\nimport {DracoWriter, DracoLoader} from '@loaders.gl/draco';\n\nconst gltfBuilder = new GLTFBuilder({DracoWriter, DracoLoader});\n```\n","slug":"modules/gltf/docs","title":"Overview"},{"excerpt":"Overview  The  module handles compressing and decompressing of 3D meshes and point clouds with DRACO. Installation Loaders and Writers…","rawMarkdownBody":"# Overview\n\n![logo](./images/draco-small.png)\n\nThe `@loaders.gl/draco` module handles compressing and decompressing of 3D meshes and point clouds with [DRACO](https://github.com/google/draco).\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/draco\n```\n\n## Loaders and Writers\n\n| Loader                                                               |\n| -------------------------------------------------------------------- |\n| [`DracoLoader`](modules/draco/docs/api-reference/draco-loader)       |\n| [`DracoWorkerLoader`](modules/draco/docs/api-reference/draco-loader) |\n| [`DracoWriter`](modules/draco/docs/api-reference/draco-writer)       |\n\n## Additional APIs\n\nSee point cloud / mesh category.\n\n## Dependencies\n\nDraco support requires the Draco libraries, which are quite big (see table below). By default, these will be loaded from CDN but can optionally be bundled and supplied by the application through the top-level `options.modules` option:\n\nBundling the entire `draco3d` library:\n\n```js\nimport draco from 'draco3d';\nimport {setLoaderOptions} from '@loaders.gl/core';\nsetLoaderOptions({\n  modules: {\n    draco3d\n  }\n});\n```\n\nBundling only the WebAssembly decoder\n\n```js\nimport {setLoaderOptions} from '@loaders.gl/core';\nsetLoaderOptions({\n  modules: {\n    'draco_wasm_wrapper.js': require('@loaders.gl/draco/libs/draco_wasm_wrapper.js'),\n    'draco_decoder.wasm': require('@loaders.gl/draco/libs/draco_decoder.wasm') // NOTE: importing `wasm` requires bundler config\n  }\n});\n```\n\n| Library                                 | Import                            | Install               | Size        | Description                                                                        |\n| --------------------------------------- | --------------------------------- | --------------------- | ----------- | ---------------------------------------------------------------------------------- |\n| `options.libs.draco3d`                  | `require('draco3d')`              | `npm install draco3d` | ~1.5MB      | The full Draco library (encode + decode, web assembly + IE11 javascript fallback). |\n| `options.libs['draco_decoder.wasm']`    | [`ArrayBuffer`]()                 | ~320K                 | manual copy | Web Assembly Decoder (access using `draco_wasm_wrapper.js`)                        |\n| `options.libs['draco_wasm_wrapper.js']` | `require('.../draco_decoder.js')` | ~64K                  | manual copy | JavaScript wrapper for `draco_decoder.wasm`                                        |\n| `options.libs['draco_decoder.js']`      | `require('.../draco_decoder.js')` | ~790K                 | manual copy | JavaScript decoder (fallback for IE11)                                             |\n| `options.libs['draco_encoder.js']`      | `require('.../draco_encode.js')`  | ~900K                 | manual copy | Encoder part of the library                                                        |\n\nRemarks\n\n- Due to the size of the Draco libraries, a reasonable strategy for applications that wish to bundle their dependencies (e.g to avoid relying on a potentially flaky CDN) might be to bundle and supply only `draco_decoder.wasm` and `draco_wasm_wrapper.js`, and still rely on the default setup to load the IE11 fallback library and the encoder code from CDN when needed.\n- Web Assembly code (`wasm` files) must be imported/loaded as binary data (`ArrayBuffer`). An option for webpack users is the [`arraybuffer-loader`](https://www.npmjs.com/package/arraybuffer-loader#for-wasm-file) webpack \"loader\".\n\n## Attributions\n\nBased on Draco examples, under the Apache 2.0 license.\n","slug":"modules/draco/docs","title":"Overview"},{"excerpt":"OBJLoader The  parses the OBJ half of the classic Wavefront OBJ/MTL format. Loader Characteristic File Extension  File Type Text File Format…","rawMarkdownBody":"# OBJLoader\n\nThe `OBJLoader` parses the OBJ half of the classic Wavefront OBJ/MTL format.\n\n| Loader                | Characteristic                                                          |\n| --------------------- | ----------------------------------------------------------------------- |\n| File Extension        | `.obj`                                                                  |\n| File Type             | Text                                                                    |\n| File Format           | [Wavefront OBJ file](https://en.wikipedia.org/wiki/Wavefront_.obj_file) |\n| Data Format           | [Mesh](docs/specifications/category-mesh.md)                            |\n| Decoder Type          | Synchronous                                                             |\n| Worker Thread Support | Yes                                                                     |\n| Streaming Support     | No                                                                      |\n\n## Usage\n\n```js\nimport {OBJLoader} from '@loaders.gl/obj';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, OBJLoader, options);\n```\n\n## Options\n\n| Option | Type | Default | Description |\n| ------ | ---- | ------- | ----------- |\n\n","slug":"modules/obj/docs/api-reference/obj-loader","title":"OBJLoader"},{"excerpt":"MVTLoader Loader for the Mapbox Vector Tile format for representation of geometry. Loader Characteristic File Extension , File Type Binary…","rawMarkdownBody":"# MVTLoader\n\nLoader for the [Mapbox Vector Tile](https://docs.mapbox.com/vector-tiles/specification/) format for representation of geometry.\n\n| Loader         | Characteristic                                                            |\n| -------------- | ------------------------------------------------------------------------- |\n| File Extension | `.mvt`,                                                                   |\n| File Type      | Binary                                                                    |\n| File Format    | [Mapbox Vector Tile](https://docs.mapbox.com/vector-tiles/specification/) |\n| Data Format    | [Geometry](/docs/specifications/category-gis)                             |\n| Supported APIs | `load`, `parse`, `parseSync`                                              |\n\n## Usage\n\n```js\nimport {MVTLoader} from '@loaders.gl/mvt';\nimport {load} from '@loaders.gl/core';\n\n// GeoJSON objects containing local coordinates decoded from tile origin to a range of [0 - (bufferSize / tileExtent), 1 + (bufferSize / tileExtent)]\nconst geometryData = await load(url, MVTLoader);\n\n// Array containing GeoJSON Features\nconst loaderOptions = {\n  mvt: {\n    coordinates: 'wgs84',\n    tileIndex: {\n      x: 0,\n      y: 0,\n      z: 0\n    }\n  }\n};\n\nconst geoJSONfeatures = await load(url, MVTLoader, loaderOptions);\n```\n\n## Outputs\n\n### GeoJSON\n\nThe parser will return an array of [GeoJSON objects](https://tools.ietf.org/html/rfc7946) with WGS84 coordinates and feature properties from MVT if `coordinates` property is set to `wgs84` and `tileIndex` properties are present.\n\n```js\nimport {MVTLoader} from '@loaders.gl/mvt';\nimport {load} from '@loaders.gl/core';\n\nconst loaderOptions = {\n  mvt: {\n    coordinates: 'wgs84',\n    tileIndex: {\n      x: xTileIndex,\n      y: yTileIndex,\n      z: zTileIndex\n    }\n  }\n};\n\nconst geoJSONfeatures = await load(url, MVTLoader, loaderOptions);\n```\n\n### GeoJSON with local coordinates\n\nThe parser will return an array of GeoJSON objects with local coordinates in a range from 0 to 1 and feature properties from MVT by default.\n\nEven though tile coordinates go from 0 to 1, there can be some negative (or greater than one) coordinates because of buffer cells within MVT to handle geometry clipping. That difference can be as much as `bufferSize / tileExtent` depending on MVT creation parameters.\n\nNote that local coordinates are relative to tile origin, which is in the top left.\n\n```js\nimport {MVTLoader} from '@loaders.gl/mvt';\nimport {load} from '@loaders.gl/core';\n\n/*\n* Default loader options are:\n*\n* {\n*   mvt: {\n*     coordinates: 'local'\n*   }\n* }\n*/\n\nconst geoJSONfeatures = await load(url, MVTLoader);\n```\n\n## Options\n\n| Option            | Type                                         | Default     | Description                                                                                                                                                                                                                                                                            |\n| ----------------- | -------------------------------------------- | ----------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| mvt.coordinates   | String                                       | `local`     | When set to `wgs84`, the parser will return a flat array of GeoJSON objects with coordinates in longitude, latitude decoded from the provided tile index. When set to `local`, the parser will return a flat array of GeoJSON objects with local coordinates decoded from tile origin. |\n| mvt.layerProperty | String                                       | `layerName` | When non-`null`, the layer name of each feature is added to `feature.properties[layerProperty]`. (A `feature.properties` object is created if the feature has no existing properties). If set to `null`, a layer name property will not be added.                                      |\n| mvt.layers        | String[]                                     | `null`      | Optional list of layer names. If not `null`, only features belonging to the named layers will be included in the output. If `null`, features from all layers are returned.                                                                                                             |\n| mvt.tileIndex     | Object (`{x: number, y: number, z: number}`) | `null`      | Mandatory with `wgs84` coordinates option. An object containing tile index values (`x`, `y`, `z`) to reproject features' coordinates into WGS84.                                                                                                                                       |\n\nIf you want to know more about how geometries are encoded into MVT tiles, please read [this documentation section](https://docs.mapbox.com/vector-tiles/specification/#encoding-geometry).\n\n## Attribution\n\nThe `MVTLoader` uses [`@mapbox/vector-tile`](https://github.com/mapbox/vector-tile-js) module under the BSD-3-Clause.\n","slug":"modules/mvt/docs/api-reference/mvt-loader","title":"MVTLoader"},{"excerpt":"Overview The  module handles tabular data stored in the CSV/DSV file format. Installation Loaders and Writers Loader   Additional APIs See…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/csv` module handles tabular data stored in the [CSV/DSV file format](https://en.wikipedia.org/wiki/Comma-separated_values).\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/csv\n```\n\n## Loaders and Writers\n\n| Loader                                                         |\n| -------------------------------------------------------------- |\n| [`CSVLoader`](modules/csv/docs/api-reference/csv-loader)       |\n| [`CSVWorkerLoader`](modules/csv/docs/api-reference/csv-loader) |\n\n## Additional APIs\n\nSee table category.\n\n## Attributions\n\nCSVLoader is based on a fork of the [papaparse](https://github.com/mholt/PapaParse) module, under MIT license.\n","slug":"modules/csv/docs","title":"Overview"},{"excerpt":"Overview The  module contains the core API of loaders.gl The core API offers functions to parse data in various ways using loaders    To…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/core` module contains the core API of loaders.gl\n\nThe core API offers functions to parse data in various ways using loaders\n\n- [`parse`](modules/core/docs/api-reference/parse)\n- [`parseSync`](modules/core/docs/api-reference/parseSync)\n- [`parseInBatches`](modules/core/docs/api-reference/parseInBatches)\n\nTo fetch data\n\n- [`fetchFile`](modules/core/docs/api-reference/fetchFile)\n\nTo load (fetch and parse) data\n\n- [`load`](modules/core/docs/api-reference/load)\n\nTo register loaders, or select a loader that matches a file from a list of candidate loaders:\n\n- [`registerLoaders`](modules/core/docs/api-reference/registerLoaders)\n- [`selectLoader`](modules/core/docs/api-reference/selectLoader)\n\nTo encode and save data\n\n- [`encode`](modules/core/docs/api-reference/encode)\n- [`write-file`](modules/core/docs/api-reference/file)\n- [`save`](modules/core/docs/api-reference/save)\n\nAs well as some utility functions.\n","slug":"modules/core/docs","title":"Overview"},{"excerpt":"Overview The  module contains a loader for Basis encoded compressed textures (images). Installation API Loader Description   Compressed…","rawMarkdownBody":"# Overview\n\nThe `@loaders.gl/basis` module contains a loader for Basis encoded compressed textures (images).\n\n## Installation\n\n```bash\nnpm install @loaders.gl/basis\nnpm install @loaders.gl/core\n```\n\n## API\n\n| Loader                                                         | Description |\n| -------------------------------------------------------------- | ----------- |\n| [`BasisLoader`](modules/basis/docs/api-reference/basis-loader) |             |\n\n### Compressed Texture API\n\nA set of functions that can extract information from \"unparsed\" binary memory representation of certain compressed texture image formats. These functions are intended to be called on raw `ArrayBuffer` data, before the `BasisLoader` parses it and converts it to a parsed image type.\n\nTBA\n\n| Function | Description |\n| -------- | ----------- |\n\n\n## Return Types\n\nThe `BasisLoader` returns Array of Array of ArrayBuffer\n\nTODO - Node.js handling - expand to normal image?\n\nSee [`BasisLoader`](modules/basis/docs/api-reference/image-loader) for more details on options etc.\n","slug":"modules/basis/docs","title":"Overview"},{"excerpt":"Overview  The  module handles Apache Arrow, an emerging standard for large in-memory columnar data. Installation Loaders and Writers Loader…","rawMarkdownBody":"# Overview\n\n![logo](./images/apache-arrow-small.png)\n\nThe `@loaders.gl/arrow` module handles [Apache Arrow](https://arrow.apache.org/), an emerging standard for large in-memory columnar data.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/core @loaders.gl/arrow\n```\n\n## Loaders and Writers\n\n| Loader                                                               |\n| -------------------------------------------------------------------- |\n| [`ArrowLoader`](modules/arrow/docs/api-reference/arrow-loader)       |\n| [`ArrowWorkerLoader`](modules/arrow/docs/api-reference/arrow-loader) |\n\n## Additional APIs\n\nArrow provides a rich JavaScript API for working with Arrow formatted data. Please refer to the [`ArrowJS`](arrowjs/docs) API documentation.\n\n## Attributions\n\n`@loaders.gl/arrow` was developed with the benefit of extensive technical advice from Paul Taylor @ Graphistry.\n","slug":"modules/arrow/docs","title":"Overview"},{"excerpt":"GLType Helper functions to work with WebGL data type constants. WebGL type constant JavaScript Typed Array Notes      Not yet directly…","rawMarkdownBody":"# GLType\n\nHelper functions to work with WebGL data type constants.\n\n| WebGL type constant | JavaScript Typed Array | Notes                                 |\n| ------------------- | ---------------------- | ------------------------------------- |\n| `GL.FLOAT`          | `Float32Array`         |                                       |\n| `GL.DOUBLE`         | `Float64Array`         | Not yet directly usable in WebGL/GLSL |\n| `GL.UNSIGNED_SHORT` | `Uint16Array`          |                                       |\n| `GL.UNSIGNED_INT`   | `Uint32Array`          |                                       |\n| `GL.UNSIGNED_BYTE`  | `Uint8Array`           |                                       |\n| `GL.UNSIGNED_BYTE`  | `Uint8ClampedArray`    |                                       |\n| `GL.BYTE`           | `Int8Array`            |                                       |\n| `GL.SHORT`          | `Int16Array`           |                                       |\n| `GL.INT`            | `Int32Array`           |                                       |\n\n## Usage\n\n```js\nimport {GL, GLType} from '@loaders.gl/math';\n// Returns Int8Array.BYTES_PER_ELEMENT\nvar size = GLType.getSizeInBytes(GL.BYTE);\n```\n\n## Static Methods\n\n### GLType.fromTypedArray(typedArray: Typed Array | Function) : Number\n\nReturns the size, in bytes, of the corresponding datatype.\n\n- `glType` The component datatype to get the size of.\n\nReturns\n\nThe size in bytes.\n\nThrows\n\n- glType is not a valid value.\n\nGets the {@link ComponentDatatype} for the provided TypedArray instance.\n\n- array The typed array.\n\nReturns\n\nThe ComponentDatatype for the provided array, or undefined if the array is not a TypedArray.\n\n### GLType.getArrayType(glType: Number) : Function\n\nreturns the constructor of the array\n\n### static GLType.getByteSize(glType: Number) : Number\n\nReturns the size in bytes of one element of the provided WebGL type.\n\nEquivalent to `GLType.getArrayType(glType).BYTES_PER_ELEMENT`.\n\n### static GLType.validate(glType) : Boolean\n\nReturns `true` if `glType` is a valid WebGL data type.\n\n### static GLType.createTypedArray(glType : Number, buffer : ArrayBuffer [, byteOffset : Number [, length : Number]]) : TypedArray\n\nCreates a typed view of an array of bytes.\n\n- `glType` The type of typed array (ArrayBuffer view) to create.\n- `buffer` The buffer storage to use for the view.\n- `byteOffset`=`0` The offset, in bytes, to the first element in the view.\n- `length`= The number of elements in the view. Defaults to buffer length.\n\nReturns\n\n`Int8Array`|`Uint8Array`|`Int16Array`|`Uint16Array`|`Int32Array`|`Uint32Array`|`Float32Array`|`Float64Array` A typed array view of the buffer.\n\nThrows\n\n- `glType` is not a valid value.\n","slug":"modules/math/docs/api-reference/gl-type","title":"GLType"},{"excerpt":"LASLoader The  parses a point cloud in the LASER file format. Loader Characteristic File Extension ,  File Type Binary File Format LASER…","rawMarkdownBody":"# LASLoader\n\nThe `LASLoader` parses a point cloud in the LASER file format.\n\n| Loader                | Characteristic                                                                                                           |\n| --------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n| File Extension        | `.las`, `.laz`                                                                                                           |\n| File Type             | Binary                                                                                                                   |\n| File Format           | [LASER file format](https://www.asprs.org/divisions-committees/lidar-division/laser-las-file-format-exchange-activities) |\n| Data Format           | [PointCloud](docs/specifications/category-mesh.md)                                                                       |\n| Decoder Type          | Synchronous                                                                                                              |\n| Worker Thread Support | Yes                                                                                                                      |\n| Streaming Support     | No                                                                                                                       |\n\n## Usage\n\n```js\nimport {LASLoader} from '@loaders.gl/las';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, LASLoader, options);\n```\n\n## Options\n\n| Option               | Type     | Default | Description                                                               |\n| -------------------- | -------- | ------- | ------------------------------------------------------------------------- |\n| `options.las.skip`   | Number   | `1`     | Read one from every _n_ points.                                           |\n| `options.onProgress` | Function | -       | Callback when a new chunk of data is read. Only works on the main thread. |\n","slug":"modules/las/docs/api-reference/las-loader","title":"LASLoader"},{"excerpt":"Tile3DHeader The 3D tile loaders are still under development. The  class contains sufficient information about each tile in the tileset to…","rawMarkdownBody":"# Tile3DHeader\n\n> The 3D tile loaders are still under development.\n\nThe `Tile3DHeader` class contains sufficient information about each tile in the tileset to determine if that tile is visible from a certain viewing position (this information includes the tiles' bounding box, the list of its child tiles and a screen space error limit).\n\n\nNotes:\n- `Tile3DHeader`s are instantiated by the `Tileset3D` class for all the tiles in the tileset.\n- Additional `Tile3DHeader` instances can be created when \n- When a tile is first created, its content is not loaded; the content is loaded on-demand when that tile is determined to be in the view.\n\n## Fields\n\n### tileset : Tileset3D\n\nThe tileset containing this tile.\n\n### content : Tile3DContent\n\nThe tile's content. This represents the actual tile's payload,\nnot the content's metadata in the tileset JSON file.\n\n### boundingVolume : TileBoundingVolume\n\nGet the tile's bounding volume.\n\n### contentBoundingVolume : TileBoundingVolume\n\nGet the bounding volume of the tile's contents. This defaults to the\ntile's bounding volume when the content's bounding volume is\n`undefined`.\n\n### boundingSphere : BoundingSphere\n\nGet the bounding sphere derived from the tile's bounding volume.\n\n### extras : any\n\nReturns the `extras` property in the tileset JSON for this tile, which contains application specific metadata.\nReturns `undefined` if `extras` does not exist.\n\nSee [Extras in the 3D Tiles specification](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#specifying-extensions-and-application-specific-extras)\n\n\n### transform\n\nThe local transform of this tile.\n@type {Matrix4}\n\n### computedTransform\n\nThe final computed transform of this tile.\n@type {Matrix4}\n\nThe error, in meters, introduced if this tile is rendered and its children are not.\n\n\n### geometricError : number\n\nThis is used to compute screen space error, i.e., the error measured in pixels.\n\n### refinement : 3DTileRefine\n\nSpecifies the type of refinement that is used when traversing this tile for rendering.\n\n### children : Tile3dHeader[]\n\nGets the tile's children.\n\n### parent : Tile3DHeader | null;\n\nThis tile's parent or `undefined` if this tile is the root.\n\nWhen a tile's content points to an external tileset JSON file, the external tileset's root tile's parent is not `undefined`; instead, the parent references the tile (with its content pointing to an external tileset JSON file) as if the two tilesets were merged.\n\n\n### hasEmptyContent : boolean\n\nWhen `true`, the tile has no content.\n\n### hasTilesetContent : boolean\n\nWhen `true`, the tile's content points to an external tileset.\n\nThis is `false` until the tile's content is loaded.\n\n\n\n## Methods\n\n### constructor(tileset, baseResource, header, parent)\n\nNote: Do not construct this directly, instead access tiles through {@link Tileset3D#tileVisible}.\n\n### destroy()\n\nReleases resources managed by this tile.\n\n### getScreenSpaceError(frameState, useParentGeometricError) : Number\n\nGet the tile's screen space error.\n\n### updateVisibility(frameState) : void\n\nUpdate the tile's visibility.\n\n### loadContent()\n\nRequests the tile's content.\n\n### unloadContent()\n\nUnloads the tile's content.\n\n### visibility(frameState : FrameState, parentVisibilityPlaneMask : Number)\n\nDetermines whether the tile's bounding volume intersects the culling volume.\n\n- `frameState` The frame state.\n- `parentVisibilityPlaneMask` The parent's plane mask to speed up the visibility check.\n\nReturns\n- `Number` A plane mask as described in `CullingVolume.computeVisibilityWithPlaneMask`.\n\n\n### contentVisibility(frameState : FrameState)\n\nAssuming the tile's bounding volume intersects the culling volume, determines\nwhether the tile's content's bounding volume intersects the culling volume.\n- FrameState frameState The frame state.\n\nReturns\n{Intersect} The result of the intersection: the tile's content is completely outside, completely inside, or intersecting the culling volume.\n\n### distanceToTile(frameState : FrameState) : Number\n\nComputes the (potentially approximate) distance from the closest point of the tile's bounding volume to the camera.\n- FrameState frameState The frame state.\n\nReturns\n- `Number` The distance, in meters, or zero if the camera is inside the bounding volume.\n\n### distanceToTileCenter(frameState : FrameState)\n\nComputes the distance from the center of the tile's bounding volume to the camera.\n- FrameState frameState The frame state.\n\nReturns\n- `Number` The distance, in meters.\n\n### insideViewerRequestVolume(frameState : FrameState) : Boolean\n\nChecks if the camera is inside the viewer request volume.\n\n- `FrameState` frameState The frame state.\n\nReturns\n- `Boolean` Whether the camera is inside the volume.\n","slug":"modules/3d-tiles/wip/tile-3d-header","title":"Tile3DHeader"},{"excerpt":"Tileset3D The 3D tiles loaders are still under development. The definition of a 3D Tiles tileset. Usage Properties asset : Object (readonly…","rawMarkdownBody":"# Tileset3D\n\n> The 3D tiles loaders are still under development.\n\nThe definition of a [3D Tiles tileset](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification).\n\n## Usage\n\n```js\nconst tileset = new Tileset3D();\nconsole.log(`Maximum building height: ${tileset.properties.height.maximum}`);\nconsole.log(`Minimum building height: ${tileset.properties.height.minimum}`);\n```\n\n```js\nimport {Tileset3D} from '^loaders.gl/3d-tiles';\nconst tileset = new Tileset3D({\n  url: 'http://localhost:8002/tilesets/Seattle/tileset.json',\n  baseScreenSpaceError: 1024,\n  skipScreenSpaceErrorFactor: 16\n});\n```\n\n### Properties\n\n### asset : Object (readonly)\n\nGets the tileset's asset object property, which contains metadata about the tileset.\n\nSee the [asset schema reference](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#reference-asset) in the 3D Tiles spec for the full set of properties.\n\n\nGets the tileset's properties dictionary object, which contains metadata about per-feature properties.\n\nSee the [properties schema reference](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#reference-properties) in the 3D Tiles spec for the full set of properties.\n\nsee Cesium3DTileFeature#getProperty\nsee Cesium3DTileFeature#setProperty\n\n### ready\n\nWhen `true`, the tileset's root tile is loaded and the tileset is ready to render.\nThis is set to `true` right before `Tileset3D.readyPromise` is resolved.\n\n### readyPromise\n\nGets the promise that will be resolved when the tileset's root tile is loaded and the tileset is ready to render.\n\nThis promise is resolved at the end of the frame before the first frame the tileset is rendered in.\n\n\n```js\ntileset.readyPromise.then(function(tileset) {\n    // tile.properties is not defined until readyPromise resolves.\n    var properties = tileset.properties;\n    if (defined(properties)) {\n        for (var name in properties) {\n            console.log(properties[name]);\n        }\n    }\n});\n```\n\n### url : String (readonly)\n\nThe url to a tileset JSON file.\n\n### basePath : String (readonly) (deprecated)\n\nThe base path that non-absolute paths in tileset JSON file are relative to.\n\n### maximumScreenSpaceError\n\nThe maximum screen space error used to drive level of detail refinement. This value helps determine when a tile refines to its descendants, and therefore plays a major role in balancing performance with visual quality.\n\n\nA tile's screen space error is roughly equivalent to the number of pixels wide that would be drawn if a sphere with a\nradius equal to the tile's <b>geometric error</b> were rendered at the tile's position. If this value exceeds\n`maximumScreenSpaceError` the tile refines to its descendants.\n\nDepending on the tileset, `maximumScreenSpaceError` may need to be tweaked to achieve the right balance. Higher values provide better performance but lower visual quality.\n *\n\n### maximumMemoryUsage : Number\n\n^default 16\n *\n^exception `maximumScreenSpaceError` must be greater than or equal to zero.\n\nThe maximum amount of GPU memory (in MB) that may be used to cache tiles. This value is estimated from\ngeometry, textures, and batch table textures of loaded tiles. For point clouds, this value also\nincludes per-point metadata.\n\n\nTiles not in view are unloaded to enforce this.\n\nIf decreasing this value results in unloading tiles, the tiles are unloaded the next frame.\n\nIf tiles sized more than `maximumMemoryUsage` are needed\nto meet the desired screen space error, determined by `Tileset3D.maximumScreenSpaceError `,\nfor the current view, then the memory usage of the tiles loaded will exceed\n`maximumMemoryUsage`.  For example, if the maximum is 256 MB, but\n300 MB of tiles are needed to meet the screen space error, then 300 MB of tiles may be loaded.  When\nthese tiles go out of view, they will be unloaded.\n\n^default 512\n *\n^exception `maximumMemoryUsage` must be greater than or equal to zero.\n^see Tileset3D#gpuMemoryUsageInBytes\n\n### root : Tile3DHeader\n\nThe root tile header.\n\n\n### boundingSphere : BoundingSphere\n\nThe tileset's bounding sphere.\n\n\n```js\nvar tileset = viewer.scene.primitives.add(new Tileset3D({\nurl : 'http://localhost:8002/tilesets/Seattle/tileset.json'\n}));\n\ntileset.readyPromise.then(function(tileset) {\n// Set the camera to view the newly added tileset\nviewer.camera.viewBoundingSphere(tileset.boundingSphere, new HeadingPitchRange(0, -0.5, 0));\n});\n```\n\n### modelMatrix : Matrix4\n\nA 4x4 transformation matrix that transforms the entire tileset.\n\n```js\n// Adjust a tileset's height from the globe's surface.\nvar heightOffset = 20.0;\nvar boundingSphere = tileset.boundingSphere;\nvar cartographic = Cartographic.fromCartesian(boundingSphere.center);\nvar surface = Cartesian3.fromRadians(cartographic.longitude, cartographic.latitude, 0.0);\nvar offset = Cartesian3.fromRadians(cartographic.longitude, cartographic.latitude, heightOffset);\nvar translation = Cartesian3.subtract(offset, surface, new Cartesian3());\ntileset.modelMatrix = Matrix4.fromTranslation(translation);\n```\n\n\n### timeSinceLoad : Number\n\nReturns the time, in milliseconds, since the tileset was loaded and first updated.\n\n\n### maximumMemoryUsage : Number\n\n### gpuMemoryUsageInBytes : Number\n\nThe total amount of GPU memory in bytes used by the tileset. This value is estimated from\ngeometry, texture, and batch table textures of loaded tiles. For point clouds, this value also\nincludes per-point metadata.\n\n### statistics\n\n\n### classificationType (Experimental) readonly\n\nDetermines whether terrain, 3D Tiles or both will be classified by this tileset.\n\n\nThis option is only applied to tilesets containing batched 3D models, geometry data, or vector data. Even when undefined, vector data and geometry data\nmust render as classifications and will default to rendering on both terrain and other 3D Tiles tilesets.\n\nWhen enabled for batched 3D model tilesets, there are a few requirements/limitations on the glTF:\n<ul>\n    <li>POSITION and _BATCHID semantics are required.</li>\n    <li>All indices with the same batch id must occupy contiguous sections of the index buffer.</li>\n    <li>All shaders and techniques are ignored. The generated shader simply multiplies the position by the model-view-projection matrix.</li>\n    <li>The only supported extensions are CESIUM_RTC and WEB3D_quantized_attributes.</li>\n    <li>Only one node is supported.</li>\n    <li>Only one mesh per node is supported.</li>\n    <li>Only one primitive per mesh is supported.</li>\n</ul>\n\nThis feature is using part of the 3D Tiles spec that is not final and is subject to change without the standard deprecation policy.\n\n\n### ellipsoid : Ellipsoid\n\nGets an ellipsoid describing the shape of the globe.\n\nReturns the `extras` property at the top-level of the tileset JSON, which contains application specific metadata.\nReturns `undefined` if `extras` does not exist.\n\nException The tileset is not loaded. Use Tileset3D.readyPromise or wait for Tileset3D.ready to be true.\n\nSee [Extras](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#specifying-extensions-and-application-specific-extras) in the 3D Tiles specification.}\n\n\n### unloadTileset\n\nUnloads all tiles that weren't selected the previous frame. This can be used to\nexplicitly manage the tile cache and reduce the total number of tiles loaded below\n`Tileset3D.maximumMemoryUsage`.\n\nTile unloads occur at the next frame to keep all the WebGL delete calls\nwithin the render loop.\n\n### isDestroyed() : Boolean\n\nReturns true if this object was destroyed; otherwise, false.\n\nIf this object was destroyed, it should not be used; calling any function other than\n`isDestroyed` will result in an exception.\n\n^returns `Boolean`: `true` if this object was destroyed; otherwise, `false`.\n\n### destroy()\n\nDestroys the WebGL resources held by this object. Destroying an object allows for deterministic\nrelease of WebGL resources, instead of relying on the garbage collector to destroy this object.\n\nOnce an object is destroyed, it should not be used; calling any function other than `isDestroyed` will result in an exception. Therefore, assign the return value `undefined` to the object as done in the example.\n\nWxception This object was destroyed, i.e., destroy() was called.\n\n\n## Methods\n\n### constructor(tileset, url, options)\n\n- `tileset` (`Object`) - The loaded tileset (parsed JSON)\n- `url` - (`String) The url to a tileset JSON file.\n- `options` Options object, see  with the following properties:\n\nNotes:\n- The `version` tileset must be 3D Tiles version 0.0 or 1.0.\n\n\n### hasExtension(extensionName : String) : Boolean\n\n`true` if the tileset JSON file lists the extension in extensionsUsed; otherwise, `false`.\n^param {String} extensionName The name of the extension to check. \\*\n^returns {Boolean} `true` if the tileset JSON file lists the extension in extensionsUsed; otherwise, `false`.\n\n\n## Options\n\n\n- `options.url` (`Resource|String|Promise.Resource|Promise.String`) The url to a tileset JSON file.\n- `options.show`=`true` (`Boolean`) - Determines if the tileset will be shown.\n- `options.modelMatrix`=`Matrix4.IDENTITY` (`Matrix4`) - A 4x4 transformation matrix that transforms the tileset's root tile.\n- `options.maximumScreenSpaceError`=`16`] (`Number`) - The maximum screen space error used to drive level of detail refinement.\n- `options.maximumMemoryUsage`=`512`] (`Number`) - The maximum amount of memory in MB that can be used by the tileset.\n- `options.dynamicScreenSpaceError`=`false`] (`Boolean`) - Optimization option. Reduce the screen space error for tiles that are further away from the camera.\n- `options.dynamicScreenSpaceErrorDensity`=`0.00278`] (`Number`) - Density used to adjust the dynamic screen space error, similar to fog density.\n- `options.dynamicScreenSpaceErrorFactor`=`4.0`] (`Number`) - A factor used to increase the computed dynamic screen space error.\n- `options.skipLevelOfDetail`=`true` (`Boolean`) - Optimization option. Determines if level of detail skipping should be applied during the traversal.\n- `options.baseScreenSpaceError`=`1024` (`Number`) - When `skipLevelOfDetail` is `true`, the screen space error that must be reached before skipping levels of detail.\n- `options.ellipsoid`=`Ellipsoid.WGS84` (`Ellipsoid`) - The ellipsoid determining the size and shape of the globe.\n\nCallbacks\n- `options.onTileLoad` (`void(tileHeader)`) -\n- `options.onTileUnload` (`void(tileHeader)`) -\n- `options.onTileError` (`void(tileHeader, message : String)`) -\n\n\n### dynamicScreenSpaceError\n\n=`false`\n\nOptimization option. Whether the tileset should refine based on a dynamic screen space error. Tiles that are further away will be rendered with lower detail than closer tiles. This improves performance by rendering fewer tiles and making less requests, but may result in a slight drop in visual quality for tiles in the distance.\n\nThe algorithm is biased towards \"street views\" where the camera is close to the ground plane of the tileset and looking at the horizon. In addition results are more accurate for tightly fitting bounding volumes like box and region.\n\n### dynamicScreenSpaceErrorDensity\n\n=`0.00278`\n\nA scalar that determines the density used to adjust the dynamic screen space error (similar to \"fog\"). Increasing this value has the effect of increasing the maximum screen space error for all tiles, but in a non-linear fashion.\n\nThe error starts at 0.0 and increases exponentially until a midpoint is reached, and then approaches 1.0 asymptotically. This has the effect of keeping high detail in the closer tiles and lower detail in the further tiles, with all tiles beyond a certain distance all roughly having an error of 1.0.\n\n\nThe dynamic error is in the range [0.0, 1.0) and is multiplied by `dynamicScreenSpaceErrorFactor` to produce the\nfinal dynamic error. This dynamic error is then subtracted from the tile's actual screen space error.\n\nIncreasing `dynamicScreenSpaceErrorDensity` has the effect of moving the error midpoint closer to the camera.\nIt is analogous to moving fog closer to the camera.\n\n### dynamicScreenSpaceErrorFactor\n\n= 4.0;\n\nA factor used to increase the screen space error of tiles for dynamic screen space error. As this value increases less tiles\nare requested for rendering and tiles in the distance will have lower detail. If set to zero, the feature will be disabled.\n\n### onTileLoad(tileHeader : Tile3DHeader) : void\n\nIndicate ssthat a tile's content was loaded.\n\nThe loaded `Tile3DHeader` is passed to the event listener.\n\nThis event is fired during the tileset traversal while the frame is being rendered\nso that updates to the tile take effect in the same frame.  Do not create or modify\nentities or primitives during the event listener.\n\n```js\n  new Tileset3D({\n    onTileLoad(tileHeader => console.log('A tile was loaded.'));\n  });\n```\n\n### onTileUnload(tileHeader : Tile3DHeader) : void\n\nIndicates that a tile's content was unloaded.\n\nThe unloaded `Tile3DHeaders` is passed to the event listener.\n\nThis event is fired immediately before the tile's content is unloaded while the frame is being\nrendered so that the event listener has access to the tile's content.  Do not create\nor modify entities or primitives during the event listener.\n\n```js\n  new Tileset3D({\n    onTileUnload(tile =>  console.log('A tile was unloaded from the cache.'));\n  });\n```\n\nSee\n- Tileset3D#maximumMemoryUsage\n- Tileset3D#trimLoadedTiles\n\n\n### onTileError(tileHeader : Tile3DHeader) : void\n\nCalled to indicate that a tile's content failed to load. By default, error messages will be logged to the console.\n\nThe error object passed to the listener contains two properties:\n- `url`: the url of the failed tile.\n- `message`: the error message.\n\n```js\n  new Tileset3D({\n    onTileFailed(tileHeader, url, message) {\n      console.log('An error occurred loading tile: ', url);\n      console.log('Error: ', message);\n    }\n  });\n```\n\n### skipLevelOfDetail : Boolean\n\nDefault: true\n\nOptimization option. Determines if level of detail skipping should be applied during the traversal.\n\nThe common strategy for replacement-refinement traversal is to store all levels of the tree in memory and require\nall children to be loaded before the parent can refine. With this optimization levels of the tree can be skipped\nentirely and children can be rendered alongside their parents. The tileset requires significantly less memory when\nusing this optimization.\n\n\n### baseScreenSpaceError : Number\n\nDefault: 1024\n\nThe screen space error that must be reached before skipping levels of detail.\n\nOnly used when `skipLevelOfDetail` is `true`.\n\n### skipScreenSpaceErrorFactor : Number\n\nDefault: 16\n\nMultiplier defining the minimum screen space error to skip.\nFor example, if a tile has screen space error of 100, no tiles will be loaded unless they\nare leaves or have a screen space error `<= 100 / skipScreenSpaceErrorFactor`.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n\n### skipLevels\n\nDefault: 1\n\nConstant defining the minimum number of levels to skip when loading tiles. When it is 0, no levels are skipped.\nFor example, if a tile is level 1, no tiles will be loaded unless they are at level greater than 2.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n\n### immediatelyLoadDesiredLevelOfDetail : false\n\nWhen true, only tiles that meet the maximum screen space error will ever be downloaded.\nSkipping factors are ignored and just the desired tiles are loaded.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n\n### loadSiblings: false\n\nDetermines whether siblings of visible tiles are always downloaded during traversal.\nThis may be useful for ensuring that tiles are already available when the viewer turns left/right.\n\nOnly used when `Tileset3D.skipLevelOfDetail` is `true`.\n","slug":"modules/3d-tiles/wip/tileset-3d-full","title":"Tileset3D"},{"excerpt":"WIP Partly ported code from Cesium repo.","rawMarkdownBody":"# WIP\n\nPartly ported code from Cesium repo.\n","slug":"modules/3d-tiles/wip","title":"WIP"},{"excerpt":"Overview  The  module supports loading and traversing 3D Tiles. References 3D Tiles Specification - The living specification. 3D Tiles…","rawMarkdownBody":"# Overview\n\n![logo](./images/3d-tiles-small.png)\n\nThe `@loaders.gl/3d-tiles` module supports loading and traversing 3D Tiles.\n\nReferences\n\n- [3D Tiles Specification](https://github.com/AnalyticalGraphicsInc/3d-tiles) - The living specification.\n- [3D Tiles Standard](https://www.opengeospatial.org/standards/3DTiles) - The official standard from [OGC](https://www.opengeospatial.org/), the Open Geospatial Consortium.\n\n## Installation\n\n```bash\nnpm install @loaders.gl/3d-tiles\nnpm install @loaders.gl/core\n```\n\n## API\n\nA standard complement of loaders and writers are provided to load the individual 3d Tile file formats:\n\n- [`Tiles3DLoader`](modules/3d-tiles/docs/api-reference/tiles-3d-loader), a loader for loading a top-down or nested tileset and its tiles.\n- [`CesiumIonLoader`](modules/3d-tiles/docs/api-reference/cesium-ion-loader), a loader extends from `Tiles3DLoader` with resolving credentials from Cesium ion.\n\nTo handle the complex dynamic tile selection and loading required to performantly render larger-than-browser-memory tilesets, additional helper classes are provided in `@loaders.gl/tiles` module:\n\n- [`Tileset3D`](modules/3d-tiles/docs/api-reference/tileset-3d) to work with the loaded tileset.\n- [`Tile3D`](modules/3d-tiles/docs/api-reference/tile-3d) to access data for a specific tile.\n\n## Usage\n\nBasic API usage is illustrated in the following snippet. Create a `Tileset3D` instance, point it a valid tileset URL, set up callbacks, and keep feeding in new camera positions:\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {Tiles3DLoader} from '@loaders.gl/3d-tiles';\nimport {Tileset3D} from '@loaders.gl/tiles';\n\nconst tilesetUrl = ''; // add the url to your tileset.json file here\n\nconst tilesetJson = await load(tilesetUrl, Tiles3DLoader);\n\nconst tileset3d = new Tileset3D(tilesetJson, {\n  onTileLoad: tile => console.log(tile)\n});\n\n// initial viewport\ntileset3d.update(viewport);\n\n// Viewport changes (pan zoom etc)\ntileset3d.update(viewport);\n\n// Visible tiles\nconst visibleTiles = tileset3d.tiles.filter(tile => tile.selected);\n\n// Note that visibleTiles will likely not immediately include all tiles\n// tiles will keep loading and file `onTileLoad` callbacks\n```\n\n## Remarks\n\n`@loaders.gl/3d-tiles` does not yet support the full 3D tiles standard. Notable omissions are:\n\n- [Region bounding volumes](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#bounding-volume) are supported but not optimally\n- [Styling](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification/Styling) is not yet supported\n- [Viewer request volumes](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#viewer-request-volume) are not yet supported\n\n## Attribution\n\n`@loaders.gl/3d-tiles` is a fork of 3D tile related code in the [Cesium github repository](https://github.com/AnalyticalGraphicsInc/cesium) under Apache 2 License, and is developed in collabration with the Cesium engineering team.\n","slug":"modules/3d-tiles/docs","title":"Overview"},{"excerpt":"KMLLoader The  parses KML files into GeoJSON. Loader Characteristic File Extension  File Type Text File Format KML Data Format GIS Decoder…","rawMarkdownBody":"# KMLLoader\n\nThe `KMLLoader` parses KML files into GeoJSON.\n\n| Loader                | Characteristic                                               |\n| --------------------- | ------------------------------------------------------------ |\n| File Extension        | `.kml`                                                       |\n| File Type             | Text                                                         |\n| File Format           | [KML](https://en.wikipedia.org/wiki/Keyhole_Markup_Language) |\n| Data Format           | [GIS](docs/specifications/category-gis.md)                   |\n| Decoder Type          | Synchronous                                                  |\n| Worker Thread Support | No                                                           |\n| Streaming Support     | No                                                           |\n\n## Usage\n\n```js\nimport {KMLLoader} from '@loaders.gl/kml';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, KMLLoader, options);\n```\n\n## Options\n\n| Option            | Type    | Default | Description                                                                                                |\n| ----------------- | ------- | ------- | ---------------------------------------------------------------------------------------------------------- |\n| `useLngLatFormat` | Boolean | `true`  | KML longitudes and latitudes are specified as `[lat, lng]`. This option \"normalizes\" them to `[lng, lat]`. |\n| `useColorArrays`  | Boolean | `true`  | Convert color strings to arrays.                                                                           |\n\n## Limitations\n\n- Currently XML parsing is only implemented in browsers, not in Node.js. Check `KMLLoader.supported` to check at run-time.\n","slug":"modules/kml/docs/api-reference/kml-loader","title":"KMLLoader"},{"excerpt":"Binary Image Utilities Utilities to extract metadata such as image format and size (dimensions) from binary images without parsing the full…","rawMarkdownBody":"# Binary Image Utilities\n\nUtilities to extract metadata such as image format and size (dimensions) from binary images without parsing the full image. Works by by looking for format-specific headers in the encoded binary data (e.g. encoded JPEG or PNG images).\n\nThe format is reported using MIME types strings. Supported binary formats and their MIME types are:\n\n| Format | MIME Type    |\n| ------ | ------------ |\n| PNG    | `image/png`  |\n| JPEG   | `image/jpeg` |\n| BMP    | `image/bmp`  |\n| GIF    | `image/gif`  |\n\n## Usage\n\n```js\nconst response = await fetchFile(imageUrl);\nconst arrayBuffer = await response.arrayBuffer();\n\nconst mimeType = getBinaryImageMIMEType(arrayBuffer);\nconst {width, height} = getBinaryImageSize(arrayBuffer, mimeType);\n```\n\n## Functions\n\n### isBinaryImage(imageData : ArrayBuffer [, mimeType : String]) : Boolean\n\nParameters:\n\n- `imageData`: Binary encoded image data.\n- `mimeType`: A MIME type string.\n\nReturns `true` if the binary data represents a known binary image format or matches the supplied `mimeType`.\n\nParameters:\n\n- `mimeType`: If supplied, checks if the image is of that type. If not supplied, returns `true` if imageData corresponds to a know supported image format.\n\n### getBinaryImageMIMEType(imageData : ArrayBuffer) : String | null\n\nParameters:\n\n- `imageData`: Binary encoded image data.\n\nReturns:\n\n- the MIME type of the image represented by the data, or `null` if it could not be identified.\n\n### getBinaryImageSize(imageData : ArrayBuffer, mimeType? : String) : Object\n\nExtracts the size of the image in `imageData`.\n\nParameters:\n\n- `imageData`: Binary encoded image data.\n- `mimeType`: A MIME type string\n\nReturns:\n\n- an object with fields containing the size of the image represented by the data.\n\n```js\n{\n  width: Number,\n  height: Number\n}\n```\n\nThrows:\n\n- if image is not in a supported binary format.\n\nIf `mimeType` is supplied, assumes the image is of that type. If not supplied, first attempts to auto deduce the image format (see `getImageMIMEType`).\n","slug":"modules/images/docs/api-reference/binary-image-api","title":"Binary Image Utilities"},{"excerpt":"JSONLoader Streaming loader for JSON encoded files. Loader Characteristic File Extension , File Type Text File Format JSON Data Format…","rawMarkdownBody":"# JSONLoader\n\nStreaming loader for JSON encoded files.\n\n| Loader         | Characteristic                                       |\n| -------------- | ---------------------------------------------------- |\n| File Extension | `.json`,                                             |\n| File Type      | Text                                                 |\n| File Format    | [JSON](https://www.json.org/json-en.html)            |\n| Data Format    | [Classic Table](/docs/specifications/category-table) |\n| Supported APIs | `load`, `parse`, `parseSync`, `parseInBatches`       |\n\n## Usage\n\n```js\nimport {JSONLoader} from '@loaders.gl/json';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, JSONLoader, {json: options});\n```\n\nThe JSONLoader supports streaming JSON parsing, in which case it will yield \"batches\" of rows from the first array it encounters in the JSON. To e.g. parse a stream of GeoJSON:\n\n```js\nimport {JSONLoader} from '@loaders.gl/json';\nimport {load} from '@loaders.gl/core';\n\nconst data = await loadInBatches('geojson.json', JSONLoader);\n\nfor await (const batch of batches) {\n  // batch.data will contain a number of rows\n  for (const feature of batch.data) {\n    switch (feature.geometry.type) {\n      case 'Polygon':\n      ...\n    }\n  }\n}\n```\n\nWhen batch parsing an embedded JSON array as a table, it is possible to get access to the containing object using the `{json: {_rootObjectBatches: true}}` option.\n\nThe loader will yield an initial and a final batch with `batch.container` providing the container object and `batch.batchType` set to `root-object-batch-partial` and `root-object-batch-complete` respectively.\n\n```js\nimport {JSONLoader} from '@loaders.gl/json';\nimport {load} from '@loaders.gl/core';\n\nconst data = await loadInBatches('geojson.json', JSONLoader);\n\nfor await (const batch of batches) {\n  switch (batch.batchType) {\n    case 'root-object-batch-partial': // contains fields seen so far\n    case 'root-object-batch-complete': // contains all fields except the streamed array\n      console.log(batch.container);\n      break;\n    default:\n    // batch.data will contain a number of rows\n    for (const feature of batch.data) {\n      switch (feature.geometry.type) {\n        case 'Polygon':\n        ...\n      }\n    }\n  }\n}\n```\n\n## Options\n\nSupports table category options such as `batchType` and `batchSize`.\n\n| Option                    | From | Type    | Default | Description                                                                                                                           |\n| ------------------------- | ---- | ------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n| `json.table`              | v2.0 | Boolean | `false` | Parses non-streaming JSON as table, i.e. return the first embedded array in the JSON. Always `true` during batched/streaming parsing. |\n| `json._rootObjectBatches` | v2.1 | Boolean | `false` | Yield an initial and final batch containing the partial and complete root object (excluding the array being streamed).                |\n\n## Attribution\n\nThis loader is based on a fork of dscape's [`clarinet`](https://github.com/dscape/clarinet) under BSD 2-clause license.\n","slug":"modules/json/docs/api-reference/json-loader","title":"JSONLoader"},{"excerpt":"ImageLoader An image loader that works under both Node.js (requires ) and the browser. Loader Characteristic File Extension…","rawMarkdownBody":"# ImageLoader\n\nAn image loader that works under both Node.js (requires `@loaders.gl/polyfills`) and the browser.\n\n| Loader         | Characteristic                                                   |\n| -------------- | ---------------------------------------------------------------- |\n| File Extension | `.png`, `.jpg`, `.jpeg`, `.gif`, `.webp`, `.bmp`, `.ico`, `.svg` |\n| File Type      | Binary                                                           |\n| File Format    | Image                                                            |\n| Data Format    | `ImageBitmap`, `Image` (older browsers) or `data` (node.js)      |\n| Supported APIs | `load`, `parse`                                                  |\n\n## Usage\n\n```js\nimport '@loaders.gl/polyfills'; // only needed if using under Node\nimport {ImageLoader} from '@loaders.gl/images';\nimport {load} from '@loaders.gl/core';\n\nconst image = await load(url, ImageLoader, options);\n```\n\n## Options\n\n| Option         | Type    | Default  | Description                                                                                          |\n| -------------- | ------- | -------- | ---------------------------------------------------------------------------------------------------- |\n| `image.type`   | String  | `'auto'` | Set to `data`, `imagebitmap` or `image` to control type of returned image.                           |\n| `image.decode` | boolean | `true`   | Applies to `image` type images only, ensures image is fully decoded before loading promise resolves. |\n\n### ImageBitmap Options\n\nIn addition, for `imagebitmap` type images, it is possible to pass through options to [`createImageBitmap`](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/createImageBitmap) to control image extraction, via the separate `options.imagebitmap` object. However, for portability it may be best to avoid relying on these options for now, since some browsers do not support `ImageBitmap` options (and some browsers do not support `ImageBitmap`s at all).\n\n| Option                             | Type   | Default     | Description                                                                                                                   |\n| ---------------------------------- | ------ | ----------- | ----------------------------------------------------------------------------------------------------------------------------- |\n| `imagebitmap.imageOrientation`     | string | `'none'`    | image should be flipped vertically. Either `'none'` or `'flipY'`.                                                             |\n| `imagebitmap.premultiplyAlpha`     | string | `'default'` | Premultiply color channels by the alpha channel. One of `'none'`, `'premultiply'`, or `'default'`.                            |\n| `imagebitmap.colorSpaceConversion` | string | `'default'` | Decode using color space conversion. Either `'none'` or `'default'` default indicates implementation-specific behavior.       |\n| `imagebitmap.resizeWidth`          | number | -           | Output image width.                                                                                                           |\n| `imagebitmap.resizeHeight`         | number | -           | Output image height.                                                                                                          |\n| `imagebitmap.resizeQuality`        | string | `'low'`     | Algorithm to be used for resizing the input to match the output dimensions. One of pixelated, low (default), medium, or high. |\n\nPortability note: The exact set of `imagebitmap` options supported may depend on the browser.\n\n## Remarks\n\n- While generic, the `ImageLoader` is designed with WebGL applications in mind, ensuring that loaded image data can be used to create a `WebGLTexture` both in the browser and in headless gl under Node.js\n- Node.js support requires import `@loaders.gl/polyfills` before installing this module.\n","slug":"modules/images/docs/api-reference/image-loader","title":"ImageLoader"},{"excerpt":"ImageWriter The  class can encode an image into  both under browser and Node.js Loader Characteristic File Extension , ,  File Format Binary…","rawMarkdownBody":"# ImageWriter\n\nThe `ImageWriter` class can encode an image into `ArrayBuffer` both under browser and Node.js\n\n| Loader         | Characteristic          |\n| -------------- | ----------------------- |\n| File Extension | `.png`, `.jpg`, `.jpeg` |\n| File Format    | Binary                  |\n| Data Format    | `ArrayBuffer`           |\n| File Format    | Image                   |\n| Encoder Type   | Asynchronous            |\n| Worker Thread  | No                      |\n| Streaming      | No                      |\n\n## Usage\n\n```js\nimport '@loaders.gl/polyfill'; // only if using under Node\nimport {ImageWriter} from '@loaders.gl/images';\nimport {encode} from '@loaders.gl/core';\n\nconst image = await encode(arrayBuffer, ImageWriter, options);\n```\n\n## Options\n\n| Option | Type   | Default | Description   |\n| ------ | ------ | ------- | ------------- |\n| `type` | String | `'png'` | image type \\* |\n\n\\* Supported image types (MIME types) depends on the environment. Typically PNG and JPG are supported.\n","slug":"modules/images/docs/api-reference/image-writer","title":"ImageWriter"},{"excerpt":"loadImages A function that loads an array of images. Primarily intended for loading: an array of images for a WebGL  or  textures an array…","rawMarkdownBody":"# loadImages\n\nA function that loads an array of images. Primarily intended for loading:\n\n- an array of images for a WebGL `TEXTURE_2D_ARRAY` or `TEXTURE_3D` textures\n- an array of images representing mip levels of a single WebGL `TEXTURE_2D` texture or one `TEXTURE_CUBE` face.\n\n## Usage\n\nLoading an array of images\n\n```js\nimport '@loaders.gl/polyfills'; // only needed for Node.js support\nimport {loadImageArray} from `@loaders.gl/images`;\n\nconst images = await loadImageArray(count, ({index}) => `filename-${index}`);\n\nfor (const image of images) {\n  ...\n}\n```\n\n```js\nimport '@loaders.gl/polyfills'; // only needed for Node.js support\nimport {loadImageArray} from `@loaders.gl/images`;\n\nconst images = await loadImageArray(count,  ({index}) => `filename-${index}`, {\n  mipLevels: 'auto'\n});\n\nfor (const imageArray of images) {\n  for (const lodImage of imageArray) {\n    ...\n  }\n}\n```\n\n## getUrl Callback Parameters\n\nthe `getUrl` callback will be called for each image with the following parameters:\n\n| Parameter | Description                                                    |\n| --------- | -------------------------------------------------------------- |\n| `index`   | The index of the image being loaded, from `0` to `count - 1`.  |\n| `lod`     | The mip level image being loaded, from `0` to `mipLevels - 1`. |\n\nNote: In addition to these values, all `options` passed in to `loadImageArray` are also available in the `getUrl` method.\n\n### loadImageArray(count : Number | String, getUrl : ({index}) => String, options? : Object) : image[] | image[][]\n\nParameters:\n\n- `count`: Number of images to load.\n- `getUrl`: A function that generates the url for each image, it is called for each image with the `index` of that image.\n- `options`: Supports the same options as [`ImageLoader`](modules/images/docs/api-reference/image-loader).\n\nReturns\n\n- an array of images (or array of arrays of mip images)\n\n## Options\n\nAccepts the same options as [`ImageLoader`](modules/images/docs/api-reference/image-loader), and\n\n| Option            | Type              | Default | Description                                            |\n| ----------------- | ----------------- | ------- | ------------------------------------------------------ |\n| `image.mipLevels` | `Number | String` | `0`     | If `'auto'` or non-zero, loads an array of mip images. |\n\nNumber of mip level images to load: Use `0` to indicate a single image with no mips. Supplying the string `'auto'` will infer the mipLevel from the size of the `lod`=`0` image.\n\n## Remarks\n\n- Returned images can be passed directly to WebGL texture methods. See [`ImageLoader`](modules/images/docs/api-reference/image-loader) for details about the type of the returned images.\n","slug":"modules/images/docs/api-reference/load-image-array","title":"loadImages"},{"excerpt":"loadCubeImages A function that loads 6 images representing the faces of a cube. Primarily intended for loading images for WebGL  textures…","rawMarkdownBody":"# loadCubeImages\n\nA function that loads 6 images representing the faces of a cube. Primarily intended for loading images for WebGL `GL.TEXTURE_CUBE` textures.\n\n## Usage\n\nLoad images for a cubemap with one image per face\n\n```js\nimport '@loaders.gl/polyfills'; // only needed for Node.js support\nimport {loadImageCube} from `@loaders.gl/images`;\n\nconst imageCube = await loadImageCube(({direction}) => `diffuse-${direction}.png`);\n\nfor (const face in imageCube) {\n  const image = imageCube[face];\n}\n```\n\nLoad images for a cubemap with an array of mip images per face\n\n```js\nimport '@loaders.gl/polyfills'; // only needed for Node.js support\nimport {loadImageCube} from `@loaders.gl/images`;\n\nconst imageCube = await loadImageCube('mips', ({direction}) => `diffuse-${direction}.png`);\n\nfor (const face in imageCube) {\n  const imageArray = imageCube[face];\n  for (const lodImage of imageArray) {\n    ...\n  }\n}\n```\n\n## getUrl Callback Parameters\n\nThe following fields will be supplied as named parameters to the `getUrl` function when loading cube maps:\n\n| `faceIndex` | `face`                                    | `direction` | `axis` | `sign`       |\n| ----------- | ----------------------------------------- | ----------- | ------ | ------------ |\n| 0           | `GL.TEXTURE_CUBE_MAP_POSITIVE_X` (0x8515) | `'right'`   | `'x'`  | `'positive'` |\n| 1           | `GL.TEXTURE_CUBE_MAP_NEGATIVE_X` (0x8516) | `'left'`    | `'x'`  | `'negative'` |\n| 2           | `GL.TEXTURE_CUBE_MAP_POSITIVE_Y` (0x8517) | `'top'`     | `'y'`  | `'positive'` |\n| 3           | `GL.TEXTURE_CUBE_MAP_NEGATIVE_Y` (0x8518) | `'bottom'`  | `'y'`  | `'negative'` |\n| 4           | `GL.TEXTURE_CUBE_MAP_POSITIVE_Z` (0x8519) | `'front'`   | `'z'`  | `'positive'` |\n| 5           | `GL.TEXTURE_CUBE_MAP_NEGATIVE_Z` (0x851a) | `'back'`    | `'z'`  | `'negative'` |\n\nNote: In addition to these values, all `options` passed in to `loadImageCube` are also available in the `getUrl` method.\n\n### loadImageCube(getUrl : ({face, direction, index}) => String, options? : Object) : Object\n\nLoads and image cube, i.e. 6 images keyed by WebGL face constants (see table).\n\nParameters:\n\n- `getUrl`: A function that generates the url for each image, it is called for each image with the `index` of that image.\n- `options`: Supports the same options as [`ImageLoader`](modules/images/docs/api-reference/image-loader).\n\nReturns\n\n- An object with 6 key/value pairs containing images (or arrays of mip images) for for each cube face. They keys are the (stringified) numeric values of the GL constant for the respective faces of the cube\n\n## Options\n\nAccepts the same options as [`ImageLoader`](modules/images/docs/api-reference/image-loader), and\n\n| Option            | Type              | Default | Description                                            |\n| ----------------- | ----------------- | ------- | ------------------------------------------------------ |\n| `image.mipLevels` | `Number | String` | `0`     | If `'auto'` or non-zero, loads an array of mip images. |\n\nNumber of mip level images to load: Use `0` to indicate a single image with no mips. Supplying the string `'auto'` will infer the mipLevel from the size of the `lod`=`0` image.\n\n## Remarks\n\n- Returned images can be passed directly to WebGL texture methods. See [`ImageLoader`](modules/images/docs/api-reference/image-loader) for details about the type of the returned images.\n","slug":"modules/images/docs/api-reference/load-image-cube","title":"loadCubeImages"},{"excerpt":"loadImage Usage Function loadImage(getUrl : String | Function, options? : Object]) : image | image[] A basic image loading function for…","rawMarkdownBody":"# loadImage\n\n## Usage\n\n```js\nimport '@loaders.gl/polyfills'; // only needed if using under Node\nimport {loadImage} from `@loaders.gl/images`;\n\nconst image = await loadImage(url);\n```\n\n```js\nimport '@loaders.gl/polyfills'; // only needed if using under Node\nimport {loadImage} from `@loaders.gl/images`;\n\nconst URL = ...;\n\nconst image = await loadImage(({lod}) => `${URL}-${lod}.jpg`, {\n  image: {\n    mipLevels: 'auto'\n  }\n});\n\nfor (const lodImage of imageArray) {\n  ...\n}\n```\n\n## Function\n\n### loadImage(getUrl : String | Function, options? : Object]) : image | image[]\n\nA basic image loading function for loading a single image (or an array of mipmap images representing a single image).\n\n- `getUrl`: A function that generates the url for each image, it is called for each image with the `lod` of that image.\n- `options`: Supports the same options as [`ImageLoader`](modules/images/docs/api-reference/image-loader).\n\nReturns\n\n- image or array of images\n\n## Options\n\nAccepts the same options as [`ImageLoader`](modules/images/docs/api-reference/image-loader), and\n\n| Option            | Type              | Default | Description                                            |\n| ----------------- | ----------------- | ------- | ------------------------------------------------------ |\n| `image.mipLevels` | `Number | String` | `0`     | If `'auto'` or non-zero, loads an array of mip images. |\n\nNumber of mip level images to load: Use `0` to indicate a single image with no mips. Supplying the string `'auto'` will infer the mipLevel from the size of the `lod`=`0` image.\n","slug":"modules/images/docs/api-reference/load-image","title":"loadImage"},{"excerpt":"I3SLoader The  is experimental. Currently only support I3S  data format. A loader for loading an Indexed 3d Scene (I3S) layer, and its…","rawMarkdownBody":"# I3SLoader\n\n> The `I3SLoader` is experimental. Currently only support I3S `MeshPyramids` data format.\n\nA loader for loading an [Indexed 3d Scene (I3S) layer](https://github.com/Esri/i3s-spec), and its geometries and textures data.\n\n| Loader         | Characteristic                                      |\n| -------------- | --------------------------------------------------- |\n| File Format    | [I3S Layer](https://github.com/Esri/i3s-spec)       |\n| File Type      | Json, Binary                                        |\n| File Extension | `.json` (layer), `.bin` (geometries)                |\n| File Format    | [i3s](https://www.opengeospatial.org/standards/i3s) |\n| Data Format    | [Data formats](#data-formats)                       |\n| Supported APIs | `load`, `parse`                                     |\n\n## Terms\n\nThe terms and concepts used in `i3s` module have the corresponding parts [I3S Spec](https://github.com/Esri/i3s-spec/blob/master/format/Indexed%203d%20Scene%20Layer%20Format%20Specification.md).\n\n- `tileset`: I3S Indexed 3D Layer File.\n- `tile`: I3S node file.\n- `tileContent`: I3S node content: geometries, textures, etc.\n\n## Usage\n\nWhen using loaders.gl's generic [`load`](https://loaders.gl/modules/core/docs/api-reference/load#load) function, user needs explicitly specify `I3Sloader` as auto detect loader from previously [`registered loaders`](https://loaders.gl/modules/core/docs/api-reference/register-loaders) is currently not supported for`I3Sloader`.\n\n```js\nimport {I3SLoader} from '@loaders.gl/i3s';\nimport {load} from '@loaders.gl/core';\n\n// load tileset\nconst tileseturl =\n  'https://tiles.arcgis.com/tiles/z2tnIkrLQ2BRzr6P/arcgis/rest/services/SanFrancisco_Bldgs/SceneServer/layers/0';\nconst tileset = await load(tileseturl, I3SLoader, {token: '<token-to-fetch-data>'});\n\n// load tile with content\nconst tileUrl =\n  'https://tiles.arcgis.com/tiles/z2tnIkrLQ2BRzr6P/arcgis/rest/services/SanFrancisco_Bldgs/SceneServer/layers/0/nodes/2';\nconst tile = await load(tileUrl, I3SLoader, {i3s: {loadContent: true}});\n\n// load tile content\n// featureUrl is needed to load the tile content\nconst tileUrl =\n  'https://tiles.arcgis.com/tiles/z2tnIkrLQ2BRzr6P/arcgis/rest/services/SanFrancisco_Bldgs/SceneServer/layers/0/nodes/2/geometries/0';\nawait load(tileUrl, I3SLoader, {tile});\n// load to `tile.content`\n```\n\n## Options\n\n| Option                     | Type             | Default | Description                                                                                                                                                                                                                                                                                                                     |\n| -------------------------- | ---------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `options.i3s.isTileset`    | `Bool` or `null` | `null`  | Whether to load `Tileset` (Layer 3D Index) file. If not specifies, will decide if follow `ArcGIS` tile layers' url convention                                                                                                                                                                                                   |\n| `options.i3s.isTileHeader` | `Bool` or `null` | `null`  | Whether to load `TileHeader`(node) file. If not specifies, will decide if follow `argis` url convention                                                                                                                                                                                                                         |\n| `options.i3s.loadContent`  | `Bool`           | `true`  | Whether to load tile content (geometries, texture, etc.). Note: I3S dataset, each tile node has separate urls pointing to tile metadata and its actual tile payload. If `loadContent` is true, i3s loader will make a request to fetch the content fiile and decoded to the format as specified in [Tile Object](#tile-object). |\n| `options.i3s.tileset`      | `Object`         | `null`  | `Tileset` object loaded by I3SLoader or follow the data format specified in [Tileset Object](#tileset-object). It is required when loading i3s geometry content                                                                                                                                                                 |\n| `options.i3s.tile`         | `Object`         | `null`  | `Tile` object loaded by I3SLoader or follow the data format [Tile Object](#tile-object). It is required when loading i3s geometry content                                                                                                                                                                                       |\n\n## Data formats\n\nThis section specifies the loaded data formats.\n\n### Tileset Object\n\nThe following fields are guaranteed. Additionally, the loaded tileset object will contain all the data fetched from the provided url.\n\n| Field            | Type     | Contents                                                                                                                                                                                                                                                                         |\n| ---------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `loader`         | `Object` | I3SLoader                                                                                                                                                                                                                                                                        |\n| `root`           | `Object` | The root tile header object                                                                                                                                                                                                                                                      |\n| `url`            | `String` | The url of this tileset                                                                                                                                                                                                                                                          |\n| `type`           | `String` | Value is `i3s`. Indicates the returned object is an `i3s` tileset.                                                                                                                                                                                                               |\n| `lodMetricType`  | `String` | Root's level of detail (LoD) metric type, which is used to decide if a tile is sufficient for current viewport. Only support `maxScreenThreshold` for now. Check I3S [lodSelection](https://github.com/Esri/i3s-spec/blob/master/docs/1.7/lodSelection.cmn.md) for more details. |\n| `lodMetricValue` | `Number` | Root's level of detail (LoD) metric value.                                                                                                                                                                                                                                       |\n\n### Tile Object\n\nThe following fields are guaranteed. Additionally, the loaded tile object will contain all the data fetched from the provided url.\n\n| Field            | Type     | Contents                                                                                                                                                                                                                                                                                 |\n| ---------------- | -------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `url`            | `String` | The url of this tile.                                                                                                                                                                                                                                                                    |\n| `contentUrl`     | `String` | The url of this tile.                                                                                                                                                                                                                                                                    |\n| `featureUrl`     | `String` | The url of this tile.                                                                                                                                                                                                                                                                    |\n| `textureUrl`     | `String` | The url of this tile.                                                                                                                                                                                                                                                                    |\n| `boundingVolume` | `Object` | A bounding volume in Cartesian coordinates converted from i3s node's [`mbs`](https://github.com/Esri/i3s-spec/blob/master/format/Indexed%203d%20Scene%20Layer%20Format%20Specification.md) that encloses a tile or its content. Exactly one box, region, or sphere property is required. |\n| `lodMetricType`  | `String` | Level of Detail (LoD) metric type, which is used to decide if a tile is sufficient for current viewport. Only support `maxScreenThreshold` for now. Check I3S [lodSelection](https://github.com/Esri/i3s-spec/blob/master/docs/1.7/lodSelection.cmn.md) for more details.                |\n| `lodMetricValue` | `String` | Level of Detail (LoD) metric value.                                                                                                                                                                                                                                                      |\n| `children`       | `Array`  | An array of objects that define child tiles. Each child tile content is fully enclosed by its parent tile's bounding volume and, generally, has more details than parent. for leaf tiles, the length of this array is zero, and children may not be defined.                             |\n| `content`        | `String` | The actual payload of the tile or the url point to the actual payload. If `option.loadContent` is enabled, content will be populated with the loaded value following the Tile Content section                                                                                            |\n| `id`             | `String` | Identifier of the tile, unique in a tileset                                                                                                                                                                                                                                              |\n| `refine`         | `String` | Refinement type of the tile, currently only support `REPLACE`                                                                                                                                                                                                                            |\n| `type`           | `String` | Type of the tile, value is `mesh` (currently only support [I3S MeshPyramids](https://github.com/Esri/i3s-spec)                                                                                                                                                                           |\n\n### Tile Content\n\nAfter content is loaded, the following fields are guaranteed. But different tiles may have different extra content fields.\n\n| Field                | Type         | Contents                                                                                                                               |\n| -------------------- | ------------ | -------------------------------------------------------------------------------------------------------------------------------------- |\n| `cartesianOrigin`    | `Number[3]`  | \"Center\" of tile geometry in WGS84 fixed frame coordinates                                                                             |\n| `cartographicOrigin` | `Number[3]`  | \"Origin\" in lng/lat (center of tile's bounding volume)                                                                                 |\n| `modelMatrix`        | `Number[16]` | Transforms tile geometry positions to fixed frame coordinates                                                                          |\n| `vertexCount`        | `Number`     | Transforms tile geometry positions to fixed frame coordinates                                                                          |\n| `attributes`         | `Object`     | Each attribute follows luma.gl [accessor](https://github.com/uber/luma.gl/blob/master/docs/api-reference/webgl/accessor.md) properties |\n| `texture`            | `Object`     | Loaded texture by [`loaders.gl/image`](https://loaders.gl/modules/images/docs/api-reference/image-loader)                              |\n| `featureData`        | `Object`     | Loaded feature data for parsing the geometies (Will be deprecated in 2.x)                                                              |\n\n`attributes` contains following fields\n\n| Field                  | Type     | Contents                          |\n| ---------------------- | -------- | --------------------------------- |\n| `attributes.positions` | `Object` | `{value, type, size, normalized}` |\n| `attributes.normals`   | `Object` | `{value, type, size, normalized}` |\n| `attributes.colors`    | `Object` | `{value, type, size, normalized}` |\n| `attributes.texCoords` | `Object` | `{value, type, size, normalized}` |\n","slug":"modules/i3s/docs/api-reference/i3s-loader","title":"I3SLoader"},{"excerpt":"Image Utilities A small set of image utility functions functions intended to help write image handling code that works across platforms…","rawMarkdownBody":"# Image Utilities\n\nA small set of image utility functions functions intended to help write image handling code that works across platforms.\n\nBackground: The image returned by the [`ImageLoader`](modules/images/docs/api-reference/image-loader.md) depends on the environment, i.e. whether the application is running in a new or old browser, or under Node.js.\n\n## Usage\n\nE.g., the `getImageData` method enables the application to get width, height and pixel data from an image returned by the `ImageLoader` in a platform independent way:\n\n```js\nimport {ImageLoader, getImageSize, getImageData} from `@loaders.gl/images`;\nimport {load} from `@loaders.gl/core`;\n\nconst image = await load(URL, ImageLoader);\n\n// Get an image data object regardless of whether the image is already an `Image`, `ImageBitmap` or already an image data object\nconst imageData = getImageData(image);\nconsole.log(imageData.width, imageData.height, imageData.data);\n```\n\n## Functions\n\n### isImageTypeSupported(type : string) : boolean\n\n- `type`: value to test\n\nReturns `true` if `type` is one of the types that `@loaders.gl/images` can use on the current platform (depends on browser, or whether running under Node.js).\n\n### isImage(image : any) : boolean\n\n- `image`: An image returned by an image category loader, such as `ImageLoader`\n\nReturns `true` if `image` is one of the types that `@loaders.gl/images` can return.\n\n### getImageType(image : any) : String\n\nReturns the type of an image. Can be used when loading images with the default setting of `options.type: 'auto'` to discover what type was actually returned.\n\n- `image`: An image returned by an image category loader, such as `ImageLoader`\n\nReturns\n\n- a string describing the type of the image.\n\nThrows\n\n- if `image` is not of a recognized type.\n\n| Type          | JavaScript Type                                 | Description                                                          |\n| ------------- | ----------------------------------------------- | -------------------------------------------------------------------- |\n| `data`        | Image data object: `data`, `width`, `height` .. | Node.js representation                                               |\n| `imagebitmap` | `ImageBitmap`                                   | The newer HTML5 image class (modern browsers only)                   |\n| `image`       | `Image` aka `HTMLImageElement`                  | More widely supported (but less performant and flexible) image class |\n\n### getImageData(image : any) : Object\n\n- `image`: An image returned by an image category loader, such as `ImageLoader`\n\nReturns and image data object with the following fields\n\n- `data` typed array containing the pixels of the image\n- `width`\n- `height`\n\nThrows\n\n- if `image` is not of a recognized type.\n","slug":"modules/images/docs/api-reference/parsed-image-api","title":"Image Utilities"},{"excerpt":"GLBLoader The  parses a GLB binary \"envelope\". Note: applications that want to parse GLB-formatted glTF files use the  instead. The  is…","rawMarkdownBody":"# GLBLoader\n\nThe `GLBLoader` parses a GLB binary \"envelope\".\n\nNote: applications that want to parse GLB-formatted glTF files use the `GLTFLoader` instead. The `GLBLoader` is intended to be used to load custom data that combines JSON and binary resources.\n\n| Loader          | Characteristic                                                                                          |\n| --------------- | ------------------------------------------------------------------------------------------------------- |\n| File Extensions | `.glb`                                                                                                  |\n| File Type       | Binary                                                                                                  |\n| File Format     | [GLB](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#glb-file-format-specification) |\n| Data Format     | See below                                                                                               |\n| Supported APIs  | `load`, `parse`, `parseSync`                                                                            |\n|                 |\n\n## Usage\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {GLBLoader} from '@loaders.gl/gltf';\nconst gltf = await load(url, GLBLoader);\n```\n\n## Options\n\n| Option                    | Type    | Default | Description                                                  |\n| ------------------------- | ------- | ------- | ------------------------------------------------------------ |\n| `glb.strict` (DEPRECATED) | Boolean | `false` | Whether to support non-standard JSON/BIN chunk type numbers. |\n\n## Data Format\n\nReturns\n\n```json\n{\n  \"header\": {\n    \"byteLength\": number,\n    \"byteOffset\": number\n  },\n\n  \"type\": string,\n  \"version\": number,\n\n  // JSON Chunk\n  \"json\": any,\n\n  // BIN Chunk\n  \"hasBinChunk\": boolean,\n  \"binChunks\": [\n    {\n      \"arrayBuffer\": ArrayBuffer,\n      \"byteOffset\": Number,\n      \"byteLength\": Number\n    }\n  ]\n}\n```\n\n| Field                       | Type          | Default | Description                                          |\n| --------------------------- | ------------- | ------- | ---------------------------------------------------- |\n| `type`                      | `String`      | `glTF`  | String containing the first four bytes of the file   |\n| `version`                   | `Number`      | `2`     | The version number, only version 2 is supported      |\n| `json`                      | `Object`      | `{}`    | Parsed JSON from the JSON chunk                      |\n| `binChunks`                 | `ArrayBuffer` | `null`  | The binary chunk                                     |\n| `binChunks[\\*].arrayBuffer` | `ArrayBuffer` | `null`  | The binary chunk                                     |\n| `binChunks[\\*].byteOffset`  | `Number`      | `null`  | offset of BIN (e.g. embedded in larger binary block) |\n| `binChunks[\\*].byteLength`  | `ArrayBuffer` | `null`  | length of BIN (e.g. embedded in larger binary block) |\n| `header.byteLength`         | `Number`      | -       | length of GLB (e.g. embedded in larger binary block) |\n| `header.byteOffset`         | `Number`      | 0       | offset of GLB (e.g. embedded in larger binary block) |\n","slug":"modules/gltf/docs/api-reference/glb-loader","title":"GLBLoader"},{"excerpt":"GLBWriter The  is a writer for the GLB binary \"envelope\". Note: applications that want to encode GLB-formatted glTF files use the  instead…","rawMarkdownBody":"# GLBWriter\n\nThe `GLBWriter` is a writer for the GLB binary \"envelope\".\n\nNote: applications that want to encode GLB-formatted glTF files use the `GLTFWriter` instead. The `GLBWriter` is intended to be used to save custom data that combines JSON and binary resources.\n\n| Loader          | Characteristic                                                                                          |\n| --------------- | ------------------------------------------------------------------------------------------------------- |\n| File Extensions | `.glb`                                                                                                  |\n| File Type       | Binary                                                                                                  |\n| Data Format     | See below                                                                                               |\n| File Format     | [GLB](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#glb-file-format-specification) |\n| Supported APIs  | `encode`, `encodeSync`                                                                                  |\n\n## Usage\n\n```js\nimport {GLBWriter} from '@loaders.gl/gltf';\nimport {encodeSync} from '@loaders.gl/core';\n\nconst arrayBuffer = encodeSync(gltf, GLBWriter, options);\n```\n\n## Options\n\n| Option | Type | Default | Description |\n| ------ | ---- | ------- | ----------- |\n| N/A    | N/A  | N/A     | N/A         |\n\n## Data Format\n\nSee [`GLBLoader`](/modules/gltf/docs/api-reference/glb-loader.md).\n","slug":"modules/gltf/docs/api-reference/glb-writer","title":"GLBWriter"},{"excerpt":"glbdump  is a utility for inspecting the structure of GLB/glTF binary container files. Installing loaders.gl/gltf makes the  command line…","rawMarkdownBody":"## glbdump\n\n`glbdump` is a utility for inspecting the structure of GLB/glTF binary container files.\n\nInstalling loaders.gl/gltf makes the `glbdump` command line tool available. It can be run using `npx`.\n\n```\n$ npx glbdump <filename>\n```\n","slug":"modules/gltf/docs/api-reference/glbdump","title":" glbdump"},{"excerpt":"glTF Extensions glTF extensions can be present in glTF files, and will be present in the parsed JSON. glTF extensions can supported by…","rawMarkdownBody":"# glTF Extensions\n\nglTF extensions can be present in glTF files, and will be present in the parsed JSON. glTF extensions can supported by applications by inspecting the `extensions` fields inside glTF objects, and it is up to each application to handle or ignore them.\n\nloaders.gl aims to provide support for glTF extensions that can be handled completely or partially during loading, and article describes glTF extensions that are fully or partially processed by the `@loaders.gl/gltf` classes.\n\nNote that many glTF extensions affect aspects that are firmly outside of the scope of loaders.gl (e.g. rendering), and no attempt is made to process those extensions in loaders.gl.\n\n| Extension                                                                                                                        | Description |\n| -------------------------------------------------------------------------------------------------------------------------------- | ----------- |\n| [KHR_draco_mesh_compression](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression) |             |\n| [KHR_lights_punctual](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_lights_punctual)               |             |\n| [KHR_materials_unlit](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_unlit)               |             |\n\n## Official Extensions\n\n### KHR_draco_mesh_compression\n\nSupports compression of mesh attributes (geometry).\n\nSpecification: [KHR_draco_mesh_compression](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression).\n\nParsing Support:\n\n- By adding the `decompress: true` options to the `GLTFParser` any decompressed by the `GLTFParser`.\n- The expanded attributes are placed in the mesh object (effectively making it look as if it had never been compressed).\n- The extension objects are removed from the glTF file.\n\nEncoding Support:\n\n- Meshes can be compressed as they are added to the `GLTFBuilder`.\n\n### KHR_lights_punctual\n\nSupports specification of point light sources and addition of such sources to the scenegraph node.\n\nSpecification: [KHR_lights_punctual](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_lights_punctual)\n\nParsing Support:\n\n- Any nodes with a `KHR_lights_punctual` extension will get a `light` field with value containing a light definition object with properties defining the light (this object will be resolved by index from the global `KHR_lights_punctual` extension object's `lights` array) .\n- The `KHR_lights_punctual` extensions will be removed from all nodes.\n- Finally, the global `KHR_lights_punctual` extension (including its light list)) will be removed.\n\nEncoding Support:\n\n- N/A\n\n### KHR_materials_unlit\n\nSpecifies that a material should not be affected by light. Useful for pre-lit materials (e.g. photogrammetry).\n\n[KHR_materials_unlit](https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_unlit)\n\n## Custom Extensions\n\n### UBER_draco_point_cloud_compression\n\nSpecification: Similar to `KHR_draco_mesh_compression`, but supports point clouds (draw mode 0). Also does not support any fallback or non-compressed accessors/attributes.\n\nParsing support:\n\n- The primitive's accessors field will be populated after decompression.\n- After decompression, the extension will be removed (as if the point cloud was never compressed).\n\nEncoding support:\n\n- Point clouds can be compressed as they are added to the `GLTFBuilder` and decompressed by the `GLTFParser`.\n","slug":"modules/gltf/docs/api-reference/gltf-extensions","title":"glTF Extensions"},{"excerpt":"GLTFLoader Parses a glTF file. Can load both the  (binary) and  (text/json) file format variants. A glTF file contains a hierarchical…","rawMarkdownBody":"# GLTFLoader\n\nParses a glTF file. Can load both the `.glb` (binary) and `.gltf` (text/json) file format variants.\n\nA glTF file contains a hierarchical scenegraph description that can be used to instantiate corresponding hierarcy of actual `Scenegraph` related classes in most WebGL libraries.\n\n| Loader          | Characteristic                                                             |\n| --------------- | -------------------------------------------------------------------------- |\n| File Extensions | `.glb`, `.gltf`                                                            |\n| File Type       | Binary, JSON, Linked Assets                                                |\n| File Format     | [glTF](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0) |\n| Data Format     | [Scenegraph](/docs/specifications/category-scenegraph)                     |\n| Supported APIs  | `load`, `parse`, `parseSync`                                               |\n| Subloaders      | `DracoLoader`, `ImageLoader`                                               |  |\n\n## Usage\n\n```\nimport {load} from '@loaders.gl/core';\nimport {GLTFLoader} from '@loaders.gl/gltf';\nconst gltf = await load(url, GLTFLoader);\n```\n\nTo decompress Draco-compressed meshes:\n\n```\nimport {load} from '@loaders.gl/core';\nimport {GLTFLoader} from '@loaders.gl/gltf';\nimport {DracoLoader} from '@loaders.gl/draco';\nconst gltf = load(url, GLTFLoader, {DracoLoader, decompress: true});\n```\n\n## Overview\n\nThe `GLTFLoader` aims to take care of as much processing as possible, while remaining framework-independent.\n\nThe GLTF Loader returns an object with a `json` field containing the glTF Scenegraph. In its basic mode, the `GLTFLoader` does not modify the loaded JSON in any way. Instead, the results of additional processing are placed in parallel top-level fields such as `buffers` and `images`. This ensures that applications that want to work with the standard glTF data structure can do so.\n\nOptionally, the loaded gltf can be \"post processed\", which lightly annotates and transforms the loaded JSON structure to make it easier to use. Refer to [postProcessGLTF](docs/api-reference/gltf-loaders/gltf-extensions.md) for details.\n\nIn addition, certain glTF extensions, in particular Draco mesh encoding, can be fully or partially processed during loading. When possible (and extension processing is enabled), such extensions will be resolved/decompressed and replaced with standards conformant representations. See [glTF Extensions](docs/api-reference/gltf-loaders/gltf-extensions.md) for more information.\n\nNote: while supported, synchronous parsing of glTF (e.g. using `parseSync()`) has significant limitations. When parsed asynchronously (using `await parse()` or `await load()`), the following additional capabilities are enabled:\n\n- linked binary resource URI:s will be loaded and resolved (assuming a valid base url is available).\n- base64 encoded binary URI:s inside the JSON payload will be decoded.\n- linked image URI:s can be loaded and decoded.\n- Draco meshes can be decoded asynchronously on worker threads (in parallel!).\n\n## Options\n\n| Option             | Type    | Default |                                                                                | Description |\n| ------------------ | ------- | ------- | ------------------------------------------------------------------------------ | ----------- |\n| `gltf.fetchImages` | Boolean | `false` | Fetch any referenced image files (and decode base64 encoded URIS). Async only. |\n| `gltf.parseImages` | Boolean | `false` |\n| `gltf.decompress`  | Boolean | `true`  | Decompress Draco compressed meshes (if DracoLoader available).                 |\n| `gltf.postProcess` | Boolean | `true`  | Perform additional post processing on the loaded glTF data.                    |\n\nRemarks:\n\n- The `gltf.postProcess` option activates additional [post processing](docs/api-reference/post-process-gltf) that transforms parts of JSON structure in the loaded glTF data, to make glTF data easier use in applications and WebGL libraries, however this changes the format of the data returned by the `GLTFLoader`.\n\n## Data Format\n\n### With Post Processing\n\nWhen the `GLTFLoader` is called with `gltf.postProcess` option set to `true` (the default),the parsed JSON chunk will be returned, and [post processing](docs/api-reference/post-process-gltf) will have been performed, which will link data from binary buffers into the parsed JSON structure using non-standard fields, and also modify the data in other ways to make it easier to use.\n\nAt the top level, this will look like a standard glTF JSON structure:\n\n```json\n{\n  scenes: [...],\n  scene: ...,\n  nodes: [...],\n  ...\n}\n```\n\nHowever, the objects inside these arrays will have been pre-processed to simplify usage. For details on changes and extra fields added to the various glTF objects, see [post processing](docs/api-reference/post-process-gltf).\n\n### Without Post Processing\n\nBy setting `gltf.postProcess` to `false`, an unprocessed glTF/GLB data structure will be returned, with binary buffers provided as an `ArrayBuffer` array.\n\n```json\n{\n  // The base URI used to load this glTF, if any. For resolving relative uris to linked resources.\n  baseUri: String,\n\n  // JSON Chunk\n  json: Object, // Containse the parsed glTF JSON or the parsed GLB JSON chunk\n\n  // Length and indices of this array will match `json.buffers`\n  // The GLB bin chunk, if present, will be found in buffer 0.\n  // Additional glTF json `buffers` are fetched and base64 decoded from the JSON uri:s.\n  buffers: [{\n    arrayBuffer: ArrayBuffer,\n    byteOffset: Number,\n    byteLength: Number\n  }],\n\n  // Images can optionally be loaded and decoded, they will be stored here\n  // Length and indices of this array will match `json.buffers`\n  images: Image[],\n\n  // GLBLoader output, if this was a GLB encoded glTF\n  _glb?: Object\n}\n```\n\n| Field                     | Type          | Default                                                   | Description                                                      |\n| ------------------------- | ------------- | --------------------------------------------------------- | ---------------------------------------------------------------- |\n| `baseUri`                 | `String`      | `` | length of GLB (e.g. embedded in larger binary block) |\n| `json`                    | `Object`      | `{}`                                                      | Parsed JSON from the JSON chunk                                  |\n| `buffers`                 | `Object[]`    | `[]`                                                      | The version number                                               |\n| `buffers[\\*].arrayBuffer` | `ArrayBuffer` | `null`                                                    | The binary chunk                                                 |\n| `buffers[\\*].byteOffset`  | `Number`      | `null`                                                    | offset of buffer (embedded in larger binary block)               |\n| `buffers[\\*].byteLength`  | `ArrayBuffer` | `null`                                                    | length of buffer (embedded in larger binary block)               |\n| `_glb`?                   | `Object`      | N/A                                                       | The output of the GLBLoader if the parsed file was GLB formatted |\n","slug":"modules/gltf/docs/api-reference/gltf-loader","title":"GLTFLoader"},{"excerpt":"GLTFScenegraph The  class provides an API for accessing and modifying glTF data. Caveat: Modification of binary data chunks has limitations…","rawMarkdownBody":"# GLTFScenegraph\n\nThe `GLTFScenegraph` class provides an API for accessing and modifying glTF data.\n\n> Caveat: Modification of binary data chunks has limitations, and this class is currently not intended to be a generic utility for modifying glTF data.\n\n## Usage\n\n```js\nimport {GLTFLoader, GLTFScenegraph} from '@loaders.gl/gltf';\nimport {load} from '@loaders.gl/core';\n\n// Load and parse a file\nconst gltfData = await parse(fetch(GLTF_URL), GLTFLoader);\n\n// Create a parser\nconst gltf = new GLTFScenegraph(gltfData);\n\n// Get the complete glTF JSON structure\nconst gltfJson = gltf.getJSON();\n\n// Get specific top-level fields from the glTF JSON chunk\nconst appData = gltf.getApplicationData('customData');\n\n// Get a top level extension from the glTF JSON chunk\nconst topLevelExtension = gltf.getExtension('ORGNAME_extensionName');\nif (topLevelExtension) {\n  ...\n}\n\n// Get images from the binary chunk (together with metadata)\nconst imageIndex = 0;\nconst image = gltf.getImage(imageIndex);\n\n// Get default glTF scenegraph\nconst scenegraph = gltf.getScene();\n// Get specific glTF scenegraph\nconst scenegraph = gltf.getScene(2);\n```\n\n## Accessor Methods\n\n### constructor(gltf : Object)\n\nCreates a new `GLTFScenegraph` instance from a pure JavaScript object.\n\n### json()\n\n### getApplicationData(key : String) : Object\n\nReturns the given data field in the top-level glTF JSON object.\n\n### getExtraData(key : String) : Object?\n\nReturns a key in the top-level glTF `extras` JSON object.\n\n### getExtension(name : String) : Object?\n\nReturns the top-level extension by `name`, if present.\n\n### getUsedExtensions() : String[]\n\nReturns an array of extension names (covering all extensions used at any level of the glTF hierarchy).\n\n### getRequiredExtensions() : String[]\n\nReturns an array of extensions at any level of the glTF hierarchy that are required to properly display this file (covering all extensions used at any level of the glTF hierarchy).\n\n### getObjectExtension(object, extensionName)\n\n### getScene([index : Number]) : Object?\n\nReturns the scene (scenegraph) with the given index, or the default scene if no index is specified.\n\n### getScene(index : Number) : Object\n\n### getNode(index : Number) : Object\n\n### getSkin(index : Number) : Object\n\n### getMesh(index : Number) : Object\n\n### getMaterial(index : Number) : Object\n\n### getAccessor(index : Number) : Object\n\n### getCamera(index : Number) : Object\n\n### getTexture(index : Number) : Object\n\n### getSampler(index : Number) : Object\n\n### getImage(index : Number) : Object\n\nReturns the image with specified index\n\n### getBufferView(index : Number) : Object\n\n### getBuffer(index : Number) : Object\n\n### getTypedArrayForBufferView(bufferView : Number | Object) : Uint8Array\n\nAccepts buffer view index or buffer view object\n\n### getTypedArrayForAccessor(accessor : Number | Object) : Uint8Array | Float32Array | ...\n\nAccepts accessor index or accessor object.\n\nReturns a typed array with type that matches the types\n\n### getTypedArrayForImageData(image : Number | Object) : Uint8Array\n\naccepts accessor index or accessor object\n\n## Modifiers\n\n### addApplicationData(key, data)\n\nAdd an extra application-defined key to the top-level data structure\n\n### addExtraData(key, data)\n\n`extras` - Standard GLTF field for storing application specific data\n\nAdd to GLTF top level extension object, mark as used\n\n### addRequiredExtension(extensionName, data)\n\nAdd GLTF top level extension object, mark as used and required\n\n### registerUsedExtension(extensionName)\n\nAdd extensionName to list of used extensions\n\n### registerRequiredExtension(extensionName)\n\nAdd extensionName to list of required extensions\n\n### removeExtension(extensionName)\n\nRemoves an extension from the top-level list\n\n### setObjectExtension(object, extensionName, data)\n\n### addMesh(attributes, indices, mode = 4)\n\n### addPointCloud(attributes)\n\n### addBufferView(buffer)\n\nAdd one untyped source buffer, create a matching glTF `bufferView`, and return its index\n\n> The binary data will not be added to the gltf buffer until `createBinChunk()` is called.\n\n### addAccessor(bufferViewIndex, accessor)\n\nAdds an accessor to a bufferView\n\n> The binary data will not be added to the gltf buffer until `createBinChunk()` is called.\n\n### addImage(imageData, mimeType)\n\nAdds a binary image. Builds glTF \"JSON metadata\" and saves buffer reference\nBuffer will be copied into BIN chunk during \"pack\"\n\n> The binary data will not be added to the gltf buffer until `createBinChunk()` is called.\n\n### createBinChunk()\n\nPacks any pending binary data into the first binary glTF buffer.\n\nNote: Overwrites the existing first buffer if present.\n","slug":"modules/gltf/docs/api-reference/gltf-scenegraph","title":"GLTFScenegraph"},{"excerpt":"GLTFWriter The  is a writer for glTF scenegraphs. Loader Characteristic File Extensions , File Types Binary, JSON, Linked Assets Data Format…","rawMarkdownBody":"# GLTFWriter\n\nThe `GLTFWriter` is a writer for glTF scenegraphs.\n\n| Loader          | Characteristic                                                             |\n| --------------- | -------------------------------------------------------------------------- |\n| File Extensions | `.glb`,`.gltf`                                                             |\n| File Types      | Binary, JSON, Linked Assets                                                |\n| Data Format     | [Scenegraph](/docs/specifications/category-scenegraph)                     |\n| File Format     | [glTF](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0) |\n| Supported APIs  | `encode`, `encodeSync`                                                     |\n\n## Usage\n\n```js\nimport {GLTFWriter} from '@loaders.gl/gltf';\nimport {encodeSync} from '@loaders.gl/core';\n\nconst arrayBuffer = encodeSync(gltf, GLTFWriter, options);\n```\n\n## Options\n\n| Option        | Type                                                  | Default | Description                                                                                   |\n| ------------- | ----------------------------------------------------- | ------- | --------------------------------------------------------------------------------------------- |\n| `DracoWriter` | [DracoWriter](/docs/api-reference/draco/draco-writer) | `null`  | To enable DRACO encoding, the application needs to import and supply the `DracoWriter` class. |\n| `DracoLoader` | [DracoLoader](/docs/api-reference/draco/draco-loader) | `null`  | To enable DRACO encoding, the application needs to import and supply the `DracoLoader` class. |\n","slug":"modules/gltf/docs/api-reference/gltf-writer","title":"GLTFWriter"},{"excerpt":"postProcessGLTF The  function transforms parsed GLTF JSON to make it easier to use. It adds loaded buffers and images to the glTF JSON…","rawMarkdownBody":"# postProcessGLTF\n\nThe `postProcessGLTF` function transforms parsed GLTF JSON to make it easier to use.\n\n- It adds loaded buffers and images to the glTF JSON objects\n- It creates typed arrays for buffer views\n\n## Usage\n\nPostprocessing is done by default by the `GLTFLoader`:\n\n```js\nimport {GLTFLoader} from '@loaders.gl/gltf';\nconst processedGLTF = await parse(..., GLTFLoader,);\n```\n\nTo turn post processing off, and then optionally post process via `postProcessGLTF` function:\n\n```js\nimport {GLTFLoader, postProcessGLTF} from '@loaders.gl/gltf';\nconst gltf = await parse(..., GLTFLoader, {gltf: {postProcess: false}});\nconst processedGLTF = postProcessGLTF(gltf);\n```\n\nAfter post-processing, the gltf scenegraphs are now easier to iterate over as indices have been resolved to object references:\n\n```js\nconst scenegraph = processedGLTF.scenegraphs[0];\nfor (const node of scenegraph.nodes) {\n  // no need to resolve indices\n  if (node.mesh.primitives) {\n    // Ditto\n    // ...\n  }\n}\n```\n\n## Functions\n\n### postProcessGLTF(gltf : Object, options? : Object) : Object\n\n- `gltf` is expected to have `json` and `buffers` fields per the GLTF Data Format Category.\n- `options.uri` - Set base URI (for image loading)\n\nThe GLTF post processor copies objects in the input gltf json field as necessary to avoid modifying the input JSON, but does not do a deep copy on sub-objects that do not need to be modified.\n\n## General Post Processing\n\n### Replace indices with references\n\nThe first thing that `postProcessGLTF` does is replace glTF indices with object references to simplify iteration over the scenegraph.\n\nBackground: The GLTF file format describes a tree structure, however it links nodes through numeric indices rather than direct references. (As an example the `nodes` field in the top-level glTF `scenegraph` array is an array of indices into the top-level `nodes` array. Each node has a `mesh` attribute that is an index into to the `meshes` array, and so on).\n\n### Adds `id` to every node\n\nThe postprocessor makes sure each node and an `id` value, unless already present.\n\n## Node Specific Post Processing\n\n### Buffers\n\nThe following fields will be populated from the supplied `gltf.buffers` parameter (this parameter is populated by the loader via `options.loadLinkedResources: true`):\n\n- `buffer.arrayBuffer` -\n- `buffer.byteOffset` -\n- `buffer.byteLength` -\n\n### BufferViews\n\n- `bufferView.data` - Typed arrays (`Uint8Arrays`) will be created for buffer views and stored in this field. These typed arrays can be used to upload data to WebGL buffers.\n\n### Accessors\n\nThe accessor parameters which are textual strings in glTF will be resolved into WebGL constants (which are just numbers, e.g. `5126` = `GL.FLOAT`), to prepare for use with WebGL frameworks.\n\n- `accessor.value` - This will be set to a typed array that is a view into the underlying bufferView.\n\nRemarks:\n\n- While it can be very convenient to initialize WebGL buffers from `accessor.value`, this approach will defeat any memory sharing on the GPU that the glTF file specifies through accessors sharing `bufferViews`. The canonical way of instantitating a glTF model is for an application to create one WebGL buffer for each `bufferView` and then use accessors to reference data chunks inside those WebGL buffers with `offset` and `stride`.\n\n## Images\n\n- `image.image` - Populated from the supplied `gltf.images` array. This array is populated by the `GLTFLoader` via `options.loadImages: true`):\n- `image.uri` - If loaded image in the `images` array is not available, uses `gltf.baseUri` or `options.baseUri` is available, to resolve a relative URI and replaces this value.\n\n### Materials\n\n- `...texture` - Since each texture object in the material has an `...index` field next to other fields, the post processor will add a `...texture` field instead of replacing the `...index` field.\n\n### Samplers\n\nModifies\n\n- `parameters` - see table\n\nSampler parameters (which are textual in glTF) will be resolved into WebGL constants.\n\n| glTF constant | WebGL constant          |\n| ------------- | ----------------------- |\n| `magFilter`   | `GL.TEXTURE_MAG_FILTER` |\n| `minFilter`   | `GL.TEXTURE_MIN_FILTER` |\n| `wrapS`       | `GL.TEXTURE_WRAP_S`     |\n| `wrapT`       | `GL.TEXTURE_WRAP_T`     |\n\n### Texture\n\nModifies\n\n- `sampler` - will be resolved the the corresponding image object.\n- `source` - will be resolved the the corresponding image object.\n","slug":"modules/gltf/docs/api-reference/post-process-gltf","title":"postProcessGLTF"},{"excerpt":"DracoWriter The  encodes a mesh or point cloud (maps of attributes) using Draco3D compression. Loader Characteristic File Extension  File…","rawMarkdownBody":"# DracoWriter\n\nThe `DracoWriter` encodes a mesh or point cloud (maps of attributes) using [Draco3D](https://google.github.io/draco/) compression.\n\n| Loader                | Characteristic                               |\n| --------------------- | -------------------------------------------- |\n| File Extension        | `.drc`                                       |\n| File Typoe            | Binary                                       |\n| Data Format           | [Mesh](docs/specifications/category-mesh.md) |\n| File Format           | [Draco](https://google.github.io/draco/)     |\n| Encoder Type          | Synchronous                                  |\n| Worker Thread Support | Yes                                          |\n| Streaming Support     | No                                           |\n\n## Usage\n\n```js\nimport {DracoWriter} from '@loaders.gl/draco';\nimport {encode} from '@loaders.gl/core';\n\nconst mesh = {\n  attributes: {\n    POSITION: {...}\n  }\n};\n\nconst data = await encode(mesh, DracoWriter, options);\n```\n\n## Options\n\n| Option       | Type             | Default                     | Description                                                        |\n| ------------ | ---------------- | --------------------------- | ------------------------------------------------------------------ |\n| `pointcloud` | Boolean          | `false`                     | set to `true` to compress pointclouds (mode=`0` and no `indices`). |\n| `method`     | String           | `MESH_EDGEBREAKER_ENCODING` | set Draco encoding method (applies to meshes only).                |\n| `speed`      | [Number, Number] | set Draco speed options.    |\n| `log`        | Function         | callback for debug info.    |\n","slug":"modules/draco/docs/images/draco-writer","title":"DracoWriter"},{"excerpt":"CSVLoader Streaming loader for comma-separated value and delimiter-separated value encoded files. Loader Characteristic File Extension…","rawMarkdownBody":"# CSVLoader\n\nStreaming loader for comma-separated value and [delimiter-separated value](https://en.wikipedia.org/wiki/Delimiter-separated_values) encoded files.\n\n| Loader         | Characteristic                                       |\n| -------------- | ---------------------------------------------------- |\n| File Extension | `.csv`, `.dsv`                                       |\n| File Type      | Text                                                 |\n| File Format    | [RFC4180](https://tools.ietf.org/html/rfc4180)       |\n| Data Format    | [Classic Table](/docs/specifications/category-table) |\n| Supported APIs | `load`, `parse`, `parseSync`, `parseInBatches`       |\n\n## Usage\n\n```js\nimport {CSVLoader} from '@loaders.gl/csv';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, CSVLoader, {csv: options});\n```\n\n## Options\n\n| Option                  | Type     | Default                 | Description                                                                                                                                                                                                                                                                                     |\n| ----------------------- | -------- | ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `csv.delimiter`         | String   | auto-detect             | The delimiting character.                                                                                                                                                                                                                                                                       |\n| `csv.header`            | Boolean  | auto-detect             | If `true`, the first row of parsed data will be interpreted as field names. If `false`, the first row is interpreted as data.                                                                                                                                                                   |\n| `csv.newline`           | String   | auto-detect             | The newline sequence. Must be `\\r`, `\\n`, or `\\r\\n`.                                                                                                                                                                                                                                            |\n| `csv.quoteChar`         | String   | `\"`                     | The character used to quote fields.                                                                                                                                                                                                                                                             |\n| `csv.escapeChar`        | String   | `\"`                     | The character used to escape the quote character within a field.                                                                                                                                                                                                                                |\n| `csv.dynamicTyping`     | Boolean  | `true`                  | If `true`, numeric and boolean data values will be converted to their type (instead if strings).                                                                                                                                                                                                |\n| `csv.comments`          | String   | `false`                 | Comment indicator (for example, \"#\" or \"//\"). Lines starting with this string are skipped.                                                                                                                                                                                                      |\n| `csv.skipEmptyLines`    | String   | `false`                 | If `true`, lines that are completely empty (those which evaluate to an empty string) will be skipped. If set to `'greedy'`, lines that don't have any content (those which have only whitespace after parsing) will also be skipped.                                                            |\n| `csv.transform`         | Function | -                       | A function to apply on each value. The function receives the value as its first argument and the column number or header name when enabled as its second argument. The return value of the function will replace the value it received. The transform function is applied before dynamicTyping. |\n| `csv.delimitersToGuess` | Array    | `[',', '\\t', '|', ';']` | An array of delimiters to guess from if the `delimiter` option is not set.                                                                                                                                                                                                                      |\n| `csv.fastMode`          | Boolean  | auto-detect             | Force set \"fast mode\". Fast mode speeds up parsing significantly for large inputs but only works when the input has no quoted fields. Fast mode will be auto enabled if no `\"` characters appear in the input.                                                                                  |\n\nRemarks:\n\n- Many options are passed on to papaparse, if necessary [papaparse docs](https://www.papaparse.com/docs#config) could serve as a source for more information.\n","slug":"modules/csv/docs/api-reference/csv-loader","title":"CSVLoader"},{"excerpt":"DracoLoader The  decodes a mesh or point cloud (maps of attributes) using DRACO compression. Loader Characteristic File Extension  File Type…","rawMarkdownBody":"# DracoLoader\n\nThe `DracoLoader` decodes a mesh or point cloud (maps of attributes) using [DRACO](https://google.github.io/draco/) compression.\n\n| Loader         | Characteristic                               |\n| -------------- | -------------------------------------------- |\n| File Extension | `.drc`                                       |\n| File Type      | Binary                                       |\n| File Format    | [Draco](https://google.github.io/draco/)     |\n| Data Format    | [Mesh](docs/specifications/category-mesh.md) |\n| Supported APIs | `parse`, `parseSync`                         |\n\n## Usage\n\n```js\nimport {DracoLoader} from '@loaders.gl/draco';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, DracoLoader, options);\n```\n\n## Options\n\n| Option | Type | Default | Description |\n| ------ | ---- | ------- | ----------- |\n\n\n## Dependencies\n\nDraco libraries by default are loaded from CDN, but can be bundled and injected. See [modules/draco/docs] for details.\n","slug":"modules/draco/docs/api-reference/draco-loader","title":"DracoLoader"},{"excerpt":"DracoWriter The  encodes a mesh or point cloud using Draco compression. Loader Characteristic File Extension  File Type Binary File Format…","rawMarkdownBody":"# DracoWriter\n\nThe `DracoWriter` encodes a mesh or point cloud using [Draco](https://google.github.io/draco/) compression.\n\n| Loader         | Characteristic                               |\n| -------------- | -------------------------------------------- |\n| File Extension | `.drc`                                       |\n| File Type      | Binary                                       |\n| File Format    | [Draco](https://google.github.io/draco/)     |\n| Data Format    | [Mesh](docs/specifications/category-mesh.md) |\n| Support API    | `encode`, `encodeSync`                       |\n\n## Usage\n\n```js\nimport {DracoWriter} from '@loaders.gl/draco';\nimport {encode} from '@loaders.gl/core';\n\nconst data = encode(url, DracoWriter, options);\n```\n\n## Options\n\n| Option               | Type               | Default | Description                                                                         |\n| -------------------- | ------------------ | ------- | ----------------------------------------------------------------------------------- |\n| `draco.pointcloud`   | `Boolean`          | `false` | Whether to compress as point cloud (GL.POINTS)                                      |\n| `draco.speed`        | `Number`           |         | Speed vs Quality, see [Draco](https://google.github.io/draco/) documentation        |\n| `draco.method`       | `String`           |         | Compression method, see [Draco](https://google.github.io/draco/) documentation      |\n| `draco.quantization` | `[Number, Number]` |         | Quantization parameters, see [Draco](https://google.github.io/draco/) documentation |\n\n## Dependencies\n\nDraco libraries by default are loaded from CDN, but can be bundled and injected. See [modules/draco/docs] for details.\n","slug":"modules/draco/docs/api-reference/draco-writer","title":"DracoWriter"},{"excerpt":"Binary Utilities loaders.gl provides a set of functions to simplify working with binary data. There are a couple of different ways to deal…","rawMarkdownBody":"# Binary Utilities\n\nloaders.gl provides a set of functions to simplify working with binary data. There are a couple of different ways to deal with binary data in the JavaScript APIs for browser and Node.js, and some small but annoying \"gotchas\" that can trip up programmers when working with binary data.\n\n## Usage\n\n```js\nimport {toArrayBuffer} from '@loaders.gl/core';\n```\n\n## Functions\n\n### toArrayBuffer(binaryData : \\*) : ArrayBuffer\n\n\"Repackages\" a binary data in non-array-buffer form as an `ArrayBuffer`.\n\n- binaryData - ArrayBuffer, Buffer (Node.js), typed array, blob, ...\n\n## Remarks\n\n- Most functions in loaders.gl that accept binary data call `toArrayBuffer(...)` on input parameters before starting processing, thus ensuring that functions work on all types of input data.\n","slug":"modules/core/docs/api-reference/binary-utilities","title":"Binary Utilities"},{"excerpt":"encode Functions encode(fileData : ArrayBuffer | String, writer : Object | Array [, options : Object , url : String]) : Promise.Any Encodes…","rawMarkdownBody":"# encode\n\n## Functions\n\n### encode(fileData : ArrayBuffer | String, writer : Object | Array [, options : Object [, url : String]]) : Promise.Any\n\nEncodes data asynchronously using the provided writer.\n\n- `data` - loaded data, either in binary or text format.\n- `writer` - can be a single writer or an array of writers.\n- `options` - optional, options for the writer (see documentation of the specific writer).\n- `url` - optional, assists in the autoselection of a writer if multiple writers are supplied to `writer`.\n\n- `options.log`=`console` Any object with methods `log`, `info`, `warn` and `error`. By default set to `console`. Setting log to `null` will turn off logging.\n\n### encodeSync(fileData : ArrayBuffer | String, writer : Object | Array, [, options : Object [, url : String]]) : any\n\nEncodes data synchronously using the provided writer, if possible. If not, returns `null`, in which case asynchronous loading is required.\n\n- `data` - loaded data, either in binary or text format.\n- `writer` - can be a single writer or an array of writers.\n- `options` - optional, options for the writer (see documentation of the specific writer).\n- `url` - optional, assists in the autoselection of a writer if multiple writers are supplied to `writer`.\n","slug":"modules/core/docs/api-reference/encode","title":"encode"},{"excerpt":"fetchFile The  function is a wrapper around  which provides support for path prefixes and some additional loading capabilities. Usage Use…","rawMarkdownBody":"# fetchFile\n\nThe `fetchFile` function is a wrapper around `fetch` which provides support for path prefixes and some additional loading capabilities.\n\n## Usage\n\nUse the `fetchFile` function as follows:\n\n```js\nimport {fetchFile} from '@loaders.gl/core';\n\nconst response = await fetchFile(url);\n\n// Now use standard browser Response APIs\n\n// Note: headers are case-insensitive\nconst contentLength = response.headers.get('content-length');\nconst mimeType = response.headers.get('content-type');\n\nconst arrayBuffer = await response.arrayBuffer();\n```\n\nThe `Response` object from `fetchFile` is usually passed to `parse` as follows:\n\n```js\nimport {fetchFile, parse} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\nconst data = await parse(fetchFile(url), OBJLoader);\n```\n\nNote that if you don't need the extra features in `fetchFile`, you can just use the browsers built-in `fetch` method.\n\n```js\nimport {parse} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\nconst data = await parse(fetch(url), OBJLoader);\n```\n\n## Functions\n\n### fetchFile(url : String [, options : Object]) : Promise.Response\n\nA wrapper around the platform [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/fetch) function with some additions:\n\n- Supports `setPathPrefix`: If path prefix has been set, it will be appended if `url` is relative (e.g. does not start with a `/`).\n- Supports `File` and `Blob` objects on the browser (and returns \"mock\" fetch response objects).\n\nReturns:\n\n- A promise that resolves into a fetch [`Response`](https://developer.mozilla.org/en-US/docs/Web/API/Response) object, with the following methods/fields:\n  - `headers`: `Headers` - A [`Headers`](https://developer.mozilla.org/en-US/docs/Web/API/Headers) object.\n  - `arrayBuffer()`: Promise.ArrayBuffer`- Loads the file as an`ArrayBuffer`.\n  - `text()`: Promise.String` - Loads the file and decodes it into text.\n  - `json()`: Promise.String` - Loads the file and decodes it into JSON.\n  - `body` : ReadableStream` - A stream that can be used to incrementally read the contents of the file.\n\nOptions:\n\nUnder Node.js, options include (see [fs.createReadStream](https://nodejs.org/api/fs.html#fs_fs_createreadstream_path_options)):\n\n- `options.highWaterMark` (Number) Default: 64K (64 \\* 1024) - Determines the \"chunk size\" of data read from the file.\n\n### readFileSync(url : String [, options : Object]) : ArrayBuffer | String\n\n> This function only works on Node.js or using data URLs.\n\nReads the raw data from a file asynchronously.\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n## Remarks\n\n- `fetchFile` will delegate to `fetch` after resolving the URL.\n- For some data sources such as node.js and `File`/`Blob` objects a mock `Response` object will be returned, and not all fields/members may be implemented.\n- When possible, `Content-Length` and `Content-Type` `headers` are also populated for non-request data sources including `File`, `Blob` and Node.js files.\n- `fetchFile` is intended to be a small (in terms of bundle size) function to help applications work with files in a portable way. The `Response` object returned on Node.js does not implement all the functionality the browser does. If you run into the need\n- In fact, the use of any of the file utilities including `readFile` and `readFileAsync` functions with other loaders.gl functions is entirely optional. loader objects can be used with data loaded via any mechanism the application prefers, e.g. directly using `fetch`, `XMLHttpRequest` etc.\n- The \"path prefix\" support is intentended to be a simple mechanism to support certain work-arounds. It is intended to help e.g. in situations like getting test cases to load data from the right place, but was never intended to support general application use cases.\n- The stream utilities are intended to be small optional helpers that facilitate writing platform independent code that works with streams. This can be valuable as JavaScript Stream APIs are still maturing and there are still significant differences between platforms. However, streams and iterators created directly using platform specific APIs can be used as parameters to loaders.gl functions whenever a stream is expected, allowing the application to take full control when desired.\n","slug":"modules/core/docs/api-reference/fetch-file","title":"fetchFile"},{"excerpt":"fetchProgress This function is still experimental A function that tracks a fetch response object and calls  callbacks. Usage _fetchProgress…","rawMarkdownBody":"# fetchProgress\n\n> This function is still experimental\n\nA function that tracks a fetch response object and calls `onProgress` callbacks.\n\n## Usage\n\n```js\nimport {_fetchProgress} from '@loaders.gl/core';\n\nfunction onProgress(percent, {loadedBytes, totalBytes}) {\n  console.log(`${percent}% ${Math.round(loadedBytes/1000)} of ${Math.round(totalBytes/1000)} Kbytes`);\n}\n\nasync function main() {\n  const response = await _fetchProgress(fetch(PROGRESS_IMAGE_URL, onProgress),\n  const data = await response.arrayBuffer();\n  // At this point, onProgress will have been called one or more times.\n  ...\n}\n```\n\n## \\_fetchProgress(response : Response | Promise, onProgress : function, onDone : function, onError : function) : Response\n\n`onProgress: (percent: number, {loadedBytes : number, totalBytes : number}) => void`\n","slug":"modules/core/docs/api-reference/fetch-progress","title":"fetchProgress"},{"excerpt":"Iterator Utilities Functions getStreamIterator(stream : Stream) : AsyncIterator Returns an async iterator that can be used to read chunks of…","rawMarkdownBody":"# Iterator Utilities\n\n## Functions\n\n### getStreamIterator(stream : Stream) : AsyncIterator\n\nReturns an async iterator that can be used to read chunks of data from the stream (or write chunks of data to the stream, in case of writable streams).\n\nWorks on both Node.js 8+ and browser streams.\n","slug":"modules/core/docs/api-reference/iterator-utilities","title":"Iterator Utilities"},{"excerpt":"load The  function can be used with any loader object. They takes a  and one or more loader objects, checks what type of data that loader…","rawMarkdownBody":"# load\n\nThe `load` function can be used with any _loader object_. They takes a `url` and one or more _loader objects_, checks what type of data that loader prefers to work on (e.g. text, JSON, binary, stream, ...), loads the data in the appropriate way, and passes it to the loader.\n\n### load(url : String | File, loaders : Object | Object[][, options : object]) : Promise.Response\n\n### load(url : String | File [, options : Object]) : Promise.Response\n\nThe `load` function is used to load and parse data with a specific _loader object_. An array of loader objects can be provided, in which case `load` will attempt to autodetect which loader is appropriate for the file.\n\nThe `loaders` parameter can also be omitted, in which case any _loader objects_ previously registered with [`registerLoaders`](docs/api-reference/core/register-loaders) will be used.\n\n- `url` - Urls can be data urls (`data://`) or a request (`http://` or `https://`) urls, or a file name (Node.js only). Also accepts `File` or `Blob` object (Browser only). Can also accept any format that is accepted by [`parse`](https://github.com/uber-web/loaders.gl/blob/master/docs/api-reference/core/parse.md), with the exception of strings that are interpreted as urls.\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of registered loaders (see `registerLoaders`)\n- `options` - optional, contains both options for the read process and options for the loader (see documentation of the specific loader).\n\nReturns:\n\n- Return value depends on the _loader category_.\n\nNotes:\n\n- If `url` is not a `string`, `load` will call `parse` directly.\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n- `load` takes a `url` and a loader object, checks what type of data that loader prefers to work on (e.g. text, binary, stream, ...), loads the data in the appropriate way, and passes it to the loader.\n- If `@loaders.gl/polyfills` is installed, `load` will work under Node.js as well.\n\n## Options\n\nA loader object, that can contain a mix of options defined by:\n\n- any loader(s) being used\n- the `parse` function\n\nIn addition to the following options\n\n| Option             | Type   | Default       | Description                                                      |\n| ------------------ | ------ | ------------- | ---------------------------------------------------------------- |\n| `options.dataType` | string | `arraybuffer` | Default depends on loader object. Set to 'text' to read as text. |\n","slug":"modules/core/docs/api-reference/load","title":"load"},{"excerpt":"parseInBatches Streaming parsing is not supported by all loaders. Refer to the documentation for each loader. For supporting loaders, the…","rawMarkdownBody":"# parseInBatches\n\n> Streaming parsing is not supported by all loaders. Refer to the documentation for each loader.\n\nFor supporting loaders, the streaming `parseInBatches` function can parse incrementally from a stream as data arrives and emit \"batches\" of parsed data.\n\nBatched (streaming) parsing is supported by some loaders\n\n```js\nimport {fetchFile, parseInBatches} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/obj';\n\nconst batchIterator = await parseInBatches(fetchFile(url), CSVLoader);\nfor await (const batch of batchIterator) {\n  console.log(batch.length);\n}\n```\n\n## Functions\n\n### parseInBatches(data : any, loaders : Object | Object\\[] [, options : Object [, url : String]]) : AsyncIterator\n\n### parseInBatches(data : any [, options : Object [, url : String]]) : AsyncIterator\n\nParses data in batches from a stream, releasing each batch to the application while the stream is still being read.\n\nParses data with the selected _loader object_. An array of `loaders` can be provided, in which case an attempt will be made to autodetect which loader is appropriate for the file (using url extension and header matching).\n\nThe `loaders` parameter can also be ommitted, in which case any _loaders_ previously registered with [`registerLoaders`](docs/api-reference/core/register-loaders) will be used.\n\n- `data`: loaded data or an object that allows data to be loaded. This parameter can be any of the following types:\n  - `Response` - `fetch` response object returned by `fetchFile` or `fetch`.\n  - `ArrayBuffer` - Parse from binary data in an array buffer\n  - `String` - Parse from text data in a string. (Only works for loaders that support textual input).\n  - `Iterator` - Iterator that yeilds binary (`ArrayBuffer`) chunks or string chunks (string chunks only work for loaders that support textual input).\n  - `AsyncIterator` - iterator that yeilds promises that resolve to binary (`ArrayBuffer`) chunks or string chunks.\n  - `ReadableStream` - A DOM or Node stream.\n  - `Promise` - A promise that resolves to any of the other supported data types can also be supplied.\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of registered loaders (see `registerLoaders`)\n- `options`: optional, options for the loader (see documentation of the specific loader).\n- `url`: optional, assists in the autoselection of a loader if multiple loaders are supplied to `loader`.\n\nReturns:\n\n- Returns an async iterator that yields batches of data. The exact format for the batches depends on the _loader object_ category.\n","slug":"modules/core/docs/api-reference/parse-in-batches","title":"parseInBatches"},{"excerpt":"parseSync Synchronous parsing is not supported by all loaders. Refer to the documentation for each loader. For supporting loaders, the…","rawMarkdownBody":"# parseSync\n\n> Synchronous parsing is not supported by all loaders. Refer to the documentation for each loader.\n\nFor supporting loaders, the synchronous `parseSync` function works on already loaded data.\n\n## Usage\n\n```js\nimport {fetchFile, parseSync} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\nconst response = await fetchFile(url);\nconst arraybuffer = await response.arrayBuffer();\n\ndata = parseSync(arraybuffer, OBJLoader);\n// Application code here\n...\n```\n\nHandling errors\n\n```js\ntry {\n  const data = await parseSync(data);\n} catch (error) {\n  console.log(error);\n}\n```\n\n## Functions\n\n### parseSync(fileData : ArrayBuffer | String, loaders : Object | Object\\[], [, options : Object [, url : String]]) : any\n\n### parseSync(fileData : ArrayBuffer | String, [, options : Object [, url : String]]) : any\n\nParses data synchronously using the provided loader, if possible. If not, returns `null`, in which case asynchronous parsing is required.\n\n- `data`: already loaded data, either in binary or text format. This parameter can be any of the following types:\n  - `Response`: `fetch` response object returned by `fetchFile` or `fetch`.\n  - `ArrayBuffer`: Parse from binary data in an array buffer\n  - `String`: Parse from text data in a string. (Only works for loaders that support textual input).\n  - `Iterator`: Iterator that yeilds binary (`ArrayBuffer`) chunks or string chunks (string chunks only work for loaders that support textual input).\n    can also be supplied.\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of registered loaders (see `registerLoaders`)\n- `options`: optional, options for the loader (see documentation of the specific loader).\n- `url`: optional, assists in the autoselection of a loader if multiple loaders are supplied to `loader`.\n\nReturns:\n\n- Return value depends on the _loader object_ category\n","slug":"modules/core/docs/api-reference/parse-sync","title":"parseSync"},{"excerpt":"parse This functions parse data. As important special cases, the async  function can also load (and then parse) data from a  (or )  object…","rawMarkdownBody":"# parse\n\nThis functions parse data. As important special cases, the async `parse` function can also load (and then parse) data from a `fetch` (or `fetchFile`) `Response` object, and the streaming `parseInBatches` version can parse incrementally from a stream as data arrives.\n\n## Usage\n\nThe return value from `fetch` or `fetchFile` is a `Promise` that resolves to the fetch `Response` object and can be passed directly to the non-sync parser functions:\n\n```js\nimport {fetchFile, parse} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\ndata = await parse(fetchFile(url), OBJLoader);\n// Application code here\n...\n```\n\nBatched (streaming) parsing is supported by some loaders\n\n```js\nimport {fetchFile, parseInBatches} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/obj';\n\nconst batchIterator = await parseInBatches(fetchFile(url), CSVLoader);\nfor await (const batch of batchIterator) {\n  console.log(batch.length);\n}\n```\n\nHandling errors\n\n```js\ntry {\n  const response = await fetch(url); // fetch can throw in case of network errors\n  const data = await parse(response); // parse will throw if server reports an error\n} catch (error) {\n  console.log(error);\n}\n```\n\n## Functions\n\n### parse(data : ArrayBuffer | String, loaders : Object | Object\\[] [, options : Object [, url : String]]) : Promise.Any\n\n### parse(data : ArrayBuffer | String, [, options : Object [, url : String]]) : Promise.Any\n\nParses data asynchronously either using the provided loader or loaders, or using the pre-registered loaders (see `register-loaders`).\n\n- `data`: loaded data or an object that allows data to be loaded. This parameter can be any of the following types:\n\n  - `Response` - response object returned by `fetchFile` or `fetch`.\n  - `ArrayBuffer` - Parse from binary data in an array buffer\n  - `String` - Parse from text data in a string. (Only works for loaders that support textual input).\n  - `Iterator` - Iterator that yeilds binary (`ArrayBuffer`) chunks or string chunks (string chunks only work for loaders that support textual input).\n  - `AsyncIterator` - iterator that yeilds promises that resolve to binary (`ArrayBuffer`) chunks or string chunks.\n  - `ReadableStream` - A DOM or Node stream.\n  - `File` - A browser file object (from drag-and-drop or file selection operations).\n  - `Promise` - A promise that resolves to any of the other supported data types can also be supplied.\n\n- `loaders` - can be a single loader or an array of loaders. If ommitted, will use the list of pre-registered loaders (see `registerLoaders`)\n\n- `options`: optional, options for the loader (see documentation of the specific loader).\n\n- `url`: optional, assists in the autoselection of a loader if multiple loaders are supplied to `loader`.\n\nReturns:\n\n- Return value depends on the _loader object_ category\n\nNotes:\n\n- If multiple `loaders` are provided (or pre-registered), an attempt will be made to autodetect which loader is appropriate for the file (using url extension and header matching).\n\n## Options\n\nTop-level options\n\n| Option           | Type    | Default   | Description                                                                                                              |\n| ---------------- | ------- | --------- | ------------------------------------------------------------------------------------------------------------------------ |\n| `options.log`    | object  | `console` | By default set to a `console` wrapper. Setting log to `null` will turn off logging.                                      |\n| `options.worker` | boolean | `true`    | If the selected loader is equipped with a worker url (and the runtime environment supports it) parse on a worker thread. |\n","slug":"modules/core/docs/api-reference/parse","title":"parse"},{"excerpt":"registerLoaders The loader registry allows applications to cherry-pick which loaders to include in their application bundle by importing…","rawMarkdownBody":"# registerLoaders\n\nThe loader registry allows applications to cherry-pick which loaders to include in their application bundle by importing just the loaders they need and registering them during initialization.\n\nApplications can then make all those imported loaders available (via format autodetection) to all subsequent `parse` and `load` calls, without those calls having to specify which loaders to use.\n\n## Usage\n\nSample application initialization code that imports and registers loaders:\n\n```js\nimport {registerLoaders} from '@loaders.gl/core';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nregisterLoaders(CSVLoader);\n```\n\nSome other file that needs to load CSV:\n\n```js\nimport {load} from '@loaders.gl/core';\n\n// The pre-registered CSVLoader gets auto selected based on file extension...\nconst data = await load('data.csv');\n```\n\n## Functions\n\n### registerLoaders(loaders : Object | Object[])\n\nRegisters one or more _loader objects_ to a global _loader object registry_, these loaders will be used if no loader object is supplied to `parse` and `load`.\n\n- `loaders` - can be a single loader or an array of loaders. The specified loaders will be added to any previously registered loaders.\n","slug":"modules/core/docs/api-reference/register-loaders","title":"registerLoaders"},{"excerpt":"save Needs update  and  function can be used with any writer.  takes a  and a writer object, checks what type of data that writer prefers to…","rawMarkdownBody":"# save\n\n> Needs update\n\n`save` and `saveSync` function can be used with any writer. `save` takes a `url` and a writer object, checks what type of data that writer prefers to work on (e.g. text, JSON, binary, stream, ...), saves the data in the appropriate way, and passes it to the writer.\n\n## Functions\n\n### save(url : String | File, writer : Object [, options : Object]) : Promise.ArrayBuffer| Promi\n\nse.String\n\nThe `save` function can be used with any writer.\n\n`save` takes a `url` and a writer object, checks what type of data that writer prefers to work on (e.g. text, JSON, binary, stream, ...), saves the data in the appropriate way, and passes it to the writer.\n\n- `url` - Can be a string, either a data url or a request url, or in Node.js, a file name, or in the browser, a File object.\n- `data` - saveed data, either in binary or text format.\n- `writer` - can be a single writer or an array of writers.\n- `options` - optional, contains both options for the read process and options for the writer (see documentation of the specific writer).\n- `options.dataType`=`arraybuffer` - By default reads as binary. Set to 'text' to read as text.\n\nReturns:\n\n- Return value depends on the category\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n### saveSync(url : String [, options : Object]) : ArrayBuffer | String\n\nSimilar to `save` except saves and parses data synchronously.\n\nNote that for `saveSync` to work, the `url` needs to be saveable synchronously _and_ the writer used must support synchronous parsing. Synchronous saveing only works on data URLs or files in Node.js. In many cases, the asynchronous `save` is more appropriate.\n","slug":"modules/core/docs/api-reference/save","title":"save"},{"excerpt":"selectLoader  is considered experimental as loader auto detection is still being improved. A core feature of loaders.gl is the ability to…","rawMarkdownBody":"# selectLoader\n\n> `selectLoader` is considered experimental as loader auto detection is still being improved.\n\nA core feature of loaders.gl is the ability to automatically select an appropriate loader for a specific file among a list of candidate loaders. This feature is built-in to the `parse` and `load` functions, but applications can also access this feature directly through the `selectLoader` API.\n\nLoader selection heuristics are based on both filename (url) extensions as well as comparison of initial data content against known headers for each file format.\n\n`selectLoader` is also aware of the [loader registry](docs/api-reference/core/register-loaders.md). If no loaders are provided (by passing in a falsy value such as `null`) `selectLoader` will search the list of pre-registered loaders.\n\n## Usage\n\nSelect a loader from a list of provided loaders:\n\n```js\nimport {_selectLoader} from '@loaders.gl/core';\nimport {ArrowLoader} from '@loaders.gl/arrow';\nimport {CSVLoader} from '@loaders.gl/csv';\n\n_selectLoader([ArrowLoader, CSVLoader], 'filename.csv'); // => CSVLoader\n```\n\nSelect a loader from pre-registered loaders in the loader registry:\n\n```js\nimport {registerLoaders, _selectLoader} from '@loaders.gl/core';\nimport {ArrowLoader} from '@loaders.gl/arrow';\nimport {CSVLoader} from '@loaders.gl/csv';\n\nregisterLoaders(ArrowLoader, CSVLoader);\n\n// By passing null instead of a loader list, selectLoader returns null.\n_selectLoader(null, 'filename.csv'); // => CSVLoader\n```\n\n## Functions\n\n### \\_selectLoader(loaders : Object | Object[] | null, url? : String, data? : ArrayBuffer | String, options? : Object)\n\nSelects an appropriate loader for a file from a list of candidate loaders by examining a URL and/or an initial data chunk.\n\nParameters:\n\n- `loaders` - can be a single loader or an array of loaders, or null.\n- `url` - An optional URL to perform autodetection against.\n- `data` - Optional data to perform autodetection against\n- `options.nothrow`=`false` - Return null instead of throwing exception if no loader can be found\n\nReturns:\n\n- A single loader (or null if `options.nothrow` was set and no matching loader was found).\n\nThrows:\n\n- If no matching loader was found, and `options.nothrow` was not set.\n\nRegarding the `loaders` parameter:\n\n- A single loader object will be returned without matching.\n- a `null` loader list will use the pre-registered list of loaders.\n- A supplied list of loaders will be searched for a matching loader.\n\n## Remarks\n\n- File extensions - An attempt will be made to extract a file extension by stripping away query parameters and base path before matching against known loader extensions.\n- Stream autodetection - Currently not well supported.\n","slug":"modules/core/docs/api-reference/select-loader","title":"selectLoader"},{"excerpt":"setLoaderOptions Usage Bundling the entire  library: Functions setLoaderOptions(options : Object) : void Merge the options with the global…","rawMarkdownBody":"# setLoaderOptions\n\n## Usage\n\nBundling the entire `draco3d` library:\n\n```js\nimport draco from 'draco3d';\nimport {setLoaderOptions} from '@loaders.gl/core';\nsetLoaderOptions({\n  modules: {\n    draco3d\n  }\n});\n```\n\n## Functions\n\n### setLoaderOptions(options : Object) : void\n\nMerge the options with the global options\n\n## Options\n\nTop-level options\n\n| Option            | Type    | Default   | Description                                                                                                              |\n| ----------------- | ------- | --------- | ------------------------------------------------------------------------------------------------------------------------ |\n| `options.log`     | object  | `console` | By default set to a `console` wrapper. Setting log to `null` will turn off logging.                                      |\n| `options.worker`  | boolean | `true`    | If the selected loader is equipped with a worker url (and the runtime environment supports it) parse on a worker thread. |\n| `options.cdn`     | boolean | string    | `true`                                                                                                                   | `true` loads from `unpkg.com/@loaders.gl`. `false` load from local urls. `string` alternate CDN url. |\n| `options.modules` | Object  | -         | Supply bundles modules or override local urls.                                                                           |\n","slug":"modules/core/docs/api-reference/set-loader-options","title":"setLoaderOptions"},{"excerpt":"setPathPrefix resolvePath(path : String) : String Applies aliases and path prefix, in that order. Returns an updated path. setPathPrefix…","rawMarkdownBody":"# setPathPrefix\n\n### resolvePath(path : String) : String\n\nApplies aliases and path prefix, in that order. Returns an updated path.\n\n### setPathPrefix(prefix : String)\n\nThis sets a path prefix that is automatically prepended to relative path names provided to load functions.\n\n### getPathPrefix() : String\n\nReturns the current path prefix set by `setPathPrefix`.\n","slug":"modules/core/docs/api-reference/set-path-prefix","title":"setPathPrefix"},{"excerpt":"BasisLoader The  is experimental A loader for Basis Universal \"supercompressed\" GPU textures. Extracts supercompressed textures from the…","rawMarkdownBody":"# BasisLoader\n\n> The `BasisLoader` is experimental\n\nA loader for Basis Universal \"supercompressed\" GPU textures. Extracts supercompressed textures from the basis container and efficiently \"transpiles\" them into the specified compressed texture format.\n\n| Loader         | Characteristic                                                    |\n| -------------- | ----------------------------------------------------------------- |\n| File Format    | [Basis Universal](https://github.com/BinomialLLC/basis_universal) |\n| File Extension | `.basis`                                                          |\n| File Type      | Binary                                                            |\n| Data Format    | Array of compressed image data objects                            |\n| Supported APIs | `load`, `parse`                                                   |\n\n## Usage\n\n```js\nimport {BasisLoader} from '@loaders.gl/basis';\nimport {load} from '@loaders.gl/core';\n\nconst miplevels = await load(url, BasisLoader, options);\nfor (const compressedImage of miplevels) {\n  ...\n}\n```\n\n## Options\n\n| Option         | Type   | Default  | Description                                             |\n| -------------- | ------ | -------- | ------------------------------------------------------- |\n| `basis.format` | String | `'auto'` | Set to one of the supported compressed texture formats. |\n\n## Compressed Texture Formats\n\nThe `BasisLoader` can transpile into the following compressed (and uncompressed) texture formats.\n\n| Format                        | Description |\n| ----------------------------- | ----------- |\n| `etc1`                        |             |\n| `etc2`                        |             |\n| `bc1`                         |             |\n| `bc3`                         |             |\n| `bc4`                         |             |\n| `bc5`                         |             |\n| `bc7-m6-opaque-only`          |             |\n| `bc7-m5`                      |             |\n| `pvrtc1-4-rgb`                |             |\n| `pvrtc1-4-rgba`               |             |\n| `astc-4x4`                    |             |\n| `atc-rgb`                     |             |\n| `atc-rgba-interpolated-alpha` |             |\n| `rgba32`                      |             |\n| `rgb565`                      |             |\n| `bgr565`                      |             |\n| `rgba4444`                    |             |\n","slug":"modules/basis/docs/api-reference/basis-loader","title":"BasisLoader"},{"excerpt":"CompressedTextureLoader The  is experimental Loader for compressed textures in the PVR file format Loader Characteristic File Format PVR…","rawMarkdownBody":"# CompressedTextureLoader\n\n> The `CompressedTextureLoader` is experimental\n\nLoader for compressed textures in the PVR file format\n\n| Loader         | Characteristic                                                                   |\n| -------------- | -------------------------------------------------------------------------------- |\n| File Format    | [PVR](http://cdn.imgtec.com/sdk-documentation/PVR+File+Format.Specification.pdf) |\n| File Extension | `.dds`, `.pvr`                                                                   |\n| File Type      | Binary                                                                           |\n| Data Format    | Array of compressed image data objects                                           |\n| Supported APIs | `load`, `parse`                                                                  |\n\n## Usage\n\n```js\nimport {CompressedTextureLoader} from '@loaders.gl/basis';\nimport {load} from '@loaders.gl/core';\n\nconst mipLevels = await load(url, CompressedTextureLoader);\nfor (const image of mipLevels) {\n  ...\n}\n```\n\n## Data Format\n\nReturns an array of image data objects representing mip levels.\n\n`{compressed: true, format, width, height, data: ...}`\n\n## Options\n\n| Option | Type | Default | Description |\n| ------ | ---- | ------- | ----------- |\n| N/A    |      |         |             |\n","slug":"modules/basis/docs/api-reference/compressed-texture-loader","title":"CompressedTextureLoader"},{"excerpt":"writeFile A file save utilities that (attempts to) work consistently across browser and node. Usage Functions writeFile(url : String…","rawMarkdownBody":"# writeFile\n\nA file save utilities that (attempts to) work consistently across browser and node.\n\n## Usage\n\n```js\nimport {writeFile} from '@loaders.gl/core';\nimport {DracoWriter} from '@loaders.gl/draco';\n\nawait writeFile(url, DracoWriter);\n```\n\n## Functions\n\n### writeFile(url : String [, options : Object]) : Promise.ArrayBuffer\n\nReads the raw data from a file asynchronously.\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n### writeFileSync(url : String [, options : Object]) : ArrayBuffer\n\n> Only works on Node.js or using data URLs.\n\nReads the raw data from a \"file\" synchronously.\n\nNotes:\n\n- Any path prefix set by `setPathPrefix` will be appended to relative urls.\n\n## Remarks\n\n- The use of the loaders.gl `writeFile` and `writeFileAsync` functions is optional, loaders.gl loaders can be used with any data loaded via any mechanism the application prefers, e.g. `fetch`, `XMLHttpRequest` etc.\n- The \"path prefix\" support is intentended to be a simple mechanism to support certain work-arounds. It is intended to help e.g. in situations like getting test cases to load data from the right place, but was never intended to support general application use cases.\n","slug":"modules/core/docs/api-reference/write-file","title":"writeFile"},{"excerpt":"ArrowLoader The Arrow loaders are still under development. The  parses the Apache Arrow columnar table format. Loader Characteristic File…","rawMarkdownBody":"# ArrowLoader\n\n> The Arrow loaders are still under development.\n\nThe `ArrowLoader` parses the Apache Arrow columnar table format.\n\n| Loader                | Characteristic                                                            |\n| --------------------- | ------------------------------------------------------------------------- |\n| File Format           | [IPC: Encapsulated Message Format](http://arrow.apache.org/docs/ipc.html) |\n| File Extension        | `.arrow`                                                                  |\n| File Type             | Binary                                                                    |\n| Data Format           | [Columnar Table](/docs/specifications/category-table)                     |\n| Decoder Type          | `load`, `parse`, `parseSync`, `parseInBatches`                            |\n| Worker Thread Support | Yes                                                                       |\n| Streaming Support     | Yes                                                                       |\n\n## Usage\n\n```js\nimport {ArrowLoader} from '@loaders.gl/arrow';\nimport {load} from '@loaders.gl/core';\n\nconst data = await load(url, ArrowLoader, options);\n```\n\n## Options\n\n| Option | Type | Default | Description |\n| ------ | ---- | ------- | ----------- |\n\n","slug":"modules/arrow/docs/api-reference/arrow-loader","title":"ArrowLoader"},{"excerpt":"CartographicRectangle A two dimensional region specified as longitude and latitude coordinates. Usage Creates a rectangle given the boundary…","rawMarkdownBody":"# CartographicRectangle\n\nA two dimensional region specified as longitude and latitude coordinates.\n\n\n## Usage\n\nCreates a rectangle given the boundary longitude and latitude in degrees.\n```js\nconst rectangle = CartographicRectangle.fromDegrees(0.0, 20.0, 10.0, 30.0);\n```\n\nCreates a rectangle given the boundary longitude and latitude in radians.\n```js\nconst rectangle = CartographicRectangle.fromRadians(0.0, Math.PI/4, Math.PI/8, 3*Math.PI/4);\n```\n\n## Static Members\n\n### CartographicRectangle.MAX_VALUE\n\nnew CartographicRectangle(-Math.PI, -CesiumMath.PI_OVER_TWO, Math.PI, CesiumMath.PI_OVER_TWO));\n\n## Members\n\n### west : Number\n\nThe westernmost longitude in radians in the range [-Pi, Pi].\n\ndefault 0.0\n\n### south : Number\n\nThe southernmost latitude in radians in the range [-Pi/2, Pi/2].\n\ndefault 0.0\n\n### east : Number\n\nThe easternmost longitude in radians in the range [-Pi, Pi].\n\ndefault 0.0\n\n### north : Number\n\nThe northernmost latitude in radians in the range [-Pi/2, Pi/2].\n\ndefault 0.0\n\n\n## Methods\n\n### constructor(west, south, east, north)\n\n- `west`=`0.0`  The westernmost longitude, in radians, in the range [-Pi, Pi].\n- `south`=`0.0`  The southernmost latitude, in radians, in the range [-Pi/2, Pi/2].\n- `east`=`0.0`  The easternmost longitude, in radians, in the range [-Pi, Pi].\n- `north`=`0.0`  The northernmost latitude, in radians, in the range [-Pi/2, Pi/2].\n\n\n### computeWidth()\n\nComputes the width of a rectangle in radians.\n\n@returns {Number} The width.\n\n### computeHeight()\n\nComputes the height of a rectangle in radians.\n\n@returns {Number} The height.\n\n### fromDegrees(west, south, east, north, result)\n\nCreates a rectangle given the boundary longitude and latitude in degrees.\n\n@param {Number} [west=0.0] The westernmost longitude in degrees in the range [-180.0, 180.0].\n@param {Number} [south=0.0] The southernmost latitude in degrees in the range [-90.0, 90.0].\n@param {Number} [east=0.0] The easternmost longitude in degrees in the range [-180.0, 180.0].\n@param {Number} [north=0.0] The northernmost latitude in degrees in the range [-90.0, 90.0].\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n### fromRadians(west, south, east, north, result)\n\nCreates a rectangle given the boundary longitude and latitude in radians.\n\n@param {Number} [west=0.0] The westernmost longitude in radians in the range [-Math.PI, Math.PI].\n@param {Number} [south=0.0] The southernmost latitude in radians in the range [-Math.PI/2, Math.PI/2].\n@param {Number} [east=0.0] The easternmost longitude in radians in the range [-Math.PI, Math.PI].\n@param {Number} [north=0.0] The northernmost latitude in radians in the range [-Math.PI/2, Math.PI/2].\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n\n### fromCartographicArray(cartographics, result)\n\nCreates the smallest possible CartographicRectangle that encloses all positions in the provided array.\n\n@param {Cartographic[]} cartographics The list of Cartographic instances.\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n### fromCartesianArray(cartesians, ellipsoid, result)\n\nCreates the smallest possible CartographicRectangle that encloses all positions in the provided array.\n\n@param {Cartesian3[]} cartesians The list of Cartesian instances.\n@param {Ellipsoid} [ellipsoid=Ellipsoid.WGS84] The ellipsoid the cartesians are on.\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n### clone(rectangle, result)\n\nDuplicates a CartographicRectangle.\n\n@param {CartographicRectangle} rectangle The rectangle to clone.\n@param {CartographicRectangle} [result] The object onto which to store the result, or undefined if a new instance should be created.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided. (Returns undefined if rectangle is undefined)\n\n\nCompares the provided CartographicRectangles componentwise and returns\n`true` if they pass an absolute or relative tolerance test,\n`false` otherwise.\n\n@param {CartographicRectangle} [left] The first CartographicRectangle.\n@param {CartographicRectangle} [right] The second CartographicRectangle.\n@param {Number} absoluteEpsilon The absolute epsilon tolerance to use for equality testing.\n@returns {Boolean} `true` if left and right are within the provided epsilon, `false` otherwise.\n/\n\tCartographicRectangle.equalsEpsilon = function(left, right, absoluteEpsilon)\n\t\t//>>includeStart('debug', pragmas.debug);\n\t\tCheck.typeOf.number('absoluteEpsilon', absoluteEpsilon);\n\t\t//>>includeEnd('debug');\n\n\t\treturn (left === right) ||\n\t\t\t   (defined(left) &&\n\t\t\t\tdefined(right) &&\n\t\t\t\t(Math.abs(left.west - right.west) <= absoluteEpsilon) &&\n\t\t\t\t(Math.abs(left.south - right.south) <= absoluteEpsilon) &&\n\t\t\t\t(Math.abs(left.east - right.east) <= absoluteEpsilon) &&\n\t\t\t\t(Math.abs(left.north - right.north) <= absoluteEpsilon));\n\t};\n\n\nDuplicates this CartographicRectangle.\n\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n/\n\tCartographicRectangle.prototype.clone = function(result)\n\t\treturn CartographicRectangle.clone(this, result);\n\t};\n\n\nCompares the provided CartographicRectangle with this CartographicRectangle componentwise and returns\n`true` if they are equal, `false` otherwise.\n\n@param {CartographicRectangle} [other] The CartographicRectangle to compare.\n@returns {Boolean} `true` if the CartographicRectangles are equal, `false` otherwise.\n/\n\tCartographicRectangle.prototype.equals = function(other)\n\t\treturn CartographicRectangle.equals(this, other);\n\t};\n\n\nCompares the provided rectangles and returns `true` if they are equal,\n`false` otherwise.\n\nCartographicRectangle.equals = function(left, right)\n\n@param {CartographicRectangle} [left] The first CartographicRectangle.\n@param {CartographicRectangle} [right] The second CartographicRectangle.\n@returns {Boolean} `true` if left and right are equal; otherwise `false`.\n\n\nCompares the provided CartographicRectangle with this CartographicRectangle componentwise and returns\n`true` if they are within the provided epsilon,\n`false` otherwise.\n\nCartographicRectangle.prototype.equalsEpsilon = function(other, epsilon)\n\n@param {CartographicRectangle} [other] The CartographicRectangle to compare.\n@param {Number} epsilon The epsilon to use for equality testing.\n@returns {Boolean} `true` if the CartographicRectangles are within the provided epsilon, `false` otherwise.\n\n### validate()\n\nChecks a CartographicRectangle's properties and throws if they are not in valid ranges.\n\nThrows\n- `north` must be in the interval [`-Pi/2`, `Pi/2`].\n- `south` must be in the interval [`-Pi/2`, `Pi/2`].\n- `east` must be in the interval [`-Pi`, `Pi`].\n- `west` must be in the interval [`-Pi`, `Pi`].\n\n### southwest(rectangle, result)\n\nComputes the southwest corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n### northwest(rectangle, result)\n\nComputes the northwest corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n### northeast(rectangle, result)\n\nComputes the northeast corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n\n### southeast(rectangle, result)\n\nComputes the southeast corner of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the corner\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n### center = function(rectangle, result)\n\nComputes the center of a rectangle.\n\n@param {CartographicRectangle} rectangle The rectangle for which to find the center\n@param {Cartographic} [result] The object onto which to store the result.\n@returns {Cartographic} The modified result parameter or a new Cartographic instance if none was provided.\n\n### intersection = function(rectangle, CartographicotherRectangle, result)\n\nComputes the intersection of two rectangles.  This function assumes that the rectangle's coordinates are\nlatitude and longitude in radians and produces a correct intersection, taking into account the fact that\nthe same angle can be represented with multiple values as well as the wrapping of longitude at the\nanti-meridian.  For a simple intersection that ignores these factors and can be used with projected\ncoordinates, see {@link CartographicRectangle.simpleIntersection}.\n\n@param {CartographicRectangle} rectangle On rectangle to find an intersection\n@param {CartographicRectangle} CartographicotherRectangle Another rectangle to find an intersection\n@param {CartographicRectangle} [result] The object onto which to store the result.\n\n\n### simpleIntersection = function(rectangle, CartographicotherRectangle, result)\n\nComputes a simple intersection of two rectangles.  Unlike {@link CartographicRectangle.intersection}, this function\ndoes not attempt to put the angular coordinates into a consistent range or to account for crossing the\nanti-meridian.  As such, it can be used for rectangles where the coordinates are not simply latitude\nand longitude (i.e. projected coordinates).\n\n@param {CartographicRectangle} rectangle On rectangle to find an intersection\n@param {CartographicRectangle} CartographicotherRectangle Another rectangle to find an intersection\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle|undefined} The modified result parameter, a new CartographicRectangle instance if none was provided or undefined if there is no intersection.\n\n\n### union(rectangle, CartographicotherRectangle, result)\n\nComputes a rectangle that is the union of two rectangles.\n\n@param {CartographicRectangle} rectangle A rectangle to enclose in rectangle.\n@param {CartographicRectangle} CartographicotherRectangle A rectangle to enclose in a rectangle.\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if none was provided.\n\n### expand(rectangle, cartographic, result)\n\nComputes a rectangle by enlarging the provided rectangle until it contains the provided cartographic.\n\n@param {CartographicRectangle} rectangle A rectangle to expand.\n@param {Cartographic} cartographic A cartographic to enclose in a rectangle.\n@param {CartographicRectangle} [result] The object onto which to store the result.\n@returns {CartographicRectangle} The modified result parameter or a new CartographicRectangle instance if one was not provided.\n\n### contains(rectangle, cartographic)\n\nReturns true if the cartographic is on or inside the rectangle, false otherwise.\n\n@param {CartographicRectangle} rectangle The rectangle\n@param {Cartographic} cartographic The cartographic to test.\n@returns {Boolean} true if the provided cartographic is inside the rectangle, false otherwise.\n\n### subsample(rectangle, ellipsoid, surfaceHeight, result)\n\nSamples a rectangle so that it includes a list of Cartesian points suitable for passing to\n{@link BoundingSphere#fromPoints}.  Sampling is necessary to account\nfor rectangles that cover the poles or cross the equator.\n\n@param {CartographicRectangle} rectangle The rectangle to subsample.\n@param {Ellipsoid} [ellipsoid=Ellipsoid.WGS84] The ellipsoid to use.\n@param {Number} [surfaceHeight=0.0] The height of the rectangle above the ellipsoid.\n@param {Cartesian3[]} [result] The array of Cartesians onto which to store the result.\n@returns {Cartesian3[]} The modified result parameter or a new Array of Cartesians instances if none was provided.\n\n\nThe largest possible rectangle.\n\n","slug":"modules/3d-tiles/wip/geospatial/cartographic-rectangle","title":"CartographicRectangle"},{"excerpt":"@math.gl/geospatial This library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes. This…","rawMarkdownBody":"# @math.gl/geospatial\n\n> This library is being developed to support 3D tiles and will be moved to the math.gl repository when it stabilizes.\n\nThis modile provides classes and utilities to facilitate working with the major geospatial coordinate systems and projections used with computer maps, primarily:\n- [WGS84](https://en.wikipedia.org/wiki/World_Geodetic_System) (World Geodetic System) coordinates.\n- [Web Mercator Projection](https://en.wikipedia.org/wiki/Web_Mercator_projection)\n\n## Class Overview\n\n| Class                   | Dewscription |\n| ---                     | --- |\n| `Ellipsoid`             | Implements ellipsoid |\n| `Ellipsoid.WSG84`       | An `Ellipsoid` instance initialized with Earth radii per WGS84. |\n| `CartographicRectangle` | A rectangle defined by cartographic longitudes and latitudes. |\n\n## Usage Examples\n\nA major use of this library is to convert between \"cartesian\" (`x`, `y`, `z`) and \"cartographic\" (`longitude`, `latitude`, `height`) representations of WSG84 coordinates. The `Ellipsoid` class implements these calculations.\n\n\n## Framework Independence\n\nLike all non-core math.gl modules, this library can be used without the math.gl core classes.\n\n- Any input vectors can be supplied as length 3 JavaScript `Array` instances.\n- Any result vectors can be treated as length 3 JavaScript `Array` instances (they may be math.gl `Vector3`).\n- The core math.gl classes inherit from JavaScript `Array` and can be used directly as input.\n","slug":"modules/3d-tiles/wip/geospatial","title":"@math.gl/geospatial"},{"excerpt":"Cartographic A class with static function to help convert geospatial coordinates, primarily in WSG84 notation, between lng/lat/height and…","rawMarkdownBody":"# Cartographic\n\nA class with static function to help convert geospatial coordinates, primarily in [WSG84](https://en.wikipedia.org/wiki/World_Geodetic_System) notation, between lng/lat/height and _cartesian_ (earth-center relative `x`,`y`,`z`) coordinates.\n\n## Usage\n\nConvert Cartesian coordinate to longitude/latitude/height-over-ellipsoid.\n\n```js\nconst lnglatz = Cartographic.fromCartesian([-115.0, 37.0]);\n```\n\nConvert longitude/latitude/height-over-ellipsoid to Cartesian:\n\n```js\nconst position = Cartographic.fromDegrees([-115.0, 37.0]);\n```\n\nConvert lng/lat/z with long lat in degrees to radians.\n\n```js\nconst position = Cartographic.toRadians([-2.007, 0.645]);\n```\n\nConvert lng/lat/z with long lat in radians to degrees.\n\n```js\nconst position = Cartographic.toDegrees([-2.007, 0.645]);\n```\n\n## Static Methods\n\n### Cartographic.toRadians([longitude : Number, latitude : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]) : Number[3]\n\nReturns a new `Vector3` from longitude and latitude values given in degrees.\n\n- `longitude` The longitude, in degrees\n- `latitude` The latitude, in degrees\n- `height`=`0.0` The height, in meters, above the ellipsoid.\n- `result`= The object onto which to store the result.\n\n### Cartographic.toDegrees([longitudeRadians : Number, latitudeRadians : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]]) : Number[3]\n\nReturns a Vector3 position from longitude and latitude values given in radians.\n\n- `longitude` The longitude, in degrees\n- `latitude` The latitude, in degrees\n- `height`=`0.0` The height, in meters, above the ellipsoid.\n- `ellipsoid`=`Ellipsoid.WGS84` The ellipsoid on which the position lies.- `result`= The object onto which to store the result.\n\n### Cartographic.fromCartesian([longitude : Number, latitude : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]]) : Number[3]\n\nConverts a Cartesian geodetic position to a longitude/latitude/height vector.\n\n- @param {Vector3} cartesian The Cartesian position to convert to cartographic representation.\n- @param {Ellipsoid} [ellipsoid=Ellipsoid.WGS84] The ellipsoid on which the position lies.\n- @param {Cartographic} [result] The object onto which to store the result.\n- @returns {Cartographic} The modified result parameter, new Cartographic instance if none was provided, or undefined if the cartesian is at the center of the ellipsoid.\n\nReturns:\n\n- a lng, lat, height from a Cartesian position. The values in the resulting object will be in radians.\n\n- `cartesian` The Cartesian position to convert to cartographic representation.\n- `ellipsoid`=`Ellipsoid.WGS84` The ellipsoid on which the position lies.\n- `result` The object onto which to store the result.\n\nReturns:\n\n- Array of 3 numbers. The modified result parameter, a new vector if none was provided, or `undefined` if the cartesian is at the center of the ellipsoid.\n\n### Cartographic.toCartesian([longitude : Number, latitude : Number, height : Number], ellipsoid : Ellipsoid [, result : Number[3]]) : Number[3]\n\nConverts a lng/lat/height into a Cartesian position on the given ellipsoid.\n\n- `cartesian` The Cartesian position to convert to cartographic representation.\n- `ellipsoid`=`Ellipsoid.WGS84` The ellipsoid on which the position lies.\n- `result` The object onto which to store the result.\n\nReturns:\n\n- The modified result parameter, new Cartographic instance if none was provided, or undefined if the cartesian is at the center of the ellipsoid.\n\nThe values in the resulting object will be in degrees.\n\n## Attribution\n\nThis class is based on [Cesium](https://github.com/AnalyticalGraphicsInc/cesium) source code under the Apache 2 License.\n","slug":"modules/3d-tiles/wip/geospatial/cartographic","title":"Cartographic"},{"excerpt":"CesiumIonLoader Extends from , inherits all the options and share the same resolved  and  format.\nAlong with the support of resolving…","rawMarkdownBody":"# CesiumIonLoader\n\n> Extends from `Tiles3DLoader`, inherits all the options and share the same resolved `Tileset` and `Tile` format.\n> Along with the support of resolving tileset metadata and authorization from Cesium ion server.\n\nParse [3D tile](https://github.com/AnalyticalGraphicsInc/3d-tiles) fetched from Cesium ion server.\n\n## Usage\n\nLoad a tileset file from Cesium ion server.\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {CesiumIonLoader} from '@loaders.gl/3d-tiles';\nconst tilesetUrl = 'https://assets.cesium.com/43978/tileset.json';\nconst ION_ACCESS_TOKEN = ''; // your own ion access token\n\nconst options = {ion: {loadGLTF: true}};\n// resolve the authorizations used for requesting tiles from Cesium ion server\nconst metadata = CesiumIonLoader.preload(tilesetUrl, {accessToken: ION_ACCESS_TOKEN});\nconsole.log(metadata);\nconst tilesetJson = await load(tilesetUrl, CesiumIonLoader, {...options, ...metadata});\n```\n\n## Options\n\nInherit all the options from `Tiles3DLoader`.\n\n| Option                     | Type   | Default | Description                                                                            |\n| -------------------------- | ------ | ------- | -------------------------------------------------------------------------------------- |\n| `['cesium-ion'].isTileset` | Bool   | `false` | Whether to load a `Tileset` file. If not specifies, will infer based on url extension. |\n| `['cesium-ion'].headers`   | Object | `null`  | Used to load data from server                                                          |\n\nTo enable parsing of DRACO compressed point clouds and glTF tiles, make sure to first register the [DracoLoader](/docs/api-reference/draco/draco-loader).\n\nPoint cloud tie options\n\n| Option                                   | Type      | Default | Description                          |\n| ---------------------------------------- | --------- | ------- | ------------------------------------ |\n| `['cesium-ion'].decodeQuantizedPosition` | `Boolean` | `false` | Pre-decode quantized position on CPU |\n\nFor i3dm and b3dm tiles:\n\n| Option                    | Type    | Default | Description                           |\n| ------------------------- | ------- | ------- | ------------------------------------- |\n| `['cesium-ion'].loadGLTF` | Boolean | `true`  | Fetch and parse any linked glTF files |\n\nIf `options['cesium-ion'].loadGLTF` is `true`, GLTF loading can be controlled by providing [`GLTFLoader` options](modules/gltf/docs/api-reference/gltf-loader.md) via the `options.gltf` sub options.\n\n## Data formats\n\nThe same as `Tiles3DLoader`.\n","slug":"modules/3d-tiles/docs/api-reference/cesium-ion-loader","title":"CesiumIonLoader"},{"excerpt":"Ellipsoid A quadratic surface defined in Cartesian coordinates by the equation . Primarily used to represent the shape of planetary bodies…","rawMarkdownBody":"# Ellipsoid\n\nA quadratic surface defined in Cartesian coordinates by the equation `(x / a)^2 + (y / b)^2 + (z / c)^2 = 1`. Primarily used to represent the shape of planetary bodies.\n\nThe main use of this class is to convert between the \"cartesian\" and \"cartographic\" coordinate systems.\n\nRather than constructing this object directly, one of the provided constants is used.\n\n## Usage\n\nCreate a Cartographic and determine it's Cartesian representation on a WGS84 ellipsoid.\n\n```js\nconst cartographicPosition = [Math.toRadians(21), Math.toRadians(78), 5000];\nconst cartesianPosition = Ellipsoid.WGS84.cartographicToCartesian(position);\n```\n\n```js\nconst cartesianPosition = new [17832.12, 83234.52, 952313.73];\nconst cartographicPosition = Ellipsoid.WGS84.cartesianToCartographic(position);\n```\n\n## Static Fields\n\n### Ellipsoid.WGS84 : Ellipsoid (readonly)\n\nAn Ellipsoid instance initialized to the WGS84 standard.\n\n### Ellipsoid.UNIT_SPHERE : Ellipsoid (readonly)\n\nAn Ellipsoid instance initialized to radii of (1.0, 1.0, 1.0).\n\n### Ellipsoid.MOON : Ellipsoid (readonly)\n\nAn Ellipsoid instance initialized to a sphere with the lunar radius.\n\n## Members\n\n### radii : Vector3 (readonly)\n\nGets the radii of the ellipsoid.\n\n### radiiSquared : Vector3 (readonly)\n\nGets the squared radii of the ellipsoid.\n\n### radiiToTheFourth : Vector3 (readonly)\n\nGets the radii of the ellipsoid raise to the fourth power.\n\n### oneOverRadii : Vector3 (readonly)\n\nGets one over the radii of the ellipsoid.\n\n### oneOverRadiiSquared : Vector3 (readonly)\n\nGets one over the squared radii of the ellipsoid.\n\n### minimumRadius : Number (readonly)\n\nGets the minimum radius of the ellipsoid.\n\n### maximumRadius : Number\n\nGets the maximum radius of the ellipsoid.\n\n## Methods\n\n### constructor(x : Number, y : Number, z : Number)\n\n- `x`=`0` The radius in the x direction.\n- `y`=`0` The radius in the y direction.\n- `z`=`0` The radius in the z direction.\n\nThrows\n\n- All radii components must be greater than or equal to zero.\n\n### clone() : Ellipsoid\n\nDuplicates an Ellipsoid instance.\n\n- {Ellipsoid} [result] Optional object onto which to store the result, or undefined if a new\n  instance should be created.\n\nReturns\n- The cloned Ellipsoid. (Returns undefined if ellipsoid is undefined)\n\n### equals(right)\n\nCompares this Ellipsoid against the provided Ellipsoid componentwise and returns `true` if they are equal, `false` otherwise. \\*\n\n- {Ellipsoid} [right] The other Ellipsoid. used.\n\nReturns - {Boolean} `true` if they are equal, `false` otherwise.\n\n### toString() : String\n\nCreates a string representing this Ellipsoid in the format  used.'(radii.x, radii.y, radii.z)'. \\*\n\nReturns\n\n- A string representing this ellipsoid in the format '(radii.x, radii.y, radii.z)'.\n\n### geocentricSurfaceNormal(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nComputes the unit vector directed from the center of this ellipsoid toward the provided Cartesian position.\n\n- `cartesian` - The WSG84 cartesian coordinate for which to to determine the geocentric normal.\n- `result` - Optional object onto which to store the result.\n\nReturns\n\n- The modified result parameter or a new `Vector3` instance if none was provided.\n\n### geodeticSurfaceNormalCartographic(cartographic : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nComputes the normal of the plane tangent to the surface of the ellipsoid at the provided position.\n\n- `cartographic` The cartographic position for which to to determine the geodetic normal.\n- `result` Optional object onto which to store the result.\n\nReturns\n\nThe modified result parameter or a new `Vector3` instance if none was provided.\n\n### geodeticSurfaceNormal(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nComputes the normal of the plane tangent to the surface of the ellipsoid at the provided position.\n\n- `cartesian` The Cartesian position for which to to determine the surface normal.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified `result` parameter or a new `Vector3` instance if none was provided.\n\n### cartographicToCartesian(cartographic : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nConverts the provided cartographic to Cartesian representation.\n\n- `cartographic` The cartographic position.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified `result` parameter or a new `Vector3` instance if none was provided.\n\n### cartesianToCartographic(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3] | `undefined`\n\nConverts the provided cartesian to cartographic representation. The cartesian is `undefined` at the center of the ellipsoid.\n\n- `cartesian` The Cartesian position to convert to cartographic representation.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified result parameter, new `Vector3` instance if none was provided, or undefined if the cartesian is at the center of the ellipsoid.\n\n### scaleToGeodeticSurface(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3] | `undefined`\n\nScales the provided Cartesian position along the geodetic surface normal so that it is on the surface of this ellipsoid. If the position is at the center of the ellipsoid, this function returns `undefined`.\n\n- `cartesian` The Cartesian position to scale.\n- `result` Optional object onto which to store the result.\n\nReturns\n\n- The modified result parameter, a new `Vector3` instance if none was provided, or undefined if the position is at the center.\n\n### scaleToGeocentricSurface(cartesian : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nScales the provided Cartesian position along the geocentric surface normal so that it is on the surface of this ellipsoid.\n\n- `cartesian` The Cartesian position to scale.\n- `result` Optional object onto which to store the result.\n\nReturns\n- The modified `result` parameter or a new `Vector3` instance if none was provided.\n\n### transformPositionToScaledSpace(position : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nTransforms a Cartesian X, Y, Z position to the ellipsoid-scaled space by multiplying its components by the result of `Ellipsoid.oneOverRadii`.\n\n- `position` The position to transform.\n- `result` Optional array into which to copy the result.\n\nReturns\n\n- The position expressed in the scaled space. The returned instance is the one passed as the `result` parameter if it is not undefined, or a new instance of it is.\n\n### transformPositionFromScaledSpace(position : Number[3] [, result : Number[3]]) : Vector3 | Number[3]\n\nTransforms a Cartesian X, Y, Z position from the ellipsoid-scaled space by multiplying its components by the result of `Ellipsoid.radii`.\n\n- `position` The position to transform.\n- `result` Optional array to which to copy the result.\n\nReturns\n\n- The position expressed in the unscaled space. The returned array is the one passed as the `result` parameter, or a new `Vector3` instance.\n\n### getSurfaceNormalIntersectionWithZAxis(position, buffer, result) : | undefined\n\nComputes a point which is the intersection of the surface normal with the z-axis.\n\n- `position` the position. must be on the surface of the ellipsoid.\n- `buffer`=`0.0` A buffer to subtract from the ellipsoid size when checking if the point is inside the ellipsoid.\n- `result` Optional array into which to copy the result.\n\nReturns\n\n- The intersection point if it's inside the ellipsoid, `undefined` otherwise.\n\nThrows\n\n- `position` is required.\n- `Ellipsoid` must be an ellipsoid of revolution (`radii.x == radii.y`).\n- Ellipsoid.radii.z must be greater than 0.\n\nNotes:\n\n- In earth case, with common earth datums, there is no need for this buffer since the intersection point is always (relatively) very close to the center.\n- In WGS84 datum, intersection point is at max z = +-42841.31151331382 (0.673% of z-axis).\n- Intersection point could be outside the ellipsoid if the ratio of MajorAxis / AxisOfRotation is bigger than the square root of 2\n\n## Attribution\n\nThis class was ported from [Cesium](https://github.com/AnalyticalGraphicsInc/cesium) under the Apache 2 License.\n","slug":"modules/3d-tiles/wip/geospatial/ellipsoid","title":"Ellipsoid"},{"excerpt":"Tiles3DLoader Parses a 3D tile. Loader Characteristic File Extensions ,, ,  File Type Binary (with linked assets) File Format 3D Tiles Data…","rawMarkdownBody":"# Tiles3DLoader\n\nParses a [3D tile](https://github.com/AnalyticalGraphicsInc/3d-tiles).\n\n| Loader                | Characteristic                                                                                                     |\n| --------------------- | ------------------------------------------------------------------------------------------------------------------ |\n| File Extensions       | `.b3dm`,`.i3dm`, `.pnts`, `.cmpt`                                                                                  |\n| File Type             | Binary (with linked assets)                                                                                        |\n| File Format           | [3D Tiles](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#tile-format-specifications) |\n| Data Format           | [Data Formats](#data-formats)                                                                                      |\n| Decoder Type          | Asynchronous                                                                                                       |\n| Worker Thread Support | No                                                                                                                 |\n| Streaming Support     | No \\*                                                                                                              |\n| Subloaders            | `DracoLoader` (`.pnts`), `GLTFLoader` (`.b3dm`, `.i3dm`)                                                           |\n\n\\* Streaming is not supported for individual tiles, however tilesets are streamed by loading only the tiles needed for the\n\n## Usage\n\nLoad a tileset file.\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {Tiles3DLoader} from '@loaders.gl/3d-tiles';\nconst tilesetUrl = 'https://assets.cesium.com/43978/tileset.json';\nconst tilesetJson = await load(tilesetUrl, Tiles3DLoader);\n```\n\nTo decompress tiles containing Draco compressed glTF models or Draco compressed point clouds:\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {Tiles3DLoader} from '@loaders.gl/3d-tiles';\nimport {DracoWorkerLoader} from '@loaders.gl/draco';\nconst tileUrl = 'https://assets.cesium.com/43978/1.pnts';\nconst tile = await load(tileUrl, Tiles3DLoader, {DracoWorkerLoader, decompress: true});\n```\n\nLoad a tileset and dynamically load/unload tiles based on viewport with helper class `Tileset3D` (`@loaders.gl/tiles`)\n\n```js\nimport {load} from '@loaders.gl/core';\nimport {Tileset3D} from '@loaders.gl/tiles';\nimport {Tiles3DLoader} from '@loaders.gl/3d-tiles';\nimport WebMercatorViewport from '@math.gl/web-mercator';\n\nconst tilesetUrl = 'https://assets.cesium.com/43978/tileset.json';\nconst tilesetJson = await load(tilesetUrl, Tiles3DLoader);\nconst tileset3d = new Tileset3D(tilesetJson, {\n  onTileLoad: tile => console.log(tile)\n});\n\nconst viewport = new WebMercatorViewport({latitude, longitude, zoom});\ntileset3d.update(viewport);\n\n// visible tiles\nconst visibleTiles = tileset3d.tiles.filter(tile => tile.selected);\n// Note that visibleTiles will likely not immediately include all tiles\n// tiles will keep loading and file `onTileLoad` callbacks\n```\n\n## Options\n\n| Option               | Type   | Default | Description                                                                            |\n| -------------------- | ------ | ------- | -------------------------------------------------------------------------------------- |\n| `3d-tiles.isTileset` | Bool   | `false` | Whether to load a `Tileset` file. If not specifies, will infer based on url extension. |\n| `3d-tiles.headers`   | Object | null    | Used to load data from server                                                          |\n\nTo enable parsing of DRACO compressed point clouds and glTF tiles, make sure to first register the [DracoLoader](/docs/api-reference/draco/draco-loader).\n\nPoint cloud tie options\n\n| Option                              | Type      | Default | Description                          |\n| ----------------------------------- | --------- | ------- | ------------------------------------ |\n| `3d-tiles.decodeQuantizedPositions` | `Boolean` | `false` | Pre-decode quantized position on CPU |\n\nFor i3dm and b3dm tiles:\n\n| Option              | Type    | Default | Description                           |\n| ------------------- | ------- | ------- | ------------------------------------- |\n| `3d-tiles.loadGLTF` | Boolean | `true`  | Fetch and parse any linked glTF files |\n\nIf `options['3d-tiles'].loadGLTF` is `true`, GLTF loading can be controlled by providing [`GLTFLoader` options](modules/gltf/docs/api-reference/gltf-loader.md) via the `options.gltf` sub options.\n\n## Notes about Tile Types\n\n### b3dm, i3dm\n\nglTF file into a hierarchical Scenegraph description that can be used to instantiate an actual Scenegraph in most WebGL libraries. Can load both binary `.glb` files and JSON `.gltf` files.\n\n## Data formats\n\nThis section specifies the loaded data formats.\n\n### Tileset Object\n\nThe following fields are guaranteed. Additionally, the loaded tileset object will contain all the data fetched from the provided url.\n\n| Field            | Type     | Contents                                                                                                                                                                                                                                                                                                                   |\n| ---------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `loader`         | `Object` | Tiles3DLoader                                                                                                                                                                                                                                                                                                              |\n| `root`           | `Object` | The root tile header object                                                                                                                                                                                                                                                                                                |\n| `url`            | `String` | The url of this tileset                                                                                                                                                                                                                                                                                                    |\n| `type`           | `String` | Value is `TILES3D`. Indicates the returned object is a Cesium `3D Tiles` tileset.                                                                                                                                                                                                                                          |\n| `lodMetricType`  | `String` | Root's Level of Detail (LoD) metric type, which is used to decide if a tile is sufficient for current viewport. Used for deciding if this tile is sufficient given current viewport. Cesium use [`geometricError`](https://github.com/AnalyticalGraphicsInc/3d-tiles/blob/master/specification/README.md#geometric-error). |\n| `lodMetricValue` | `Number` | Root's level of detail (LoD) metric value.                                                                                                                                                                                                                                                                                 |\n\n### Tile Object\n\nThe following fields are guaranteed. Additionally, the loaded tile object will contain all the data fetched from the provided url.\n\n| Field             | Type         | Contents                                                                                                                                                                                                                                                                                                            |\n| ----------------- | ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `url`             | `String`     | The url of this tile.                                                                                                                                                                                                                                                                                               |\n| `contentUrl`      | `String`     | The contentUrl of this tile.                                                                                                                                                                                                                                                                                        |\n| `boundingVolume`  | `Object`     | A bounding volume in Cartesian coordinates that encloses a tile or its content. Exactly one box, region, or sphere property is required. ([`Reference`](https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification#bounding-volume))                                                               |\n| `lodMetricType`   | `String`     | Level of Detail (LoD) metric type, which is used to decide if a tile is sufficient for current viewport. Used for deciding if this tile is sufficient given current viewport. Cesium use [`geometricError`](https://github.com/AnalyticalGraphicsInc/3d-tiles/blob/master/specification/README.md#geometric-error). |\n| `lodMetricValue`  | `String`     | Level of Detail (LoD) metric value.                                                                                                                                                                                                                                                                                 |\n| `children`        | `Array`      | An array of objects that define child tiles. Each child tile content is fully enclosed by its parent tile's bounding volume and, generally, has more details than parent. for leaf tiles, the length of this array is zero, and children may not be defined.                                                        |\n| `content`         | `String`     | The actual payload of the tile or the url point to the actual payload.                                                                                                                                                                                                                                              |\n| `id`              | `String`     | Identifier of the tile, unique in a tileset                                                                                                                                                                                                                                                                         |\n| `refine`          | `String`     | Refinement type of the tile, `ADD` or `REPLACE`                                                                                                                                                                                                                                                                     |\n| `type`            | `String`     | Type of the tile, one of `pointcloud` (`.pnts`), `scenegraph` (`.i3dm`, `.b3dm`)                                                                                                                                                                                                                                    |\n| `transformMatrix` | `Number[16]` | A matrix that transforms from the tile's local coordinate system to the parent tile's coordinate system—or the tileset's coordinate system in the case of the root tile                                                                                                                                             |\n\n### Tile Content\n\nAfter content is loaded, the following fields are guaranteed. But different tiles may have different extra content fields.\n\n| Field                | Type         | Contents                                                                                                                               |\n| -------------------- | ------------ | -------------------------------------------------------------------------------------------------------------------------------------- |\n| `cartesianOrigin`    | `Number[3]`  | \"Center\" of tile geometry in WGS84 fixed frame coordinates                                                                             |\n| `cartographicOrigin` | `Number[3]`  | \"Origin\" in lng/lat (center of tile's bounding volume)                                                                                 |\n| `modelMatrix`        | `Number[16]` | Transforms tile geometry positions to fixed frame coordinates                                                                          |\n| `attributes`         | `Object`     | Each attribute follows luma.gl [accessor](https://github.com/uber/luma.gl/blob/master/docs/api-reference/webgl/accessor.md) properties |\n\n`attributes` contains following fields\n\n| Field                  | Type     | Contents                          |\n| ---------------------- | -------- | --------------------------------- |\n| `attributes.positions` | `Object` | `{value, type, size, normalized}` |\n| `attributes.normals`   | `Object` | `{value, type, size, normalized}` |\n| `attributes.colors`    | `Object` | `{value, type, size, normalized}` |\n\nPointCloud Fields\n\n| Field        | Type                       | Contents                                                 |\n| ------------ | -------------------------- | -------------------------------------------------------- |\n| `pointCount` | `Number`                   | Number of points                                         |\n| `color`      | `Number[3]` or `Number[4]` | Color of the tile when there are not `attributes.colors` |\n\nScenegraph Fields\n\n| Field  | Type     | Contents                                                                                             |\n| ------ | -------- | ---------------------------------------------------------------------------------------------------- |\n| `gltf` | `Object` | check [GLTFLoader](https://loaders.gl/modules/gltf/docs/api-reference/gltf-loader) for detailed spec |\n","slug":"modules/3d-tiles/docs/api-reference/tiles-3d-loader","title":"Tiles3DLoader"},{"excerpt":"Tile3DStyle /** A style that is applied to a {@link Cesium3DTileset}.  Evaluates an expression defined using the {@link https://github.com…","rawMarkdownBody":"# Tile3DStyle\n\n/** A style that is applied to a {@link Cesium3DTileset}. <p> Evaluates an expression defined using the {@link https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification/Styling|3D Tiles Styling language}. </p> @alias Tile3DStyle @constructor @param {Resource|String|Object} [style] The url of a style or an object defining a style.\n\n\n\n## Attribution\n\n// This file is derived from the Cesium code base under Apache 2 license\n// See LICENSE.md and https://github.com/AnalyticalGraphicsInc/cesium/blob/master/LICENSE.md\n\n\n## Usage\n\nCreating a style instance\n```js\ntileset.style = new Cesium.Cesium3DTileStyle({\n    color : {\n        conditions : [\n            ['${Height} >= 100', 'color(\"purple\", 0.5)'],\n            ['${Height} >= 50', 'color(\"red\")'],\n            ['true', 'color(\"blue\")']\n        ]\n    },\n    show : '${Height} > 0',\n    meta : {\n        description : '\"Building id ${id} has height ${Height}.\"'\n    }\n});\n```\n\n```js\ntileset.style = new Cesium.Cesium3DTileStyle({\n    color : 'vec4(${Temperature})',\n    pointSize : '${Temperature} * 2.0'\n});\n```\n\nEvaluating `show` (feature visibility) using a style\n\n```js\nconst style = new Tile3DStyle({\n     show : '(regExp(\"^Chest\").test(${County})) && (${YearBuilt} >= 1970)'\n});\nstyle.show.evaluate(feature); // returns true or false depending on the feature's properties\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override show expression with a custom function\nstyle.show = {\n     evaluate : function(feature) {\n     return true;\n   }\n};\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override show expression with a boolean\nstyle.show = true;\n};\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override show expression with a string\nstyle.show = '${Height} > 0';\n};\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override show expression with a condition\nstyle.show = {\n     conditions: [\n     ['${height} > 2', 'false'],\n   ['true', 'true']\n   ];\n};\n```\n\nEvaluating colors using the style\n\n```js\nconst style = new Tile3DStyle({\n  color : '(${Temperature} > 90) ? color(\"red\") : color(\"white\")'\n});\nstyle.color.evaluateColor(feature, result); // returns a Color object\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override color expression with a custom function\nstyle.color = {\n     evaluateColor : function(feature, result) {\n     return Color.clone(Color.WHITE, result);\n   }\n};\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override color expression with a string\nstyle.color = 'color(\"blue\")';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override color expression with a condition\nstyle.color = {\n     conditions : [\n     ['${height} > 2', 'color(\"cyan\")'],\n   ['true', 'color(\"blue\")']\n   ]\n};\n```\n\nControlling pointSize using styles\n\n```js\nconst style = new Tile3DStyle({\n     pointSize : '(${Temperature} > 90) ? 2.0 : 1.0'\n});\nstyle.pointSize.evaluate(feature); // returns a Number\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override pointSize expression with a custom function\nstyle.pointSize = {\n     evaluate : function(feature) {\n     return 1.0;\n   }\n};\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override pointSize expression with a number\nstyle.pointSize = 1.0;\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override pointSize expression with a string\nstyle.pointSize = '${height} / 10';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override pointSize expression with a condition\nstyle.pointSize =  {\n     conditions : [\n     ['${height} > 2', '1.0'],\n   ['true', '2.0']\n   ]\n};\n```\n\n\nChanging `pointOutlineColor` (experimental)\n\n```js\nconst style = new Tile3DStyle();\n// Override pointOutlineColor expression with a string\nstyle.pointOutlineColor = 'color(\"blue\")';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override pointOutlineColor expression with a condition\nstyle.pointOutlineColor = {\n     conditions : [\n     ['${height} > 2', 'color(\"cyan\")'],\n   ['true', 'color(\"blue\")']\n   ]\n};\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override pointOutlineWidth expression with a string\nstyle.pointOutlineWidth = '5';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override pointOutlineWidth expression with a condition\nstyle.pointOutlineWidth = {\n     conditions : [\n     ['${height} > 2', '5'],\n   ['true', '0']\n   ]\n};\n```\n\nSetting label color\n\n```js\nconst style = new Tile3DStyle();\n// Override labelColor expression with a string\nstyle.labelColor = 'color(\"blue\")';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override labelColor expression with a condition\nstyle.labelColor = {\n     conditions : [\n     ['${height} > 2', 'color(\"cyan\")'],\n   ['true', 'color(\"blue\")']\n   ]\n};\n```\n\nSetting label outline color\n\n```js\nconst style = new Tile3DStyle();\n// Override labelOutlineColor expression with a string\nstyle.labelOutlineColor = 'color(\"blue\")';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override labelOutlineColor expression with a condition\nstyle.labelOutlineColor = {\n     conditions : [\n     ['${height} > 2', 'color(\"cyan\")'],\n   ['true', 'color(\"blue\")']\n   ]\n};\n```\n\nEvaluating a font using a style\n\n```js\nconst style = new Tile3DStyle({\n     font : '(${Temperature} > 90) ? \"30px Helvetica\" : \"24px Helvetica\"'\n});\nstyle.font.evaluate(feature); // returns a String\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override font expression with a custom function\nstyle.font = {\n     evaluate : function(feature) {\n     return '24px Helvetica';\n   }\n};\n```\n\nEvaluating a `labelStyle` using a style\n\n```js\nconst style = new Tile3DStyle({\n     labelStyle : '(${Temperature} > 90) ? ' + LabelStyle.FILL_AND_OUTLINE + ' : ' + LabelStyle.FILL\n});\nstyle.labelStyle.evaluate(feature); // returns a LabelStyle\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override labelStyle expression with a custom function\nstyle.labelStyle = {\n     evaluate : function(feature) {\n     return LabelStyle.FILL;\n   }\n};\n```\n\nEvaluating a labelText using a style\n\n```js\nconst style = new Tile3DStyle({\n     labelText : '(${Temperature} > 90) ? \">90\" : \"<=90\"'\n});\nstyle.labelText.evaluate(feature); // returns a String\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override labelText expression with a custom function\nstyle.labelText = {\n     evaluate : function(feature) {\n     return 'Example label text';\n   }\n};\n```\n\n\n## Member Fields\n\n### style : Object (readonly)\n\nGets the object defining the style using the\n{@link https://github.com/AnalyticalGraphicsInc/3d-tiles/tree/master/specification/Styling|3D Tiles Styling language}.\n\nDefault: `{}`\n\n\n### show : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `show` property. Alternatively a boolean, string, or object defining a show style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return or convert to a `Boolean`.\n\nThis expression is applicable to all tile formats.\n\n\n### color : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `color` property. Alternatively a string or object defining a color style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Color`.\n\nThis expression is applicable to all tile formats.\n\n\n### pointSize : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `pointSize` property. Alternatively a string or object defining a point size style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Number`.\n\nThis expression is only applicable to point features in a Vector tile or a Point Cloud tile.\n\n\n### pointOutlineColor : StyleExpression\n\n> **experimental** This feature is using part of the 3D Tiles spec that is not final and is subject to change without a standard deprecation policy.\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `pointOutlineColor` property. Alternatively a string or object defining a color style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Color`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n### pointOutlineWidth : StyleExpression\n\n> **experimental** This feature is using part of the 3D Tiles spec that is not final and is subject to change without a standard deprecation policy.\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `pointOutlineWidth` property. Alternatively a string or object defining a number style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Number`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n### labelColor : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `labelColor` property. Alternatively a string or object defining a color style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Color`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n\n### labelOutlineColor : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `labelOutlineColor` property. Alternatively a string or object defining a color style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Color`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n### labelOutlineWidth : StuleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `labelOutlineWidth` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Number`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n@example\nconst style = new Tile3DStyle();\n// Override labelOutlineWidth expression with a string\nstyle.labelOutlineWidth = '5';\n\n@example\nconst style = new Tile3DStyle();\n// Override labelOutlineWidth expression with a condition\nstyle.labelOutlineWidth = {\n     conditions : [\n     ['${height} > 2', '5'],\n   ['true', '0']\n   ]\n};\n\n\n### font\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `font` property. Alternatively a string or object defining a string style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `String`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n@type {StyleExpression}\n\n\n### labelStyle : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `label style` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `LabelStyle`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n### labelText : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `labelText` property. Alternatively a string or object defining a string style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `String`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `backgroundColor` property. Alternatively a string or object defining a color style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Color`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\n\nconst style = new Tile3DStyle();\n// Override backgroundColor expression with a string\nstyle.backgroundColor = 'color(\"blue\")';\n\n```js\n\nconst style = new Tile3DStyle();\n// Override backgroundColor expression with a condition\nstyle.backgroundColor = {\n     conditions : [\n     ['${height} > 2', 'color(\"cyan\")'],\n   ['true', 'color(\"blue\")']\n   ]\n};\n   */\n  backgroundColor : {\n    get : function() {\n      this._checkReady();\n      return this._backgroundColor;\n    },\n    set : function(value) {\n      this._backgroundColor = getExpression(this, value);\n      this._style.backgroundColor = getJsonFromExpression(this._backgroundColor);\n    }\n  },\n\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `backgroundPadding` property. Alternatively a string or object defining a vec2 style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Cartesian2`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\n\nconst style = new Tile3DStyle();\n// Override backgroundPadding expression with a string\nstyle.backgroundPadding = 'vec2(5.0, 7.0)';\nstyle.backgroundPadding.evaluate(feature); // returns a Cartesian2\n   */\n  backgroundPadding : {\n    get : function() {\n      this._checkReady();\n      return this._backgroundPadding;\n    },\n    set : function(value) {\n      this._backgroundPadding = getExpression(this, value);\n      this._style.backgroundPadding = getJsonFromExpression(this._backgroundPadding);\n    }\n  },\n\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `backgroundEnabled` property. Alternatively a string or object defining a boolean style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Boolean`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\n\nconst style = new Tile3DStyle();\n// Override backgroundEnabled expression with a string\nstyle.backgroundEnabled = 'true';\n\n```js\n\nconst style = new Tile3DStyle();\n// Override backgroundEnabled expression with a condition\nstyle.backgroundEnabled = {\n     conditions : [\n     ['${height} > 2', 'true'],\n   ['true', 'false']\n   ]\n};\n   */\n  backgroundEnabled : {\n    get : function() {\n      this._checkReady();\n      return this._backgroundEnabled;\n    },\n    set : function(value) {\n      this._backgroundEnabled = getExpression(this, value);\n      this._style.backgroundEnabled = getJsonFromExpression(this._backgroundEnabled);\n    }\n  },\n\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `scaleByDistance` property. Alternatively a string or object defining a vec4 style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Cartesian4`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\n\nconst style = new Tile3DStyle();\n// Override scaleByDistance expression with a string\nstyle.scaleByDistance = 'vec4(1.5e2, 2.0, 1.5e7, 0.5)';\nstyle.scaleByDistance.evaluate(feature); // returns a Cartesian4\n   */\n  scaleByDistance : {\n    get : function() {\n      this._checkReady();\n      return this._scaleByDistance;\n    },\n    set : function(value) {\n      this._scaleByDistance = getExpression(this, value);\n      this._style.scaleByDistance = getJsonFromExpression(this._scaleByDistance);\n    }\n  },\n\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `translucencyByDistance` property. Alternatively a string or object defining a vec4 style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Cartesian4`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\n\nconst style = new Tile3DStyle();\n// Override translucencyByDistance expression with a string\nstyle.translucencyByDistance = 'vec4(1.5e2, 1.0, 1.5e7, 0.2)';\nstyle.translucencyByDistance.evaluate(feature); // returns a Cartesian4\n   */\n  translucencyByDistance : {\n    get : function() {\n      this._checkReady();\n      return this._translucencyByDistance;\n    },\n    set : function(value) {\n      this._translucencyByDistance = getExpression(this, value);\n      this._style.translucencyByDistance = getJsonFromExpression(this._translucencyByDistance);\n    }\n  },\n\n\n### distanceDisplayCondition : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `distanceDisplayCondition` property. Alternatively a string or object defining a vec2 style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Cartesian2`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\nconst style = new Tile3DStyle();\n// Override distanceDisplayCondition expression with a string\nstyle.distanceDisplayCondition = 'vec2(0.0, 5.5e6)';\nstyle.distanceDisplayCondition.evaluate(feature); // returns a Cartesian2\n```\n\n### heightOffset : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `heightOffset` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Number`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n```js\nconst style = new Tile3DStyle();\n// Override heightOffset expression with a string\nstyle.heightOffset = '2.0';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override heightOffset expression with a condition\nstyle.heightOffset = {\n     conditions : [\n     ['${height} > 2', '4.0'],\n   ['true', '2.0']\n   ]\n};\n```\n\n### anchorLineEnabled : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `anchorLineEnabled` property. Alternatively a string or object defining a boolean style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Boolean`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\nconst style = new Tile3DStyle();\n// Override anchorLineEnabled expression with a string\nstyle.anchorLineEnabled = 'true';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override anchorLineEnabled expression with a condition\nstyle.anchorLineEnabled = {\n     conditions : [\n     ['${height} > 2', 'true'],\n   ['true', 'false']\n   ]\n};\n```\n\n### anchorLineColor : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `anchorLineColor` property. Alternatively a string or object defining a color style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Color`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\nconst style = new Tile3DStyle();\n// Override anchorLineColor expression with a string\nstyle.anchorLineColor = 'color(\"blue\")';\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override anchorLineColor expression with a condition\nstyle.anchorLineColor = {\n     conditions : [\n     ['${height} > 2', 'color(\"cyan\")'],\n   ['true', 'color(\"blue\")']\n   ]\n};\n```\n\n###\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `image` property. Alternatively a string or object defining a string style can be used.\n\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `String`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n```js\nconst style = new Tile3DStyle({\n     image : '(${Temperature} > 90) ? \"/url/to/image1\" : \"/url/to/image2\"'\n});\nstyle.image.evaluate(feature); // returns a String\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override image expression with a custom function\nstyle.image = {\n     evaluate : function(feature) {\n     return '/url/to/image';\n   }\n};\n```\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `disableDepthTestDistance` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `Number`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\nconst style = new Tile3DStyle();\n// Override disableDepthTestDistance expression with a string\nstyle.disableDepthTestDistance = '1000.0';\nstyle.disableDepthTestDistance.evaluate(feature); // returns a Number\n```\n\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `horizontalOrigin` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `HorizontalOrigin`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\nconst style = new Tile3DStyle({\n     horizontalOrigin : HorizontalOrigin.LEFT\n});\nstyle.horizontalOrigin.evaluate(feature); // returns a HorizontalOrigin\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override horizontalOrigin expression with a custom function\nstyle.horizontalOrigin = {\n     evaluate : function(feature) {\n     return HorizontalOrigin.CENTER;\n   }\n};\n```\n\n### verticalOrigin : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `verticalOrigin` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `VerticalOrigin`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n```js\n\nconst style = new Tile3DStyle({\n     verticalOrigin : VerticalOrigin.TOP\n});\nstyle.verticalOrigin.evaluate(feature); // returns a VerticalOrigin\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override verticalOrigin expression with a custom function\nstyle.verticalOrigin = {\n     evaluate : function(feature) {\n     return VerticalOrigin.CENTER;\n   }\n};\n```\n\n### labelVerticalOrigin : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `labelHorizontalOrigin` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `HorizontalOrigin`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\nconst style = new Tile3DStyle({\n     labelHorizontalOrigin : HorizontalOrigin.LEFT\n});\nstyle.labelHorizontalOrigin.evaluate(feature); // returns a HorizontalOrigin\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override labelHorizontalOrigin expression with a custom function\nstyle.labelHorizontalOrigin = {\n     evaluate : function(feature) {\n     return HorizontalOrigin.CENTER;\n   }\n};\n```\n\n### labelVerticalOrigin : StyleExpression\n\nGets or sets the {@link StyleExpression} object used to evaluate the style's `labelVerticalOrigin` property. Alternatively a string or object defining a number style can be used.\nThe getter will return the internal {@link Expression} or {@link ConditionsExpression}, which may differ from the value provided to the setter.\n\nThe expression must return a `VerticalOrigin`.\n\nThis expression is only applicable to point features in a Vector tile.\n\n\n```js\nconst style = new Tile3DStyle({\n     labelVerticalOrigin : VerticalOrigin.TOP\n});\nstyle.labelVerticalOrigin.evaluate(feature); // returns a VerticalOrigin\n```\n\n```js\nconst style = new Tile3DStyle();\n// Override labelVerticalOrigin expression with a custom function\nstyle.labelVerticalOrigin = {\n     evaluate : function(feature) {\n     return VerticalOrigin.CENTER;\n   }\n};\n```\n\n### meta : StyleExpression\n\nGets or sets the object containing application-specific expression that can be explicitly evaluated, e.g., for display in a UI.\n\n\n```js\nconst style = new Tile3DStyle({\n     meta : {\n     description : '\"Building id ${id} has height ${Height}.\"'\n   }\n});\n```\n","slug":"modules/3d-tiles/wip/styles/docs/tile-3d-style","title":"Tile3DStyle"},{"excerpt":"","rawMarkdownBody":"","slug":"arrowjs/docs/paul-drafts/vectors/index","title":""},{"excerpt":"","rawMarkdownBody":"","slug":"arrowjs/docs/paul-drafts/tables/index","title":""},{"excerpt":"","rawMarkdownBody":"","slug":"arrowjs/docs/paul-drafts/ipc/index","title":""},{"excerpt":"","rawMarkdownBody":"","slug":"arrowjs/docs/paul-drafts/data-types/index","title":""},{"excerpt":"","rawMarkdownBody":"","slug":"arrowjs/docs/paul-drafts/visitors/index","title":""},{"excerpt":"","rawMarkdownBody":"","slug":"arrowjs/docs/paul-drafts/builders/index","title":""},{"excerpt":"Contributing This page contains information for Arrow JS contributors. API Design Notes Understanding some of the design decisions made when…","rawMarkdownBody":"# Contributing\n\nThis page contains information for Arrow JS contributors.\n\n## API Design Notes\n\nUnderstanding some of the design decisions made when defining the JavaScript binding API may help facilitate a better appreciateion of why the API is designed the way it is:\n\n- To facilitate keeping the evolution of the JavaScript bindings matched to other bindings, the JavaScript Arrow API is designed to be close match to the C++ Arrow API, although some differences have been made where it makes sense. Some design patterns, like the way `RecordBatchReader.from()` returns different `RecordBatchReader` subclasses depending on what source is being read.\n\n\n## Editing Documentation\n\n### Markdown vs JSDoc\n\nSince the Arrow JavaScript API includes both manually written markdown and \"automatically\" generated jsdoc. Some main differences are:\n\n- The markdown version contains a \"Developer Guide\" which is not present in the jsdoc.\n- The markdown version of the \"API reference\" focuses on readability. It contains more text with semantic descriptions and examples of usage of classes and functions. It also omits more complex typescript annotions for function prototypes to ensure that the API documentation is easy to digest for all JavaScript programmers.\n- The jsdoc version includes the full Typescript type information and is more richly hyperlinked and can be valuable to developers as a supplement to the markdown reference when those particular details matter.\n\n### Updating Docs\n\nIn general, the markdown docs should be considered the source of truth for the JavaScript API:\n\n* To avoid excessive duplication and possible divergence between markdown and JSDoc, it is recommended that the JSDoc version contains brief summary texts only.\n* Reviewers should make sure that PRs affecting the JS API (bothk features and bug fixes) contain appropriate changes to the markdown docs (in the same way that such PRs must contain appropriate changes to e.g. test cases).\n* When appropriate, to ensure the markdown docs remain \"the source of truth\" for the Arrow JS API, bugs should be reviewed first towards the markdown documentation, e.g. to see if the documented behavior is incorrectly specified and needs to be fixed.\n","slug":"arrowjs/docs/contributing","title":"Contributing"},{"excerpt":"Introduction The Arrow JavaScript API is designed to helps applications tap into the full power of working with binary columnar data in the…","rawMarkdownBody":"# Introduction\n\nThe Arrow JavaScript API is designed to helps applications tap into the full power of working with binary columnar data in the Apache Arrow format. Arrow JS has a rich set of classes that supports use cases such as batched loading and writing, as well performing data frame operations on Arrow encoded data, including applying filters, iterating over tables, etc.\n\n## Getting Started\n\nTo install and start coding with Apache Arrow JS bindings, see the [Getting Started](docs/get-started).\n\n\n## About Apache Arrow\n\nApache Arrow is a performance-optimized binary columnar memory layout specification for encoding vectors and table-like containers of flat and nested data. The Arrow spec is design to eliminate memory copies and aligns columnar data in memory to minimize cache misses and take advantage of the latest SIMD (Single input multiple data) and GPU operations on modern processors.\n\nApache Arrow is emerging as the standard for large in-memory columnar data (Spark, Pandas, Drill, Graphistry, ...). By standardizing on a common binary interchange format, big data systems can reduce the costs and friction associated with cross-system communication.\n\n\n## Resources\n\nThere are some excellent resources available that can help you quickly get a feel for what capabilities the Arrow JS API offers:\n\n* Observable: [Introduction to Apache Arrow](https://observablehq.com/@theneuralbit/introduction-to-apache-arrow)\n* Observable: [Using Apache Arrow JS with Large Datasets](https://observablehq.com/@theneuralbit/using-apache-arrow-js-with-large-datasets)\n* Observable: [Manipulating Flat Arrays, Arrow-Style](https://observablehq.com/@lmeyerov/manipulating-flat-arrays-arrow-style)\n* [Manipulating Flat Arrays](https://observablehq.com/@mbostock/manipulating-flat-arrays) General article on Columnar Data and Data Frames\n\nApache Arrow project links:\n\n* [Apache Arrow Home](https://arrow.apache.org/)\n* [Apache Arrow JS on github](https://github.com/apache/arrow/tree/master/js)\n* [Apache Arrow JS on npm](https://www.npmjs.com/package/apache-arrow)\n","slug":"arrowjs/docs","title":"Introduction"},{"excerpt":"Roadmap What's Next for Apache Arrow in Javascript There are a lot of features we'd like to add over the next few Javascript releases…","rawMarkdownBody":"# Roadmap\n\nWhat's Next for Apache Arrow in Javascript\n\nThere are a lot of features we'd like to add over the next few Javascript releases:\n\n* **Inline predicates**: Function calls in the inner loop of a scan over millions of records can be very expensive. We can potentially save that time by generating a new scan function with the predicates inlined when a filter is created.\n\n* **Cache filter results**: Right now every time we do a scan on a filtered DataFrame we re-check the predicate on every row. There should be an (optional?) lazily computed index to store the predicate results for subsequent re-use.\n\n* **Friendlier API**: I shouldn't have to write a custom scan function just to take a look at the results of a filter! Every DataFrame should have a toJSON() function (See ARROW-2202).\n\n* **node.js ↔ (Python, C++, Java, ...) interaction**: A big benefit of Arrow's common in-memory format is that different tools can operate on the same memory. Unfortunately we're pretty closed off in the browser, but node doesn't have that problem! Finishing ARROW-1700, node.js Plasma store client should make this type of interaction possible.\n\nHave an idea? Tell us! Generally JIRAs are preferred but we'll take GitHub issues too. If you just want to discuss something, reach out on the mailing list or slack. But PRs are the best of all, we can always use more contributors!\n\n\n## Feature Completeness\n\nIdeally each Apache Arrow language binding would offer the same set of features, at least to the extent that the language/platform in question allows. In practice however, not all features have been implemented in all language bindings.\n\nIn comparison with the C++ Arrow API bindings, there are some missing features in the JavaScript bindings:\n\n- Tensors are not yet supported.\n- No explicit support for Apache Arrow Flight\n","slug":"arrowjs/docs/roadmap","title":"Roadmap"},{"excerpt":"Introduction Apache Arrow is a binary specification and set of libraries for representing Tables and Columns of strongly-typed fixed-width…","rawMarkdownBody":"# Introduction\n\nApache Arrow is a binary specification and set of libraries for representing Tables and Columns of strongly-typed fixed-width, variable-width, and nested data structures in-memory and over-the-wire.\n\nArrow represents columns of values in sets of contiguous buffers. This is in contrast to a row-oriented representation, where the values for each row are stored in a contiguous buffer. The columnar representation makes it easier to take advantage of SIMD instruction sets in modern CPUs and GPUs, and can lead to dramatic performance improvements processing large amounts of data.\n\n## Components\n\nThe Arrow library is organized into separate components responsible for creating, reading, writing, serializing, deserializing, or manipulating Tables or Columns.\n\n* [Data Types](docs/paul-drafts/introduction.md#arrow-data-types) - Classes that define the fixed-width, variable-width, and composite data types Arrow can represent\n* [Vectors](docs/paul-drafts/introduction.md#arrow-vectors) - Classes to read and decode JavaScript values from the underlying buffers or Vectors for each data type\n* [Builders](docs/paul-drafts/introduction.md#arrow-builders) - Classes to write and encode JavaScript values into the underlying buffers or Vectors for each data type\n* [Visitors](docs/paul-drafts/introduction.md#arrow-visitors) - Classes to traverse, manipulate, read, write, or aggregate values from trees of Arrow Vectors or DataTypes\n* [IPC Readers and Writers](docs/paul-drafts/introduction.md#arrow-ipc-primitives) - Classes to read and write the Arrow IPC (inter-process communication) binary file and stream formats\n* [Fields, Schemas, RecordBatches, Tables, and Columns](docs/paul-drafts/introduction.md#fields-schemas-recordbatches-tables-and-columns) - Classes to describe, manipulate, read, and write groups of strongly-typed Vectors or Columns\n\n## [Data Types](docs/paul-drafts/data-types/index.md)\n\nAt the heart of Arrow is set of well-known logical [data types](docs/paul-drafts/data-types/index.md), ensuring each Column in an Arrow Table is strongly-typed. These data types define how a Column's underlying buffers should be constructed and read, and includes configurable (and custom) metadata fields for further annotating a Column. A Schema describing each Column's name and data type is encoded alongside each Column's data buffers, allowing you to consume an Arrow data source without knowing the data types or column layout beforehand.\n\nEach data type falls into one of three rough categories: Fixed-width types, variable-width types, or composite types that contain other Arrow data types. All data types can represent null values, which are stored in a separate validity [bitmask](https://en.wikipedia.org/wiki/Mask_(computing)). Follow the links below for a more detailed description of each data type.\n\n### [Fixed-width Data Types](docs/paul-drafts/data-types/index.md#fixed-width-data-types)\n\nFixed-width data types describe physical primitive values (bytes or bits of some fixed size), or logical values that can be represented as primitive values. In addition to an optional [`Uint8Array`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array) validity bitmask, these data types have a physical data buffer (a [`TypedArray`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray#TypedArray_objects) corresponding to the data type's physical element width).\n\n * [Null](docs/paul-drafts/data-types/index.md#null) - A column of NULL values having no physical storage\n * [Bool](docs/paul-drafts/data-types/index.md#bool) - Booleans as either 0 or 1 (bit-packed, LSB-ordered)\n * [Int](docs/paul-drafts/data-types/index.md#int) - Signed or unsigned 8, 16, 32, or 64-bit little-endian integers\n * [Float](docs/paul-drafts/data-types/index.md#float) - 2, 4, or 8-byte floating point values\n * [Decimal](docs/paul-drafts/data-types/index.md#decimal) - Precision-and-scale-based 128-bit decimal values\n * [FixedSizeBinary](docs/paul-drafts/data-types/index.md#fixedsizebinary) - A list of fixed-size binary sequences, where each value occupies the same number of bytes\n * [Date](docs/paul-drafts/data-types/index.md#date) - Date as signed 32-bit integer days or 64-bit integer milliseconds since the UNIX epoch\n * [Time](docs/paul-drafts/data-types/index.md#time) - Time as signed 32 or 64-bit integers, representing either seconds, millisecond, microseconds, or nanoseconds since midnight (00:00:00)\n * [Timestamp](docs/paul-drafts/data-types/index.md#timestamp) - Exact timestamp as signed 64-bit integers, representing either seconds, milliseconds, microseconds, or nanoseconds since the UNIX epoch\n * [Interval](docs/paul-drafts/data-types/index.md#interval) - Time intervals as pairs of either (year, month) or (day, time) in SQL style\n * [FixedSizeList](docs/paul-drafts/data-types/index.md#fixedsizelist) - Fixed-size sequences of another logical Arrow data type\n\n### [Variable-width Data Types](docs/paul-drafts/data-types/index.md#variable-width-data-types)\n\nVariable-width types describe lists of values with different widths, including binary blobs, Utf8 code-points, or slices of another underlying Arrow data type. These types store the values contiguously in memory, and have a physical [`Int32Array`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array) of offsets that describe the start and end indicies of each list element.\n\n * [List](docs/paul-drafts/data-types/list.md) - Variable-length sequences of another logical Arrow data type\n * [Utf8](docs/paul-drafts/data-types/utf8.md) - Variable-length byte sequences of UTF8 code-points (strings)\n * [Binary](docs/paul-drafts/data-types/binary.md) - Variable-length byte sequences (no guarantee of UTF8-ness)\n\n### [Composite Data Types](docs/paul-drafts/data-types/index.md#composite-data-types)\n\nComposite types don't have physical data buffers of their own. They contain other Arrow data types and delegate work to them.\n\n * [Union](docs/paul-drafts/data-types/union.md) - Union of logical child data types\n * [Map](docs/paul-drafts/data-types/map.md) - Map of named logical child data types\n * [Struct](docs/paul-drafts/data-types/struct.md) - Struct of ordered logical child data types\n","slug":"arrowjs/docs/paul-drafts/introduction","title":"Introduction"},{"excerpt":"Installing Installing Arrow JS The Apache Arrow JS bindings are published as an npm module. Importing Arrow JS You should now be able to…","rawMarkdownBody":"# Installing\n\n## Installing Arrow JS\n\nThe Apache Arrow JS bindings are published as an npm module.\n\n```sh\nnpm install apache-arrow\n# or\nyarn add apache-arrow\n```\n\n\n## Importing Arrow JS\n\nYou should now be able to import arrow into your projects\n\n```js\nimport {Table} from 'apache-arrow';\n```\n","slug":"arrowjs/docs/get-started/installing","title":"Installing"},{"excerpt":"Examples Some short examples Get a table from an Arrow file on disk (in IPC format) Create a Table when the Arrow file is split across…","rawMarkdownBody":"# Examples\n\nSome short examples\n\n### Get a table from an Arrow file on disk (in IPC format)\n\n```js\nimport { readFileSync } from 'fs';\nimport { Table } from 'apache-arrow';\n\nconst arrow = readFileSync('simple.arrow');\nconst table = Table.from([arrow]);\n\nconsole.log(table.toString());\n\n/*\n foo,  bar,  baz\n   1,    1,   aa\nnull, null, null\n   3, null, null\n   4,    4,  bbb\n   5,    5, cccc\n*/\n```\n\n### Create a Table when the Arrow file is split across buffers\n\n```js\nimport { readFileSync } from 'fs';\nimport { Table } from 'apache-arrow';\n\nconst table = Table.from([\n    'latlong/schema.arrow',\n    'latlong/records.arrow'\n].map((file) => readFileSync(file)));\n\nconsole.log(table.toString());\n\n/*\n        origin_lat,         origin_lon\n35.393089294433594,  -97.6007308959961\n35.393089294433594,  -97.6007308959961\n35.393089294433594,  -97.6007308959961\n29.533695220947266, -98.46977996826172\n29.533695220947266, -98.46977996826172\n*/\n```\n\n### Create a Table from JavaScript arrays\n\n```js\nimport {\n  Table,\n  FloatVector,\n  DateVector\n} from 'apache-arrow';\n\nconst LENGTH = 2000;\n\nconst rainAmounts = Float32Array.from(\n  { length: LENGTH },\n  () => Number((Math.random() * 20).toFixed(1)));\n\nconst rainDates = Array.from(\n  { length: LENGTH },\n  (_, i) => new Date(Date.now() - 1000 * 60 * 60 * 24 * i));\n\nconst rainfall = Table.new(\n  [FloatVector.from(rainAmounts), DateVector.from(rainDates)],\n  ['precipitation', 'date']\n);\n```\n\n### Load data with `fetch`\n\n```js\nimport { Table } from \"apache-arrow\";\n\nconst table = await Table.from(fetch((\"/simple.arrow\")));\nconsole.log(table.toString());\n\n```\n\n### Columns look like JS Arrays\n\n```js\nimport { readFileSync } from 'fs';\nimport { Table } from 'apache-arrow';\n\nconst table = Table.from([\n    'latlong/schema.arrow',\n    'latlong/records.arrow'\n].map(readFileSync));\n\nconst column = table.getColumn('origin_lat');\n\n// Copy the data into a TypedArray\nconst typed = column.toArray();\nassert(typed instanceof Float32Array);\n\nfor (let i = -1, n = column.length; ++i < n;) {\n    assert(column.get(i) === typed[i]);\n}\n```\n","slug":"arrowjs/docs/get-started/examples","title":"Examples"},{"excerpt":"What's New v0.4.1 TBA v0.4.0 TBA v0.3.0 TBA v0.3.0 TBA","rawMarkdownBody":"# What's New\n\n# v0.4.1\n\nTBA\n\n\n# v0.4.0\n\nTBA\n\n\n# v0.3.0\n\nTBA\n\n\n# v0.3.0\n\nTBA\n","slug":"arrowjs/docs/whats-new","title":"What's New"},{"excerpt":"Extracting Data While keeping data in Arrow format allows for efficient data frame operations, there are of course cases where data needs to…","rawMarkdownBody":"# Extracting Data\n\nWhile keeping data in Arrow format allows for efficient data frame operations, there are of course cases where data needs to be extracted in a form that can be use with non-Arrow-aware JavaScript code.\n\n### Converting Data\n\nMany arrow classes support the following methods:\n\n* `toArray()` - Typically returns a typed array.\n* `toJSON()` - Arrow JS types can be converted to JSON.\n* `toString()` - Arrow JS types can be converted to strings.\n\n### Extracting Data by Row\n\nYou can get a temporary object representing a row in a table.\n\n```js\nconst row = table.get(0);\n```\n\nNote that the `row` does not retain the schema, so you'll either need to know the order of columns `row.get(0)`, or use the `to*()` methods.\n\n### Extracting Data by Column\n\nMore efficient is to get a column.\n\n```js\nconst column = table.getColumn('data');\n```\n\nThe column can be chunked, so to get a contiguous (typed) array, call\n\n```js\nconst array = table.getColumn('columnName').toArray();\n```\n\nNote that if there are multiple chunks in the array, this will create a new typed array and copy the typed arrays in the chunks into that array.\n\n### Extracting data by Column and Batch\n\nA more efficient (zero-copy) way to get access to data (especially if the table has not been sliced or filtered) could be to walk through the chunks in each column and get the underlying typed array for that chunk.\n","slug":"arrowjs/docs/developer-guide/converting-data","title":"Extracting Data"},{"excerpt":"Data Frame Operations Part of the power of data frame operations is that they typically do not actually perform any modifications (copying…","rawMarkdownBody":"# Data Frame Operations\n\nPart of the power of data frame operations is that they typically do not actually perform any modifications (copying etc) of the underlying data, and ultimately only impact how iteration over that data is done, and what \"view\" of the data is presented. This allows data frame operations to be extremely performant, even when applied on very big (multi-gigabyte) data aset.\n\nNote that the Arrow JS `Table` class inherits from the `DataFrame` class which is why the examples in this section can use `DataFrame` methods to `Table` instances.\n\nAlso, most of the data frame operations do not modify the original `Table` or `DataFrame`, but rather return a new similar object with new filtering or \"iteration constraints\" applied. So memory is usually not changed or modified during these operations.\n\nReferences:\n* Much of the text in this section is adapted from Brian Hulette's [Introduction to Apache Arrow](https://observablehq.com/@theneuralbit/introduction-to-apache-arrow)\n\n\n## Removing Rows\n\nA simplest way to remove rows from a data frame mey be use `Table.slice(start, end)`. As usual, rather than actually modifying memory, this operation returns a new `Table`/`DataFrame` with iteration constrained to a sub set of the rows in the original frame.\n\n\n## Removing Columns\n\nThe `Table.select(keys: String[])` method drops all columns except the columns with names that match the supplied `keys`.\n\n```js\ntable.select(['name', 'age']); // Drop all colums except name and age\n````\n\n\n## Filtering Rows\n\nAnother way to \"remove\" rows from data frames is to apply filters. Filters effectively \"removes\" rows that don't fullfill the predicates in the filter. For details see the note below.\n\n```js\nconst selectedName = 'myname';\n// Remove all rows with name === 'myname'\nconst dataFrame = table.filter(arrow.predicate.col('name').eq(selectedName));\n```\n\nThe predicates classes provided by arrow allows for the comparison of column values against literals or javascript values (equality, greater or equal than, less or equal than) as well as the creation of composite logical expressions (`and`, `or` and `not`) out of individual column comparisons.\n\nIt is also possible to write custom predicates by supplying an arbitrary JavaScript function to filter a row, however performance is usually best when using the built-in comparison predicates.\n\n> Note that calling `filter()` on a `DataFrame` doesn't actually remove any rows from the underlying data store (it just stores the predicates). It's not until you iterate over the date, e.g. by calling `countBy()` or `scan()` that we actually apply the filter on the rows.\n\n\n## Counting Rows\n\nTo count the number of times different values appear in a table, use `countBy()`.\n\n```js\nconst newTable = table.countBy('column_name');\n```\n\nNote that `countBy()` does not return a modified data frame or table, but instead returns a new `Table` that contains two columns, `value` and `count`. Each distinct value in the specified column in the original table is listed once in `value`, and the corresponding `count` field in the same row indicates how many times it was present in the original table.\n\nNote that the results are not sorted.\n\n## Sorting\n\nDataFrames do not currently support sorting. To sort you need to move the data back to JavaScript arrays.\n\n## Iterating over a DataFrame (Scanning)\n\nThe `DataFrame.scan()` method lets you define a custom function that will be called for each (non-filtered) record in the `DataFrame`.\n\nNote: For simpler use cases, it is recommended to use the Arrow API provided predicates etc rather than writing a custom scan function, as performance will often be better.\n\n\n### Writing a `next` callback for `scan()`\n\nIn order to be more efficient, Arrow data is broken up into batches of records (which is what makes it possible to do concatenations despite the columnar layout, and `DataFrame.scan()` does not hide this implementation detail from you.\n\n\n### Optimizing `scan()` performance with `bind()` callbacks\n\nIn addition to the `next` callback, you can supply a `bind` function for scan to call each time it starts reading from a new `RecordBatch`. `scan` will call these functions as illustrated in the following pseudo-code:\n\n```js\nfor (const batch of batches) {\n  bind(batch);\n  for (const index in batch) {\n    next(index, batch);\n  }\n}\n```\n\nNote:\n* The `index` passed to next only applies to the current RecordBatch, it is not a global index.\n* The current `RecordBatch` is passed to `next`, so it is possible to access data without writing a bind function, but there will be a performance penalty if your data has a lot of batches.\n","slug":"arrowjs/docs/developer-guide/data-frame-operations","title":"Data Frame Operations"},{"excerpt":"Working with BigInts Arrow supports big integers. If the JavaScript platform supports the recently introduced  typed array, Arrow JS will…","rawMarkdownBody":"# Working with BigInts\n\nArrow supports big integers.\n\nIf the JavaScript platform supports the recently introduced `BigInt64Array` typed array, Arrow JS will use this type.\n\nFor convenience ArrowJS inject additional methods (on the object instance) that lets it be converted to JSON, strings, values and primitives\n\n* `bigIntArray.toJSON()`\n* `bigIntArray.toString()`\n* `bigIntArray.valueOf()`\n* `bigIntArray[Symbol.toPrimitive](hint: 'string' | 'number' | 'default')`\n\n## Notes about Conversion Methods\n\nWhen you have one of the wide numeric types (`Int64`, `Uint64`, or `Decimal` which is 128bit), those `Vector` instances always return/accept subarray slices of the underlying 32bit typed arrays.\n\nBut to make life easier for people consuming the typed arrays, the Arrow JS API adds some [extra methods](https://github.com/apache/arrow/blob/3eb07b7ed173e2ecf41d689b0780dd103df63a00/js/src/util/bn.ts#L31) to the typed arrays before they're returned. The goal of these methods is to handle conversion to and from the various primitive types (`number`, `string`, `bigint`, and `JSON.stringify()`) so people usually \"fall into the pit of success\".\n\nOne of the added methods is an implementation of [`[Symbol.toPrimitive]`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol/toPrimitive), which JS will use when doing certain kinds of implicit primitive coercion.\n\n The implementation of these methods is [bifurcated](https://github.com/apache/arrow/blob/3eb07b7ed173e2ecf41d689b0780dd103df63a00/js/src/util/bn.ts#L125), so if you're in an environment with `BigInt` support we use the native type, but if not, we'll make a best-effort attempt to return something meaningful (usually the unsigned decimal representation of the number as a string, though we'd appreciate help if someone knows how to compute the signed decimal representation).\n\nExamples:\n```js\nimport { Int64Vector } from 'apache-arrow';\nimport assert from 'assert';\n\nconst bigIntArr = new BigInt64Array([ 1n + BigInt(Number.MAX_SAFE_INTEGER) ])\nconst lilIntArr = new Int32Array(bigIntArr.buffer)\nassert(bigIntArr.length === 1)\nassert(lilIntArr.length === 2)\n\nconst bigIntVec = Int64Vector.from(bigIntArr)\nassert(bigIntVec.length === 1)\n\nconst bigIntVal = bigIntVec.get(0)\nassert(bigIntVal instanceof Int32Array)\nassert(bigIntVal[0] === 0)\nassert(bigIntVal[1] === 2097152)\n\n// these implicitly call bigIntVal[Symbol.toPrimitive]()\nassert(('' + bigIntVal) == '9007199254740992') // aka bigIntVal[Symbol.toPrimitive]('string')\nassert((0 + bigIntVal) == 9007199254740992) // aka bigIntVal[Symbol.toPrimitive]('number')\nassert((0n + bigIntVal) == 9007199254740992n) // aka bigIntVal[Symbol.toPrimitive]('default')```\n```\n","slug":"arrowjs/docs/developer-guide/big-ints","title":"Working with BigInts"},{"excerpt":"Data Sources and Sinks The Arrow JavaScript API is designed to make it easy to work with data sources both in the browser and in Node.js…","rawMarkdownBody":"# Data Sources and Sinks\n\nThe Arrow JavaScript API is designed to make it easy to work with data sources both in the browser and in Node.js.\n\n\n## Streams\n\nBoth Node and DOM/WhatWG Streams can be used directly as input sources by the Arrow JS API.\n\n## Fetch Responses\n\nFetch responses (Promises) can be used where a data source is expected.\n\n## ArrayBuffers\n\nMost data sources accept `Uint8Arrays`.\n\n## AsyncIterators\n\nAsync iterators are the most general way to abstract \"streaming\" data sources and data sinks and are consistently accepted (and in many cased returned) by the Arrow JS API.\n","slug":"arrowjs/docs/developer-guide/data-sources","title":"Data Sources and Sinks"},{"excerpt":"Data Types Arrow supports a rich set of data types: Fixed-length primitive types: numbers, booleans, date and times, fixed size binary…","rawMarkdownBody":"# Data Types\n\nArrow supports a rich set of data types:\n\n* Fixed-length primitive types: numbers, booleans, date and times, fixed size binary, decimals, and other values that fit into a given number\n* Variable-length primitive types: binary, string\n* Nested types: list, struct, and union\n* Dictionary type: An encoded categorical type\n\n\n### Converting Dates\n\nApache Arrow Timestamp is a 64-bit int of milliseconds since the epoch, represented as two 32-bit ints in JS to preserve precision. The fist number is the \"low\" int and the second number is the \"high\" int.\n\n```js\nfunction toDate(timestamp) {\n  return new Date((timestamp[1] * Math.pow(2, 32) + timestamp[0])/1000);\n}\n```\n\n","slug":"arrowjs/docs/developer-guide/data-types","title":"Data Types"},{"excerpt":"Reading and Writing Arrow Data About RecordBatches Arrow tables are typically split into record batches, allowing them to be incrementally…","rawMarkdownBody":"# Reading and Writing Arrow Data\n\n## About RecordBatches\n\nArrow tables are typically split into record batches, allowing them to be incrementally loaded or written, and naturally the Arrow API provides classes to facilite this reading.\n\n\n## Reading Arrow Data\n\nThe `Table` class provides a simple `Table.from` convenience method for reading an Arrow formatted data file into Arrow data structures:\n\n```\nimport { readFileSync } from 'fs';\nimport { Table } from 'apache-arrow';\nconst arrow = readFileSync('simple.arrow');\nconst table = Table.from([arrow]);\nconsole.log(table.toString());\n```\n\n### Using RecordBatchReader to read from a Data Source\n\nTo read Arrow tables incrementally, you use the `RecordBatchReader` class.\n\nIf you only have one table in your file (the normal case), then you'll only need one `RecordBatchReader`:\n\n```js\nconst reader = await RecordBatchReader.from(fetch(path, {credentials: 'omit'}));\nfor await (const batch of reader) {\n  console.log(batch.length);\n}\n```\n\n### Reading Multiple Tables from a Data Source\n\nThe JavaScript Arrow API supports arrow data streams that contain multiple tables (this is an \"extension\" to the arrow spec). Naturally, each Table comes with its own set of record batches, so to read all batches from all tables in the data source you will need a double loop:\n\n```js\nconst readers = RecordBatchReader.readAll(fetch(path, {credentials: 'omit'}));\nfor await (const reader of readers) {\n  for await (const batch of reader) {\n    console.log(batch.length);\n  }\n}\n```\n\nNote: this code also works if there is only one table in the data source, in which case the outer loop will only execute once.\n\n\n# Writing Arrow Data\n\nThe `RecordStreamWriter` class allows you to write Arrow `Table` and `RecordBatch` instances to a data source.\n\n\n## Using Transform Streams\n\n### Connecting to Python Processes\n\nA more complicated example of using Arrow to go from node -> python -> node:\n\n```js\nconst { AsyncIterable } = require('ix');\nconst { child } = require('event-stream');\nconst { fork } = require('child_process');\nconst { RecordBatchStreamWriter } = require('apache-arrow');\n\nconst compute_degrees_via_gpu_accelerated_sql = ((scriptPath) => (edgeListColumnName) =>\n    spawn('python3', [scriptPath, edgeListColumnName], {\n        env: process.env,\n        stdio: ['pipe', 'pipe', 'inherit']\n    })\n)(require('path').resolve(__dirname, 'compute_degrees.py'));\n\nfunction compute_degrees(colName, recordBatchReaders) {\n    return AsyncIterable\n        .as(recordBatchReaders).mergeAll()\n        .pipe(RecordBatchStreamWriter.throughNode())\n        .pipe(compute_degrees_via_gpu_accelerated_sql(colName));\n}\n\nmodule.exports = compute_degrees;\n\n```\n\nThis example construct pipes of streams of events and that python process just reads from stdin, does a GPU-dataframe operation, and writes the results to stdout. (This example uses Rx/IxJS style functional streaming pipelines).\n\n`compute_degrees_via_gpu_accelerated_sql` returns a node `child_process` that is also a duplex stream, similar to the [`event-stream#child()` method](https://www.npmjs.com/package/event-stream#child-child_process)\n","slug":"arrowjs/docs/developer-guide/reading-and-writing","title":"Reading and Writing Arrow Data"},{"excerpt":"Notes on Memory Management Apache Arrow is a performance-optimized architecture, and the foundation of that performance is the approach to…","rawMarkdownBody":"# Notes on Memory Management\n\nApache Arrow is a performance-optimized architecture, and the foundation of that performance is the approach to memory management. It can be useful to have an understanding of how.\n\n## How Arrow Stores Data\n\nArrow reads in arrow data as arraybuffer(s) and then creates chunks that are \"sub array views\" into that big array buffer, and lists of those chunks are then composed into \"logical\" arrays.\n\nChunks are created for each column in each RecordBatch.\n\nThe chunks can be \"sliced and diced\" by operations on `Column`, `Table` and `DataFrame` objects, but are never copied (as long as flattening is not requested) and are conceptually immutable. (There is a low-level `Vector.set()` method however given that it could modify data that is used by multiple objects its use should be reserved for cases where implications are fully understood).\n","slug":"arrowjs/docs/developer-guide/memory-management","title":"Notes on Memory Management"},{"excerpt":"Using Predicates The Arrow API provides standard predicates that allow for the comparison of column values against literals (equality…","rawMarkdownBody":"# Using Predicates\n\n\nThe Arrow API provides standard predicates that allow for the comparison of column values against literals (equality, greater or equal than, less or eqial than) as well as the creation of composite logical expressions (`and`, `or` and `not`) out of individual column comparisons.\n\nIt is of course also possible to write custom predicates, however the performance is best when using the built-ins. Note that for performance reasons, filters are specified using \"predicates\" rather than custom JavaScript functions. For details on available predicates see [Using Predicates]().\n\n## Filtering using Predicates\n\n> Note that calling `filter()` on a `DataFrame` doesn't actually do anything (other than store the predicates). It's not until you call `countBy()` or `scan()` on the resulting object that Arrow actually scans through all of the data.\n\n```js\ntable = table.filter(arrow.predicate.col('winnername').eq(winner));\n\nfor (const row of table) {\n  // only returns rows that match criteria\n}\n```\n","slug":"arrowjs/docs/developer-guide/predicates","title":"Using Predicates"},{"excerpt":"Working with Tables References: Much of the text in this section is adapted from Brian Hulette's Using Apache Arrow JS with Large Datasets…","rawMarkdownBody":"# Working with Tables\n\nReferences:\n* Much of the text in this section is adapted from Brian Hulette's [Using Apache Arrow JS with Large Datasets](https://observablehq.com/@theneuralbit/using-apache-arrow-js-with-large-datasets)\n\n\n## Loading Arrow Data\n\nApplications often start with loading some Arrow formatted data. The Arrow API provides several ways to do this, but in many cases, the simplest approach is to use `Table.from()`.\n\n```js\nimport {Table} from 'apache-arrow';\nconst response = await fetch(dataUrl);\nconst arrayBuffer = await response.arrayBuffer();\nconst dataTable = arrow.Table.from(new Uint8Array(arrayBuffer));\n```\n\n## Getting Records Count\n\n```js\nconst count = table.count();\n```\n\n### Getting Arrow Schema Metadata\n\n```js\nconst fieldNames = table.schema.fields.map(f => f.name);\n// Array(3) [\"Latitude\", \"Longitude\", \"Date\"]\n```\n\n```js\nconst fieldTypes = tables.schema.fields.map(f => f.type)\n// Array(3) [Float, Float, Timestamp]\n\nconst fieldTypeNames = ...;\n// Array(3) [\"Float64\", \"Float64\", \"Timestamp<MICROSECOND>\"]\n```\n\n### Accessing Arrow Table Row Data\n\n```js\nconst firstRow = tables.get(0) // 1st row data\nconst lastRow = tables.get(rowCount-1)\n```\n\n## Record toJSON and toArray\n\nIt is easy to converting Rows to JSON/Arrays/Strings:\n\n```js\ntoJSON = Array(3) [41.890751259, -87.71617311899999, Int32Array(2)]\ntoArray = Array(3) [41.933659084, -87.72369064600001, Int32Array(2)]\n```\n\nSimilar conversion methods are avaiable on many Arrow classes.\n\ntables.get(0).toJSON()\n\n## Slicing Arrow Data\n\nevery10KRow = Array(17) [Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3), Array(3)]\n\nOur custom arrow data range stepper for sampling data:\n\nrange = ƒ(start, end, step)\n\n### Iterating over Rows and Cells\n\n```js\nfor (let row of dataFrame) {\n  for (let cell of row) {\n    if ( Array.isArray(cell) ) {\n      td = '[' + cell.map((value) => value == null ? 'null' : value).join(', ') + ']';\n    } else if (fields[k] === 'Date') {\n      td = toDate(cell); // convert Apache arrow Timestamp to Date\n    } else {\n      td = cell.toString();\n    }\n    k++;\n  }\n}\n```\n\n\n### Converting Dates\n\nApache Arrow Timestamp is a 64-bit int of milliseconds since the epoch, represented as two 32-bit ints in JS to preserve precision. The fist number is the \"low\" int and the second number is the \"high\" int.\n\n```js\nfunction toDate(timestamp) {\n  return new Date((timestamp[1] * Math.pow(2, 32) + timestamp[0])/1000);\n}\n```\n\n\n### Column Data Vectors\n\nApache Arrow stores columns in typed arrays and vectors:\n\nTyped vectors have convinience methods to convert Int32 arrays data to JS values you can work with.\n\nFor example, to get timestamps in milliseconds:\n\ntimestamps = Array(10) [2017-01-01, 2017-01-01, 2017-01-01, 2017-01-01, 2017-01-01, 2017-01-01, 2017-01-01, 2017-01-01, 2017-01-01, 2017-01-01]\n\n### Filtering Timestamped Data\n\n```js\nfunction filterByDate(startDate, endDate) {\n  const dateFilter = arrow.predicate.custom(i => {\n  \tconst arrowDate = table.getColumn('Date').get(i);\n    const date = toDate(arrowDate);\n    return date >= startDate && date <= endDate;\n  }, b => 1);\n\n  const getDate;\n  const results = [];\n  table.filter(dateFilter)\n    .scan(\n      index => {\n        results.push({\n          'date': toDate(getDate(index))\n        });\n      },\n      batch => {\n        getDate = arrow.predicate.col('Date').bind(batch);\n      }\n    );\n\n  return results;\n}\n```\n\nOur custom filter by date method uses custom arrow table predicate filter and scan methods to generate JS friendly data you can map or graph:\n","slug":"arrowjs/docs/developer-guide/tables","title":"Working with Tables"},{"excerpt":"Using with Typescript This documentation does not include advanced type definitions in the interest of simplicity and making the…","rawMarkdownBody":"# Using with Typescript\n\nThis documentation does not include advanced type definitions in the interest of simplicity and making the documentation accessible to more JavaScript developers. If you are working with Typescript in your application and would benefit from documentation that includes the Typescript definitions, you can refer to the auto generated JSDocs for the API.\n\n## Considerations when Using Typescript\n\nTo ensure that type information \"flows\" correctly from the types of function/constructor arguments to the types of returned objects, some special methods are provided (effectively working around limitations in Typescript).\n\nA key example is the availability of static `new()` methods on a number of classes that are intended to be used instead of calling `new` on the constructor. Accordingly, `Table.new()` is an alternative to `new Table()`, that provides stronger type inference on the returned Table.\n\nYou may want to leverage this syntax if your application is written in Typescript.\n","slug":"arrowjs/docs/developer-guide/typescript","title":"Using with Typescript"},{"excerpt":"Apache Arrow JavaScript API Reference Class List TODO - This is a class list from the C++ docs, it has only been partially updated to match…","rawMarkdownBody":"# Apache Arrow JavaScript API Reference\n\n## Class List\n\n> TODO - This is a class list from the C++ docs, it has only been partially updated to match JS API\n\n| Class             | Summary |\n| ---               | ---     |\n| `Array`           | Array base type Immutable data array with some logical type and some length |\n| `ArrayData`       | Mutable container for generic Arrow array data  |\n| `BinaryArray`     | Concrete Array class for variable-size binary data |\n| `BooleanArray`    | Concrete Array class for boolean data  |\n| `Buffer`          | Object containing a pointer to a piece of contiguous  memory with a particular size |\n| `ChunkedArray`    | A data structure managing a list of primitive Arrow arrays logically as one large array |\n| `Column`          | An immutable column data structure consisting of a field (type metadata) and a chunked data array |\n| `Decimal128`      | Represents a signed 128-bit integer in two's  complement |\n| `Decimal128Array` | Concrete Array class for 128-bit decimal data  |\n| `DictionaryArray` | Concrete Array class for dictionary data  |\n| `Field`           | The combination of a field name and data type, with  optional metadata |\n| `FixedSizeBinaryArray` | Concrete Array class for fixed-size  binary data |\n| `FixedWidthType`  | Base class for all fixed-width data types  |\n| `FlatArray`       | Base class for non-nested arrays  |\n| `FloatingPoint`   | Base class for all floating-point data types  |\n| `Int16Type`       | Concrete type class for signed 16-bit integer data  |\n| `Int32Type`       | Concrete type class for signed 32-bit integer data  |\n| `Int64Type`       | Concrete type class for signed 64-bit integer data  |\n| `Int8Type`        | Concrete type class for signed 8-bit integer data  |\n| `Integer`         | Base class for all integral data types  |\n| `ListArray`       | Concrete Array class for list data  |\n| `ListType`        | Concrete type class for list data  |\n| `NestedType`      | |\n| `NullArray`       | Degenerate null type Array  |\n| `NullType`        | Concrete type class for always-null data  |\n| `Number`          | Base class for all numeric data types  |\n| `NumericArray`    | |\n| `PrimitiveArray`  | Base class for arrays of fixed-size logical  types |\n| `RecordBatch`     | Collection of equal-length arrays matching a  particular Schema |\n| `RecordBatchReader` | Abstract interface for reading stream of  record batches |\n| `Schema`          | Sequence of arrow::Field objects describing the  columns of a record batch or table data structure |\n| `Status`          | |\n| `StringArray`     | Concrete Array class for variable-size string ( utf-8) data |\n| `StructArray`     | Concrete Array class for struct data  |\n| `Table`           | Logical table as sequence of chunked arrays  |\n| `TableBatchReader` | Compute a sequence of record batches from a ( possibly chunked) Table |\n| `TimeUnit`        | |\n| `UnionArray`      | Concrete Array class for union data  |\n","slug":"arrowjs/docs/api-reference","title":"Apache Arrow JavaScript API Reference"},{"excerpt":"Chunked Holds a \"chunked array\" that allows a number of array fragments (represented by  instances) to be treated logically as a single…","rawMarkdownBody":"# Chunked\n\nHolds a \"chunked array\" that allows a number of array fragments (represented by `Vector` instances) to be treated logically as a single vector. `Vector` instances can be concatenated into a `Chunked` without any memory being copied.\n\n\n## Usage\n\nCreate a new contiguous typed array from a `Chunked` instance (note that this creates a new typed array unless only one chunk)\n\n```js\nconst typedArray = chunked.toArray();\n```\n\nA `Chunked` array supports iteration, random element access and mutation.\n\n\n\n## Inheritance\n\nclass Chunked extends [Vector](docs-arrow/api-reference/vector.md)\n\n\n## Static Methods\n\n### Chunked.flatten(...vectors: Vector[]) : Vector\n\n<p class=\"badges\">\n   <img src=\"https://img.shields.io/badge/zero-copy-green.svg?style=flat-square\" alt=\"zero-copy\" />\n</p>\n\nUtility method that flattens a number of `Vector` instances or Arrays of `Vector` instances into a single Array of `Vector` instances. If the incoming Vectors are instances of `Chunked`, the child chunks are extracted and flattened into the resulting Array. Does not mutate or copy data from the Vector instances.\n\nReturns an Array of `Vector` instances.\n\n### Chunked.concat(...chunks: Vector<T>[]): Chunked\n\n<p class=\"badges\">\n   <img src=\"https://img.shields.io/badge/zero-copy-green.svg?style=flat-square\" alt=\"zero-copy\" />\n</p>\n\nConcatenates a number of `Vector` instances of the same type into a single `Chunked` Vector. Returns a new `Chunked` Vector.\n\nNote: This method extracts the inner chunks of any incoming `Chunked` instances, and flattens them into the `chunks` array of the returned `Chunked` Vector.\n\n## Members\n\n### [Symbol.iterator]() : Iterator\n\n`Chunked` arrays are iterable, allowing you to use constructs like `for (const element of chunked)` to iterate over elements. For in-order traversal, this is more performant than random-element access.\n\n### type : T\n\nReturns the DataType instance which determines the type of elements this `Chunked` instance contains. All vector chunks will have this type.\n\n### length: Number  (read-only)\n\nReturns the total number of elements in this `Chunked` instance, representing the length of of all chunks.\n\n### chunks: Vector[]  (read-only)\n\nReturns an array of the `Vector` chunks that hold the elements in this `Chunked` array.\n\n### typeId : TBD  (read-only)\n\nThe `typeId` enum value of the `type` instance\n\n### data : Data  (read-only)\n\nReturns the `Data` instance of the _first_ chunk in the list of inner Vectors.\n\n### ArrayType  (read-only)\n\nReturns the constructor of the underlying typed array for the values buffer as determined by this Vector's DataType.\n\n### numChildren  (read-only)\n\nThe number of logical Vector children for the Chunked Vector. Only applicable if the DataType of the Vector is one of the nested types (List, FixedSizeList, Struct, or Map).\n\n### stride  (read-only)\n\nThe number of elements in the underlying data buffer that constitute a single logical value for the given type. The stride for all DataTypes is 1 unless noted here:\n\n- For `Decimal` types, the stride is 4.\n- For `Date` types, the stride is 1 if the `unit` is DateUnit.DAY, else 2.\n- For `Int`, `Interval`, or `Time` types, the stride is 1 if `bitWidth <= 32`, else 2.\n- For `FixedSizeList` types, the stride is the `listSize` property of the `FixedSizeList` instance.\n- For `FixedSizeBinary` types, the stride is the `byteWidth` property of the `FixedSizeBinary` instance.\n\n### nullCount  (read-only)\n\nNumber of null values across all Vector chunks in this chunked array.\n\n### indices : ChunkedKeys<T> | null  (read-only)\n\nIf this is a dictionary encoded column, returns a `Chunked` instance of the indicies of all the inner chunks. Otherwise, returns `null`.\n\n### dictionary: ChunkedDict | null  (read-only)\n\nIf this is a dictionary encoded column, returns the Dictionary.\n\n\n## Methods\n\n### constructor(type : \\*, chunks? : Vector[] = [], offsets? : Number[])\n\n<p class=\"badges\">\n   <img src=\"https://img.shields.io/badge/zero-copy-green.svg?style=flat-square\" alt=\"zero-copy\" />\n</p>\n\nCreates a new `Chunked` array instance of the given `type` and optionally initializes it with a list of `Vector` instances.\n\n* `type` - The DataType of the inner chunks\n* `chunks`= - Vectors must all be compatible with `type`.\n* `offsets`= - A Uint32Array of offsets where each inner chunk starts and ends. If not provided, offsets are automatically calculated from the list of chunks.\n\nTBD - Confirm/provide some information on how `offsets` can be used?\n\n\n### clone(chunks? : this.chunks): Chunked\n\n<p class=\"badges\">\n   <img src=\"https://img.shields.io/badge/zero-copy-green.svg?style=flat-square\" alt=\"zero-copy\" />\n</p>\n\nReturns a new `Chunked` instance that is a clone of this instance. Does not copy the actual chunks, so the new `Chunked` instance will reference the same chunks.\n\n\n### concat(...others: Vector<T>[]): Chunked\n\n<p class=\"badges\">\n   <img src=\"https://img.shields.io/badge/zero-copy-green.svg?style=flat-square\" alt=\"zero-copy\" />\n</p>\n\nConcatenates a number of `Vector` instances after the chunks. Returns a new `Chunked` array.\n\nThe supplied `Vector` chunks must be the same DataType as the `Chunked` instance.\n\n### slice(begin?: Number, end?: Number): Chunked\n\nReturns a new chunked array representing the logical array containing the elements within the index range, potentially dropping some chunks at beginning and end.\n\n* `begin`=`0` - The first logical index to be included as index 0 in the new array.\n* `end` - The first logical index to be included as index 0 in the new array. Defaults to the last element in the range.\n\nReturns a zero-copy slice of this Vector. The begin and end arguments are handled the same way as JS' `Array.prototype.slice`; they are clamped between 0 and `vector.length` and wrap around when negative, e.g. `slice(-1, 5)` or `slice(5, -1)`\n\n\n### getChildAt(index : Number): Chunked | null\n\nIf this `Chunked` Vector's DataType is one of the nested types (Map or Struct), returns a `Chunked` Vector view over all the chunks for the child Vector at `index`.\n\n### search(index: Number): [number, number] | null;\n### search(index: Number, then?: SearchContinuation): ReturnType<N>;\n### search(index: Number, then?: SearchContinuation)\n\nUsing an `index` that is relative to the whole `Chunked` Vector, binary search through the list of inner chunks using supplied \"global\" `index` to find the chunk at that location. Returns the child index of the inner chunk and an element index that has been adjusted to the keyspace of the found inner chunk.\n\n`search()` can be called with only an integer index, in which case a pair of `[chunkIndex, valueIndex]` are returned as a two-element Array:\n\n```ts\nlet chunked = [\n    Int32Vector.from([0, 1, 2, 3]),\n    Int32Vector.from([4, 5, 6, 7, 8])\n].reduce((x, y) => x.concat(y));\n\nlet [chunkIndex, valueIndex] = chunked.search(6)\nassert(chunkIndex === 1)\nassert(valueIndex === 3)\n```\n\nIf `search()` is called with an integer index and a callback, the callback will be invoked with the `Chunked` instance as the first argument, then the `chunkIndex` and `valueIndex` as the second and third arguments:\n\n```ts\nlet getChildValue = (parent, childIndex, valueIndex) =>\n    chunked.chunks[childIndex].get(valueIndex);\nlet childValue = chunked.search(6, (chunked, childIndex, valueIndex) => )\n```\n\n\n### isValid(index: Number): boolean\n\nChecks if the element at `index` in the logical array is valid.\n\nChecks the null map (if present) to determine if the value in the logical `index` is included.\n\n### get(index : Number): T['TValue'] | null\n\nReturns the element at `index` in the logical array, or `null` if no such element exists (e.e.g if `index` is out of range).\n\n### set(index: Number, value: T['TValue'] | null): void\n\nWrites the given `value` at the provided `index`. If the value is null, the null bitmap is updated.\n\n### indexOf(element: Type, offset?: Number): Number\n\nReturns the index of the first occurrence of `element`, or `-1` if the value was not found.\n\n* `offset` - the index to start searching from.\n\n### toArray(): TypedArray\n\nReturns a single contiguous typed array containing data in all the chunks (effectively \"flattening\" the chunks.\n\nNotes:\n* Calling this function creates a new typed array unless there is only one chunk.\n\n\n","slug":"arrowjs/docs/api-reference/chunked","title":"Chunked"},{"excerpt":"Column An immutable column data structure consisting of a field (type metadata) and a chunked data array. Usage Copy a column Get a…","rawMarkdownBody":"# Column\n\nAn immutable column data structure consisting of a field (type metadata) and a chunked data array.\n\n## Usage\n\nCopy a column\n```js\nconst typedArray = column.slice();\n```\n\nGet a contiguous typed array from a `Column` (creates a new typed array unless only one chunk)\n```js\nconst typedArray = column.toArray();\n```\n\ncolumns are iterable\n```js\nlet max = column.get(0);\nlet min = max;\nfor (const value of column) {\n  if      (value > max) max = value;\n  else if (value < min) min = value;\n}\n```\n\n\n## Inheritance\n\nColumn extends [`Chunked`](modules/arrow/docs/api-reference/chunked.md)\n\n\n## Fields\n\nIn addition to fields inherited from `Chunked`, Colum also defines\n\n### name : String\n\nThe name of the column (short for `field.name`)\n\n### field : Field\n\nReturns the `Field` instance that describes for the column.\n\n\n## Methods\n\n\n### constructor(field : Field, vectors: Vector, offsets?: Uint32Array)\n\n\n### clone\n\nReturns a new `Column` instance with the same properties.\n\n\n### getChildAt(index : Number) : Vector\n\nReturns the `Vector` that contains the element with \n","slug":"arrowjs/docs/api-reference/column","title":"Column"},{"excerpt":"DataFrame Extends  Methods filter(predicate: Predicate) : FilteredDataFrame Returns: A  which is a subclass of , allowing you to chain…","rawMarkdownBody":"# DataFrame\n\nExtends `Table`\n\n## Methods\n\n### filter(predicate: Predicate) : FilteredDataFrame\n\nReturns: A `FilteredDataFrame` which is a subclass of `DataFrame`, allowing you to chain additional data frame operations, including applying additional filters.\n\nNote that this operation just registers filter predicates and is this very cheap to call. No actual filtering is done until iteration starts.\n\n### scan(next: Function, bind?: Function)\n\nPerformantly iterates over all non-filtered rows in the data frame.\n\n* `next` `(idx: number, batch: RecordBatch) => void` -\n* `bind` `(batch: RecordBatch) => void` - Optional, typically used to generate high-performance per-batch accessor functions for `next`.\n\n### countBy(name: Col | String) : CountByResult\n\n","slug":"arrowjs/docs/api-reference/data-frame","title":"DataFrame"},{"excerpt":"Dictionary A  stores index-to-value maps for dictionary encoded columns. Fields indices: V readonly dictionary: Vector readonly Static…","rawMarkdownBody":"# Dictionary\n\nA `Dictionary` stores index-to-value maps for dictionary encoded columns.\n\n\n## Fields\n\n### indices: V<TKey> readonly\n### dictionary: Vector<T> readonly\n\n## Static Methods\n\n### Dictionary.from(values: Vector, indices: TKey, keys: ArrayLike<number> | TKey['TArray']) : Dictionary\n\n## Methods\n\n### constructor(data: Data)\n\n### reverseLookup(value: T): number\n\n### getKey(idx: number): TKey['TValue'] | null\n\n### getValue(key: number): T['TValue'] | null\n\n### setKey(idx: number, key: TKey['TValue'] | null): void\n\n### setValue(key: number, value: T['TValue'] | null): void\n","slug":"arrowjs/docs/api-reference/dictionary","title":"Dictionary"},{"excerpt":"RecordBatchReader The RecordBatchReader is the IPC reader for reading chunks from a stream or file Usage The JavaScript API supports…","rawMarkdownBody":"# RecordBatchReader\n\nThe RecordBatchReader is the IPC reader for reading chunks from a stream or file\n\n## Usage\n\nThe JavaScript API supports streaming multiple arrow tables over a single socket.\n\nTo read all batches from all tables in a data source:\n\n```js\nconst readers = RecordBatchReader.readAll(fetch(path, {credentials: 'omit'}));\nfor await (const reader of readers) {\n    for await (const batch of reader) {\n        console.log(batch.length);\n    }\n}\n```\n\nIf you only have one table (the normal case), then there'll only be one RecordBatchReader/the outer loop will only execute once. You can also create just one reader via\n\n```js\nconst reader = await RecordBatchReader.from(fetch(path, {credentials: 'omit'}));\n```\n\n\n## Methods\n\n### readAll() : `AsyncIterable<RecordBatchReader>`\n\nReads all batches from all tables in the data source.\n\n\n### from(data : \\*) : RecordBatchFileReader \\| RecordBatchStreamReader\n\n`data`\n* Array\n* fetch response object\n* stream\n\n\nThe `RecordBatchReader.from` method will also detect which physical representation it's working with (Streaming or File), and will return either a `RecordBatchFileReader` or `RecordBatchStreamReader` accordingly.\n\n\n\nRemarks:\n* if you're fetching the table from a node server, make sure the content-type is `application/octet-stream`\n\n\n\n### toNodeStream()\n### pipe()\n\nYou can also turn the RecordBatchReader into a stream\nif you're in node, you can use either toNodeStream() or call the pipe(writable) methods\n\n\n\nin the browser (assuming you're using the UMD or \"browser\" fields in webpack), you can call\n\n### toDOMStream() or\n### pipeTo(writable)/pipeThrough(transform)\n\nIn the browser (assuming you're using the UMD or \"browser\" fields in webpack), you can call `toDOMStream()` or `pipeTo(writable)`/`pipeThrough(transform)`\n\nYou can also create a transform stream directly, instead of using `RecordBatchReader.from()`\n\nYou can also create a transform stream directly, instead of using `RecordBatchReader.from()`\n\n### throughNode\n### throughDOM\n\nvia `throughNode()` and `throughDOM()` respectively:\n\n1. https://github.com/apache/arrow/blob/49b4d2aad50e9d18cb0a51beb3a2aaff1b43e168/js/test/unit/ipc/reader/streams-node-tests.ts#L54\n2. https://github.com/apache/arrow/blob/49b4d2aad50e9d18cb0a51beb3a2aaff1b43e168/js/test/unit/ipc/reader/streams-dom-tests.ts#L50\n\nBy default the transform streams will only read one table from the source readable stream and then close, but you can change this behavior by passing `{ autoDestroy: false }` to the transform creation methods\n\n\n## Remarks\n\n* Reading from multiple tables (`readAll()`) is technically an extension in the JavaScript Arrow API compared to the Arrow C++ API. The authors found it was useful to be able to send multiple tables over the same physical socket\nso they built the ability to keep the underlying socket open and read more than one table from a stream.\n* Note that Arrow has two physical representations, one for streaming, and another for random-access so this only applies to the streaming representation.\n* The IPC protocol is that a stream of ordered Messages are consumed atomically. Messages can be of type `Schema`, `DictionaryBatch`, `RecordBatch`, or `Tensor` (which we don't support yet). The Streaming format is just a sequence of messages with Schema first, then `n` `DictionaryBatches`, then `m` `RecordBatches`.\n","slug":"arrowjs/docs/api-reference/record-batch-reader","title":"RecordBatchReader"},{"excerpt":"Data Untyped storage backing for . Can be thought of as array of  instances. Also contains slice offset (including null bitmaps). Fields…","rawMarkdownBody":"# Data\n\nUntyped storage backing for `Vector`.\n\nCan be thought of as array of `ArrayBuffer` instances.\n\nAlso contains slice offset (including null bitmaps).\n\n\n## Fields\n\nreadonly type: T;\n\nreadonly length: Number;\n\nreadonly offset: Number;\n\nreadonly stride: Number;\n\nreadonly childData: Data[];\n\nreadonly values: Buffers<T>[BufferType.DATA];\n\nreadonly typeIds: Buffers<T>[BufferType.TYPE];\n\nreadonly nullBitmap: Buffers<T>[BufferType.VALIDITY];\n\nreadonly valueOffsets: Buffers<T>[BufferType.OFFSET];\n\nreadonly ArrayType: any;\n\nreadonly typeId: T['TType'];\n\nreadonly buffers: Buffers<T>;\n\nreadonly nullCount: Number;\n\n\n## Static Methods\n\nConvenience methods for creating Data instances for each of the Arrow Vector types.\n\n### Data.Null<T extends Null>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer) : Data\n\n### Data.Int<T extends Int>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Dictionary<T extends Dictionary>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Float<T extends Float>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Bool<T extends Bool>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Decimal<T extends Decimal>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Date<T extends Date_>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Time<T extends Time>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Timestamp<T extends Timestamp>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Interval<T extends Interval>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.FixedSizeBinary<T extends FixedSizeBinary>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, data: DataBuffer<T>) : Data\n\n### Data.Binary<T extends Binary>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, valueOffsets: ValueOffsetsBuffer, data: Uint8Array) : Data\n\n### Data.Utf8<T extends Utf8>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, valueOffsets: ValueOffsetsBuffer, data: Uint8Array) : Data\n\n### Data.List<T extends List>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, valueOffsets: ValueOffsetsBuffer, child: Data<T['valueType']> | Vector<T['valueType']>) : Data\n\n### Data.FixedSizeList<T extends FixedSizeList>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, child: Data | Vector) : Data\n\n### Data.Struct<T extends Struct>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, children: (Data | Vector)[]) : Data\n\n### Data.Map<T extends Map_>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, children: (Data | Vector)[]) : Data\n\n### Data.Union<T extends SparseUnion>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, typeIds: TypeIdsBuffer, children: (Data | Vector)[]) : Data\n\n### Data.Union<T extends DenseUnion>(type: T, offset: Number, length: Number, nullCount: Number, nullBitmap: NullBuffer, typeIds: TypeIdsBuffer, valueOffsets: ValueOffsetsBuffer, children: (Data | Vector)[]) : Data\n}\n\n\n## Methods\n\n### constructor(type: T, offset: Number, length: Number, nullCount?: Number, buffers?: Partial<Buffers<T>> | Data<T>, childData?: (Data | Vector)[]);\n\n### clone(type: DataType, offset?: Number, length?: Number, nullCount?: Number, buffers?: Buffers<R>, childData?: (Data | Vector)[]) : Data;\n\n### slice(offset: Number, length: Number) : Data\n\n\n","slug":"arrowjs/docs/api-reference/data","title":"Data"},{"excerpt":"Field The combination of a field name and data type, with optional metadata. Fields are used to describe the individual constituents of a…","rawMarkdownBody":"# Field\n\nThe combination of a field name and data type, with optional metadata. Fields are used to describe the individual constituents of a nested DataType or a Schema.\n\n\n## Members\n\n### name : String (read only)\n\nThe name of this field.\n\n### type : Type (read only)\n\nThe type of this field.\n\n### nullable : Boolean (read only)\n\nWhether this field can contain `null` values, in addition to values of `Type` (this creates an extra null value map).\n\n### metadata : Object | null (read only)\n\nA field's metadata is represented by a map which holds arbitrary key-value pairs. Returns `null` if no metadata has been set.\n\n### typeId : ?\n\nTBD?\n\n### indices : ?\n\nTBD? Used if data type is a dictionary.\n\n\n## Methods\n\n### constructor(name : String, nullable?: Boolean, metadata?: Object)\n\nCreates an instance of `Field` with parameters initialized as follows:\n\n* `name` - Name of the column\n* `nullable`=`false` - Whether a null-array is maintained.\n* `metadata`=`null` - Map of metadata\n","slug":"arrowjs/docs/api-reference/field","title":"Field"},{"excerpt":"RecordBatchWriter The  \"serializes\" Arrow Tables (or streams of RecordBatches) to the Arrow File, Stream, or JSON representations for inter…","rawMarkdownBody":"## RecordBatchWriter\n\nThe `RecordBatchWriter` \"serializes\" Arrow Tables (or streams of RecordBatches) to the Arrow File, Stream, or JSON representations for inter-process communication (see also: [Arrow IPC format docs](https://arrow.apache.org/docs/format/IPC.html#streaming-format)).\n\nThe RecordBatchWriter is conceptually a \"transform\" stream that transforms Tables or RecordBatches into binary `Uint8Array` chunks that represent the Arrow IPC messages (`Schema`, `DictionaryBatch`, `RecordBatch`, and in the case of the File format, `Footer` messages).\n\nThese binary chunks are buffered inside the `RecordBatchWriter` instance until they are consumed, typically by piping the RecordBatchWriter instance to a Writable Stream (like a file or socket), enumerating the chunks via async-iteration, or by calling `toUint8Array()` to create a single contiguous buffer of the concatenated results once the desired Tables or RecordBatches have been written.\n\nRecordBatchWriter conforms to the `AsyncIterableIterator` protocol in all environments, and supports two additional stream primitives based on the environment (nodejs or browsers) available at runtime.\n\n* In nodejs, the `RecordBatchWriter` can be converted to a `ReadableStream`, piped to a `WritableStream`, and has a static method that returns a `TransformStream` suitable in chained `pipe` calls.\n* browser environments that support the [DOM/WhatWG Streams Standard](https://github.com/whatwg/streams), corresponding methods exist to convert `RecordBatchWriters` to the DOM `ReadableStream`, `WritableStream`, and `TransformStream` variants.\n\n*Note*: The Arrow JSON representation is not suitable as an IPC mechanism in real-world scenarios. It is used inside the Arrow project as a human-readable debugging tool and for validating interoperability between each language's separate implementation of the Arrow library.\n\n\n## Member Fields\n\nclosed: Promise (readonly)\n\nA Promise which resolves when this `RecordBatchWriter` is closed.\n\n## Static Methods\n\n### RecordBatchWriter.throughNode(options?: Object): DuplexStream\n\nCreates a Node.js `TransformStream` that transforms an input `ReadableStream` of Tables or RecordBatches into a stream of `Uint8Array` Arrow Message chunks.\n\n- `options.autoDestroy`: boolean - (default: `true`) Indicates whether the RecordBatchWriter should close after writing the first logical stream of RecordBatches (batches which all share the same Schema), or should continue and reset each time it encounters a new Schema.\n- `options.*` - Any Node Duplex stream options can be supplied\n\nReturns: A Node.js Duplex stream\n\nExample:\n\n```js\n\nconst fs = require('fs');\nconst { PassThrough, finished } = require('stream');\nconst { Table, RecordBatchWriter } = require('apache-arrow');\n\nconst table = Table.new({\n    i32: Int32Vector.from([1, 2, 3]),\n    f32: Float32Vector.from([1.0, 1.5, 2.0]),\n});\n\nconst source = new PassThrough({ objectMode: true });\n\nconst result = source\n    .pipe(RecordBatchWriter.throughNode())\n    .pipe(fs.createWriteStream('table.arrow'));\n\nsource.write(table);\nsource.end();\n\nfinished(result, () => console.log('done writing table.arrow'));\n```\n\n### RecordBatchWriter.throughDOM(writableStrategy? : Object, readableStrategy? : Object) : Object\n\nCreates a DOM/WhatWG `ReadableStream`/`WritableStream` pair that together transforms an input `ReadableStream` of Tables or RecordBatches into a stream of `Uint8Array` Arrow Message chunks.\n\n- `options.autoDestroy`: boolean - (default: `true`) Indicates whether the RecordBatchWriter should close after writing the first logical stream of RecordBatches (batches which all share the same Schema), or should continue and reset each time it encounters a new Schema.\n- `writableStrategy.*`= - Any options for QueuingStrategy\\<RecordBatch\\>\n- `readableStrategy.highWaterMark`? : Number\n- `readableStrategy.size`?: Number\n\nReturns: an object with the following fields:\n\n- `writable`: WritableStream\\<Table | RecordBatch\\>\n- `readable`: ReadableStream\\<Uint8Array\\>\n\n\n\n\n## Methods\n\nconstructor(options? : Object)\n\n* `options.autoDestroy`: boolean -\n\n\n### toString(sync: Boolean): string | Promise<string>\n\n### toUint8Array(sync: Boolean): Uint8Array | Promise<Uint8Array>\n\n\n### writeAll(input: Table | Iterable<RecordBatch>): this\n### writeAll(input: AsyncIterable<RecordBatch>): Promise<this>\n### writeAll(input: PromiseLike<AsyncIterable<RecordBatch>>): Promise<this>\n### writeAll(input: PromiseLike<Table | Iterable<RecordBatch>>): Promise<this>\n\n* [Symbol.asyncIterator](): AsyncByteQueue<Uint8Array>\n\nReturns An async iterator that produces Uint8Arrays.\n\n### toDOMStream(options?: Object): ReadableStream<Uint8Array>\n\nReturns a new DOM/WhatWG stream that can be used to read the Uint8Array chunks produced by the RecordBatchWriter\n\n- `options` - passed through to the DOM ReadableStream constructor, any DOM ReadableStream options.\n\n### toNodeStream(options?: Object): Readable\n\n- `options` - passed through to the Node ReadableStream constructor, any Node ReadableStream options.\n\n### close() : void\n\nClose the RecordBatchWriter. After close is called, no more chunks can be written.\n\n### abort(reason?: any) : void\n### finish() : this\n### reset(sink?: WritableSink<ArrayBufferViewInput>, schema?: Schema | null): this\n\nChange the sink\n\n### write(payload?: Table | RecordBatch | Iterable<Table> | Iterable<RecordBatch> | null): void\n\nWrites a `RecordBatch` or all the RecordBatches from a `Table`.\n\n\n## Remarks\n\n* Just like the `RecordBatchReader`, a `RecordBatchWriter` is a factory base class that returns an instance of the subclass appropriate to the situation: `RecordBatchStreamWriter`, `RecordBatchFileWriter`, `RecordBatchJSONWriter`\n","slug":"arrowjs/docs/api-reference/record-batch-writer","title":" RecordBatchWriter"},{"excerpt":"Predicates Value Literal Col The Col predicate gets the value of the specified column bind(batch : RecordBatch) : Function Returns a more…","rawMarkdownBody":"# Predicates\n\n\n\n\n## Value\n\n## Literal\n\n## Col\n\nThe Col predicate gets the value of the specified column\n\n### bind(batch : RecordBatch) : Function\n\nReturns a more efficient accessor for the column values in this batch, taking local indices.\n\nNote: These accessors are typically created in the `DataFrame.scan` bind method, and then used in the the `DataFrame.next` method.\n\n## ComparisonPredicate\n\n## And\n\n## Or\n\n## Equals\n\n## LTEq\n\n## GTEq\n\n## Not\n\n## CustomPredicate\n","slug":"arrowjs/docs/api-reference/predicates","title":"Predicates"},{"excerpt":"RecordBatch Overview A Record Batch in Apache Arrow is a collection of equal-length array instances. Usage A record batch can be created…","rawMarkdownBody":"# RecordBatch\n\n## Overview\n\nA Record Batch in Apache Arrow is a collection of equal-length array instances.\n\n## Usage\n\nA record batch can be created from this list of arrays using `RecordBatch.from`:\n```\nconst data = [\n  new Array([1, 2, 3, 4]),\n  new Array(['foo', 'bar', 'baz', None]),\n  new Array([True, None, False, True])\n]\n\nconst recordBatch = RecordBatch.from(arrays);\n```\n\n\n## Inheritance\n\n`RecordBatch` extends [`StructVector`](docs-arrow/api-reference/struct-vector) extends [`BaseVector`](docs-arrow/api-reference/vector)\n\n\n## Members\n\n### schema : Schema (readonly)\n\nReturns the schema of the data in the record batch\n\n### numCols : Number (readonly)\n\nReturns number of fields/columns in the schema (shorthand for `this.schema.fields.length`).\n\n\n## Static Methods\n\n### RecordBatch.from(vectors: Array, names: String[] = []) : RecordBatch\n\nCreates a `RecordBatch`, see `RecordBatch.new()`.\n\n\n### RecordBatch.new(vectors: Array, names: String[] = []) : RecordBatch\n\nCreates new a record batch.\n\nSchema is auto inferred, using names or index positions if `names` are not supplied.\n\n\n## Methods\n\n### constructor(schema: Schema, numRows: Number, childData: (Data | Vector)[])\n\nCreate a new `RecordBatch` instance with `numRows` rows of child data.\n\n* `numRows` - \n* `childData` - \n\n\n### constructor(schema: Schema, data: Data, children?: Vector[])\n\nCreate a new `RecordBatch` instance with `numRows` rows of child data.\n\n### constructor(...args: any[])\n\n### clone(data: Data, children?: Array) : RecordBatch\n\nReturns a newly allocated copy of this `RecordBatch`\n\n### concat(...others: Vector[]) : Table\n\nConcatenates a number of `Vector` instances.\n\n### select(...columnNames: K[]) : RecordBatch\n\nReturn a new `RecordBatch` with a subset of columns.\n","slug":"arrowjs/docs/api-reference/record-batch","title":"RecordBatch"},{"excerpt":"Row A  is an Object that retrieves each value at a certain index across a collection of child Vectors. Rows are returned from the  function…","rawMarkdownBody":"# Row\n\nA `Row` is an Object that retrieves each value at a certain index across a collection of child Vectors. Rows are returned from the `get()` function of the nested `StructVector` and `MapVector`, as well as `RecordBatch` and `Table`.\n\nA `Row` defines read-only accessors for the indices and (if applicable) names of the child Vectors. For example, given a `StructVector` with the following schema:\n\n```ts\nconst children = [\n    Int32Vector.from([0, 1]),\n    Utf8Vector.from(['foo', 'bar'])\n];\n\nconst type = new Struct<{ id: Int32, value: Utf8 }>([\n    new Field('id', children[0].type),\n    new Field('value', children[1].type)\n]);\n\nconst vector = new StructVector(Data.Struct(type, 0, 2, 0, null, children));\n\nconst row = vector.get(1);\n\nassert((row[0] ===   1  ) && (row.id    === row[0]));\nassert((row[1] === 'bar') && (row.value === row[1]));\n```\n\n`Row` implements the Iterator interface, enumerating each value in order of the child vectors list.\n\nNotes:\n\n- If the Row's parent type is a `Struct`, `Object.getOwnPropertyNames(row)` returns the child vector indices.\n- If the Row's parent type is a `Map`, `Object.getOwnPropertyNames(row)` returns the child vector field names, as defined by the `children` Fields list of the `Map` instance.\n\n## Methods\n\n### [key: string]: T[keyof T]['TValue']\n### [kParent]: MapVector<T> | StructVector<T>\n### [kRowIndex]: number\n### [kLength]: number (readonly)\n### [Symbol.iterator](): IterableIterator<T[keyof T][\"TValue\"]>\n### get(key: K): T[K][\"TValue\"]\n\nReturns the value at the supplied `key`, where `key` is either the integer index of the set of child vectors, or the name of a child Vector\n\n### toJSON(): any\n### toString(): any\n","slug":"arrowjs/docs/api-reference/row","title":"Row"},{"excerpt":"Schema Sequence of arrow::Field objects describing the columns of a record batch or table data structure Accessors fields : Field…","rawMarkdownBody":"# Schema\n\nSequence of arrow::Field objects describing the columns of a record batch or table data structure\n\n\n## Accessors\n\n### fields : Field[] \\(readonly)\n\nReturn the list of fields (columns) in the schema.\n\n### metadata (readonly)\n\nThe custom key-value metadata, if any. metadata may be null.\n\n### dictionaries (readonly)\n\nTBD - List of dictionaries (each dictionary is associated with a column that is dictionary encoded).\n\n### dictionaryFields (readonly)\n\nTBD - List of fields\n\n\n## Methods\n\n### constructor(fields: Field[], metadata?: Object, dictionaries?: Object, dictionaryFields?: Object)\n\nCreates a new schema instance.\n\n\n### select(columnNames) : Schema\n\nReturns a new `Schema` with the Fields indicated by the column names.\n\n\n","slug":"arrowjs/docs/api-reference/schema","title":"Schema"},{"excerpt":"StructVector Methods asMap(keysSorted: boolean = false) TBA","rawMarkdownBody":"# StructVector\n\n\n## Methods\n\n### asMap(keysSorted: boolean = false)\n\nTBA\n","slug":"arrowjs/docs/api-reference/struct-vector","title":"StructVector"},{"excerpt":"Table Logical table as sequence of chunked arrays Overview The JavaScript  class is not part of the Apache Arrow specification as such, but…","rawMarkdownBody":"# Table\n\nLogical table as sequence of chunked arrays\n\n\n## Overview\n\nThe JavaScript `Table` class is not part of the Apache Arrow specification as such, but is rather a tool to allow you to work with multiple record batches and array pieces as a single logical dataset.\n\nAs a relevant example, we may receive multiple small record batches in a socket stream, then need to concatenate them into contiguous memory for use in NumPy or pandas. The Table object makes this efficient without requiring additional memory copying.\n\nA Table’s columns are instances of `Column`, which is a container for one or more arrays of the same type.\n\n\n## Usage\n\n`Table.new()` accepts an `Object` of `Columns` or `Vectors`, where the keys will be used as the field names for the `Schema`:\n\n```js\nconst i32s = Int32Vector.from([1, 2, 3]);\nconst f32s = Float32Vector.from([.1, .2, .3]);\nconst table = Table.new({ i32: i32s, f32: f32s });\nassert(table.schema.fields[0].name === 'i32');\n```\n\nIt also accepts a a list of Vectors with an optional list of names or\nFields for the resulting Schema. If the list is omitted or a name is\nmissing, the numeric index of each Vector will be used as the name:\n\n```ts\nconst i32s = Int32Vector.from([1, 2, 3]);\nconst f32s = Float32Vector.from([.1, .2, .3]);\nconst table = Table.new([i32s, f32s], ['i32']);\nassert(table.schema.fields[0].name === 'i32');\nassert(table.schema.fields[1].name === '1');\n```\n\nIf the supplied arguments are `Column` instances, `Table.new` will infer the `Schema` from the `Column`s:\n\n```ts\nconst i32s = Column.new('i32', Int32Vector.from([1, 2, 3]));\nconst f32s = Column.new('f32', Float32Vector.from([.1, .2, .3]));\nconst table = Table.new(i32s, f32s);\nassert(table.schema.fields[0].name === 'i32');\nassert(table.schema.fields[1].name === 'f32');\n```\n\nIf the supplied Vector or Column lengths are unequal, `Table.new` will\nextend the lengths of the shorter Columns, allocating additional bytes\nto represent the additional null slots. The memory required to allocate\nthese additional bitmaps can be computed as:\n\n```ts\nlet additionalBytes = 0;\nfor (let vec in shorter_vectors) {\n additionalBytes += (((longestLength - vec.length) + 63) & ~63) >> 3;\n}\n```\n\nFor example, an additional null bitmap for one million null values would require `125,000` bytes (`((1e6 + 63) & ~63) >> 3`), or approx. `0.11MiB`\n\n\n## Inheritance\n\n`Table` extends Chunked\n\n\n## Static Methods\n\n### Table.empty() : Table\n\nCreates an empty table\n\n### Table.from() : Table\n\nCreates an empty table\n\n### Table.from(source: RecordBatchReader): Table\n### Table.from(source: Promise<RecordBatchReader>): Promise<Table>\n### Table.from(source?: any) : Table\n### Table.fromAsync(source: import('./ipc/reader').FromArgs): Promise<Table>\n### Table.fromVectors(vectors: any[], names?: String[]) : Table\n### Table.fromStruct(struct: Vector) : Table\n\n\n### Table.new(columns: Object)\n### Table.new(...columns)\n### Table.new(vectors: Vector[], names: String[])\n\nType safe constructors. Functionally equivalent to calling `new Table()` with the same arguments, however if using Typescript using the `new` method instead will ensure that types inferred from the arguments \"flow through\" into the return Table type.\n\n\n## Members\n\n### schema (readonly)\n\nThe `Schema` of this table.\n\n\n### length : Number (readonly)\n\nThe number of rows in this table.\n\nTBD: this does not consider filters\n\n\n### chunks : RecordBatch[] \\(readonly)\n\nThe list of chunks in this table.\n\n\n### numCols : Number (readonly)\n\nThe number of columns in this table.\n\n\n## Methods\n\n### constructor(batches: RecordBatch[])\n\nThe schema will be inferred from the record batches.\n\n### constructor(...batches: RecordBatch[])\n\nThe schema will be inferred from the record batches.\n\n### constructor(schema: Schema, batches: RecordBatch[])\n\n### constructor(schema: Schema, ...batches: RecordBatch[])\n\n### constructor(...args: any[])\n\n\nCreate a new `Table` from a collection of `Columns` or `Vectors`, with an optional list of names or `Fields`.\n\nTBD\n\n### clone(chunks?:)\n\nReturns a new copy of this table.\n\n### getColumnAt(index: number): Column | null\n\nGets a column by index.\n\n### getColumn(name: String): Column | null\n\nGets a column by name\n\n### getColumnIndex(name: String) : Number | null\n\nReturns the index of the column with name `name`.\n\n### getChildAt(index: number): Column | null\n\nTBD\n\n### serialize(encoding = 'binary', stream = true) : Uint8Array\n\nReturns a `Uint8Array` that contains an encoding of all the data in the table.\n\nNote: Passing the returned data back into `Table.from()` creates a \"deep clone\" of the table.\n\n\n### count(): number\n\nTBD - Returns the number of elements.\n\n### select(...columnNames: string[]) : Table\n\nReturns a new Table with the specified subset of columns, in the specified order.\n\n### countBy(name : Col | String) : Table\n\nReturns a new Table that contains two columns (`values` and `counts`).\n","slug":"arrowjs/docs/api-reference/table","title":"Table"},{"excerpt":"Vector Also referred to as . An abstract base class for vector types. Can support a null map ... TBD Inheritance Fields data: Data (readonly…","rawMarkdownBody":"# Vector\n\nAlso referred to as `BaseVector`. An abstract base class for vector types.\n\n* Can support a null map\n* ...\n* TBD\n\n\n## Inheritance\n\n\n## Fields\n\n### data: Data<T> (readonly)\n\nThe underlying Data instance for this Vector.\n\n### numChildren: number (readonly)\n\nThe number of logical Vector children. Only applicable if the DataType of the Vector is one of the nested types (List, FixedSizeList, Struct, or Map).\n\n### type : T\n\nThe DataType that describes the elements in the Vector\n\n### typeId : T['typeId']\n\nThe `typeId` enum value of the `type` instance\n\n### length : number\n\nNumber of elements in the `Vector`\n\n### offset : number\n\nOffset to the first element in the underlying data.\n\n### stride : number\n\nStride between successive elements in the the underlying data.\n\nThe number of elements in the underlying data buffer that constitute a single logical value for the given type. The stride for all DataTypes is 1 unless noted here:\n\n- For `Decimal` types, the stride is 4.\n- For `Date` types, the stride is 1 if the `unit` is DateUnit.DAY, else 2.\n- For `Int`, `Interval`, or `Time` types, the stride is 1 if `bitWidth <= 32`, else 2.\n- For `FixedSizeList` types, the stride is the `listSize` property of the `FixedSizeList` instance.\n- For `FixedSizeBinary` types, the stride is the `byteWidth` property of the `FixedSizeBinary` instance.\n\n### nullCount : Number\n\nNumber of `null` values in this `Vector` instance (`null` values require a null map to be present).\n\n### VectorName : String\n\nReturns the name of the Vector\n\n### ArrayType : TypedArrayConstructor | ArrayConstructor\n\nReturns the constructor of the underlying typed array for the values buffer as determined by this Vector's DataType.\n\n### values : T['TArray']\n\nReturns the underlying data buffer of the Vector, if applicable.\n\n### typeIds : Int8Array | null\n\nReturns the underlying typeIds buffer, if the Vector DataType is Union.\n\n### nullBitmap : Uint8Array | null\n\nReturns the underlying validity bitmap buffer, if applicable.\n\nNote: Since the validity bitmap is a Uint8Array of bits, it is _not_ sliced when you call `vector.slice()`. Instead, the `vector.offset` property is updated on the returned Vector. Therefore, you must factor `vector.offset` into the bit position if you wish to slice or read the null positions manually. See the implementation of `BaseVector.isValid()` for an example of how this is done.\n\n### valueOffsets : Int32Array | null\n\nReturns the underlying valueOffsets buffer, if applicable. Only the List, Utf8, Binary, and DenseUnion DataTypes will have valueOffsets.\n\n## Methods\n\n### clone(data: Data<R>, children): Vector<R>\n\nReturns a clone of the current Vector, using the supplied Data and optional children for the new clone. Does not copy any underlying buffers.\n\n### concat(...others: Vector<T>[])\n\nReturns a `Chunked` vector that concatenates this Vector with the supplied other Vectors. Other Vectors must be the same type as this Vector.\n\n\n### slice(begin?: number, end?: number)\n\nReturns a zero-copy slice of this Vector. The begin and end arguments are handled the same way as JS' `Array.prototype.slice`; they are clamped between 0 and `vector.length` and wrap around when negative, e.g. `slice(-1, 5)` or `slice(5, -1)`\n\n### isValid(index: number): boolean\n\nReturns whether the supplied index is valid in the underlying validity bitmap.\n\n### getChildAt<R extends DataType = any>(index: number): Vector<R> | null\n\nReturns the inner Vector child if the DataType is one of the nested types (Map or Struct).\n\n### toJSON(): any\n\nReturns a dense JS Array of the Vector values, with null sentinels in-place.\n","slug":"arrowjs/docs/api-reference/vector","title":"Vector"},{"excerpt":"Types Objects representing types.","rawMarkdownBody":"# Types\n\nObjects representing types.\n\n","slug":"arrowjs/docs/api-reference/types","title":"Types"},{"excerpt":"Types and Vectors Overview Usage Constructing new  instances is done through the static  methods Special Vectors Dictionary Arrays The…","rawMarkdownBody":"# Types and Vectors\n\n## Overview\n\n\n## Usage\n\nConstructing new `Vector` instances is done through the static `from()` methods\n\n\n## Special Vectors\n\n### Dictionary Arrays\n\nThe Dictionary type is a special array type that enables one or more record batches in a file or stream to transmit integer indices referencing a shared dictionary containing the distinct values in the logical array. Later record batches reuse indices in earlier batches and add new ones as needed.\n\nA `Dictionary` is similar to a `factor` in R or a pandas, or \"Categorical\" in Python. It is is often used with strings to save memory and improve performance.\n\n\n### StructVector\n\nHolds nested fields.\n\n\n### Bool Vectors\n\n| Bool Vectors            |\n| ---                     |\n| `BoolVector`            |\n\n\n### Binary Vectors\n\n| Binary Vectors          |\n| ---                     |\n| `BinaryVector`          |\n\n\n## FloatVectors\n\n| Float Vectors           | Backing         | Comments                  |\n| ---                     |\n| `Float16Vector`         | `Uint16Array`   | No native JS 16 bit type, additional methods available |\n| `Float32Vector`         | `Float32Array`  | Holds 32 bit floats       |\n| `Float64Vector`         | `Float64Array`  | Holds 64 bit floats       |\n\n\n### Static FloatVector Methods\n\n### FloatVector.from(data: Uint16Array): Float16Vector;\n### FloatVector.from(data: Float32Array): Float32Vector;\n### FloatVector.from(data: Float64Array): Float64Vector;\n### FloatVector16.from(data: Uint8Array | Iterable<Number>): Float16Vector;\n### FloatVector16.from(data: Uint16Array | Iterable<Number>): Float16Vector;\n### FloatVector32.from(data: Float32['TArray'] | Iterable<Number>): Float32Vector;\n### FloatVector64.from(data: Float64['TArray'] | Iterable<Number>): Float64Vector;\n\n\n## Float16Vector Methods\n\nSince JS doesn't have half floats, `Float16Vector` is backed by a `Uint16Array` integer array. To make it practical to work with these arrays in JS, some extra methods are added.\n\n### toArray() : `Uint16Array`\n\nReturns a zero-copy view of the underlying `Uint16Array` data.\n\nNote: Avoids incurring extra compute or copies if you're calling `toArray()` in order to create a buffer for something like WebGL, but makes it hard to use the returned data as floating point values in JS.\n\n### toFloat32Array() : Float32Array\n\nThis method will convert values to 32 bit floats. Allocates a new Array.\n\n### toFloat64Array() : Float64Array\n\nThis method will convert values to 64 bit floats. Allocates a new Array.\n\n\n## IntVectors\n\n| Int Vectors             | Backing         | Comments                  |\n| ---                     | ---             | ---                       |\n| `Int8Vector`            | `Int8Array`     |                           |\n| `Int16Vector`           | `Int16Array`    |                           |\n| `Int32Vector`           | `Int32Array`    |                           |\n| `Int64Vector`           | `Int32Array`    | 64-bit values stored as pairs of `lo, hi` 32-bit values for engines without BigInt support, extra methods available |\n| `Uint8Vector`           | `Uint8Array`    |                           |\n| `Uint16Vector`          | `Uint16Array `  |                           |\n| `Uint32Vector`          | `Uint32Array `  |                           |\n| `Uint64Vector`          | `Uint32Array`   | 64-bit values stored as pairs of `lo, hi` 32-bit values for engines without BigInt support, extra methods available |\n\n## Int64Vector Methods\n\n### toArray() : `Int32Array`\n\nReturns a zero-copy view of the underlying pairs of `lo, hi` 32-bit values as an `Int32Array`. This Array's length is twice the logical length of the `Int64Vector`.\n\n### toBigInt64Array(): `BigInt64Array`\n\nReturns a zero-copy view of the underlying 64-bit integers as a `BigInt64Array`. This Array has the samne length as the length of the original `Int64Vector`.\n\nNote: as of 03/2019, `BigInt64Array` is only available in v8/Chrome. In JS runtimes without support for `BigInt`, this method throws an unsupported error.\n\n## Uint64Vector Methods\n\n### toArray() : `Uint32Array`\n\nReturns a zero-copy view of the underlying pairs of `lo, hi` 32-bit values as a `Uint32Array`. This Array's length is twice the logical length of the `Uint64Vector`.\n\n### toBigUint64Array(): `BigUint64Array`\n\nReturns a zero-copy view of the underlying 64-bit integers as a `BigUint64Array`. This Array has the samne length as the length of the original `Uint64Vector`.\n\nNote: as of 03/2019, `BigUint64Array` is only available in v8/Chrome. In JS runtimes without support for `BigInt`, this method throws an unsupported error.\n\n## Static IntVector Methods\n\n### IntVector.from(data: Int8Array): Int8Vector;\n### IntVector.from(data: Int16Array): Int16Vector;\n### IntVector.from(data: Int32Array, is64?: boolean): Int32Vector | Int64Vector;\n### IntVector.from(data: Uint8Array): Uint8Vector;\n### IntVector.from(data: Uint16Array): Uint16Vector;\n### IntVector.from(data: Uint32Array, is64?: boolean): Uint32Vector | Uint64Vector;\n\n### Int8Vector.from(this: typeof Int8Vector,   data: Int8Array   | Iterable<number>): Int8Vector;\n### Int16Vector.from(this: typeof Int16Vector,  data: Int16Array  | Iterable<number>): Int16Vector;\n### Int32Vector.from(this: typeof Int32Vector,  data: Int32Array  | Iterable<number>): Int32Vector;\n### Int64Vector.from(this: typeof Int64Vector,  data: Int32Array  | Iterable<number>): Int64Vector;\n### Uint8Vector.from(this: typeof Uint8Vector,  data: Uint8Array  | Iterable<number>): Uint8Vector;\n### Uint16Vector.from(this: typeof Uint16Vector, data: Uint16Array | Iterable<number>): Uint16Vector;\n### Uint32Vector.from(this: typeof Uint32Vector, data: Uint32Array | Iterable<number>): Uint32Vector;\n### Uint64Vector.from(this: typeof Uint64Vector, data: Uint32Array | Iterable<number>): Uint64Vector;\n\n\n## Date Vectors\n\n| Date Vectors            | Backing       |                     |\n| ---                     | ---           | ---                 |\n| `DateDayVector`         | `Int32Array`  |                     |\n| `DateMillisecondVector` | `Int32Array`  | TBD - stride: 2?    |\n","slug":"arrowjs/docs/api-reference/vectors","title":"Types and Vectors"}]}}}